{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1d25dc5",
   "metadata": {},
   "source": [
    "# F1 Race Predictor with Circuit-Specific Performance and Live Data Integration\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, we enhance our Formula 1 race predictor by incorporating circuit-specific performance data, weather conditions, and free practice session data. We modify the simulation to use pre-trained agents based on historical race and lap data, allowing us to simulate races under specified conditions and update our predictions with live data.\n",
    "\n",
    "**Notably, we adjust the code to include only the drivers who are actually participating in the specified race and address issues causing unrealistic simulation results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8a39da",
   "metadata": {},
   "source": [
    "## 1. Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "id": "4d7ed06d",
   "metadata": {},
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "from tensorboard.notebook import display\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# For Monte Carlo Simulation and Agent-Based Modeling\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# For Animation (if needed)\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.animation import FuncAnimation"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "41b3eb4e",
   "metadata": {},
   "source": [
    "## 2. Load Data with Proper Handling of Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "id": "a846ce76",
   "metadata": {},
   "source": [
    "# Define NA values\n",
    "na_values = ['\\\\N']\n",
    "\n",
    "# Load Data\n",
    "circuits = pd.read_csv('../../data/raw_data/circuits.csv', na_values=na_values)\n",
    "constructors = pd.read_csv('../../data/raw_data/constructors.csv', na_values=na_values)\n",
    "drivers = pd.read_csv('../../data/raw_data/drivers.csv', na_values=na_values)\n",
    "races = pd.read_csv('../../data/raw_data/races.csv', na_values=na_values)\n",
    "results = pd.read_csv('../../data/raw_data/results.csv', na_values=na_values)\n",
    "lap_times = pd.read_csv('../../data/raw_data/lap_times.csv', na_values=na_values)\n",
    "pit_stops = pd.read_csv('../../data/raw_data/pit_stops.csv', na_values=na_values)\n",
    "qualifying = pd.read_csv('../../data/raw_data/qualifying.csv', na_values=na_values)\n",
    "status = pd.read_csv('../../data/raw_data/status.csv', na_values=na_values)\n",
    "weather = pd.read_csv('../../data/raw_data/ff1_weather.csv', na_values=na_values)\n",
    "practice_sessions = pd.read_csv('../../data/raw_data/ff1_free_practice.csv', na_values=na_values)\n",
    "\n",
    "print('Data Loaded Successfully')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "44b21b4c",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f0b2d2",
   "metadata": {},
   "source": [
    "### 3.1 Helper Functions for Standardization"
   ]
  },
  {
   "cell_type": "code",
   "id": "32032482",
   "metadata": {},
   "source": [
    "# Function to standardize event names\n",
    "def standardize_event_name(name):\n",
    "    if pd.isnull(name):\n",
    "        return ''\n",
    "    name = name.lower()\n",
    "    name = re.sub(r'[^a-z0-9 ]', '', name)  # Remove special characters\n",
    "    name = name.strip()\n",
    "    name = name.replace(' grand prix', '')\n",
    "    name = name.replace('gp', '')\n",
    "    name = name.replace('formula 1', '')\n",
    "    name = name.replace('formula one', '')\n",
    "    name = name.replace('fia', '')\n",
    "    name = name.replace('großer preis von', '')\n",
    "    name = name.replace('groser preis von', '')\n",
    "    name = name.replace('großer preis', '')\n",
    "    name = name.replace('grosser preis', '')\n",
    "    name = name.replace('gran premio de', '')\n",
    "    name = name.replace('gran premio', '')\n",
    "    name = name.replace('prix', '')\n",
    "    name = name.replace('de', '')\n",
    "    name = name.replace('di', '')\n",
    "    name = name.replace('della', '')\n",
    "    name = name.replace('las', '')\n",
    "    name = name.replace('city', '')\n",
    "    name = name.strip()\n",
    "    return name\n",
    "\n",
    "# Function to standardize driver names\n",
    "def standardize_driver_name(name):\n",
    "    if pd.isnull(name):\n",
    "        return ''\n",
    "    name = name.lower()\n",
    "    name = name.strip()\n",
    "    name = re.sub(r'[^a-z]', '', name)  # Remove non-alphabetic characters\n",
    "    return name"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "17a51318",
   "metadata": {},
   "source": [
    "### 3.2 Preprocess Practice Session Data"
   ]
  },
  {
   "cell_type": "code",
   "id": "32f8dd7e",
   "metadata": {},
   "source": [
    "# Rename Columns for Consistency\n",
    "practice_sessions.rename(columns={'EventName': 'name', 'Year': 'year', 'SessionName': 'session'}, inplace=True)\n",
    "\n",
    "# Standardize Event Names\n",
    "practice_sessions['standardized_name'] = practice_sessions['name'].apply(standardize_event_name)\n",
    "practice_sessions['standardized_name'] = practice_sessions['standardized_name'].str.lower()\n",
    "\n",
    "# Standardize Driver Names\n",
    "practice_sessions['Driver'] = practice_sessions['Driver'].str.upper()\n",
    "practice_sessions['driver_name_standardized'] = practice_sessions['Driver'].apply(standardize_driver_name)\n",
    "\n",
    "# Convert Lap Times to Total Seconds\n",
    "practice_sessions['LapTime_seconds'] = pd.to_timedelta(practice_sessions['LapTime']).dt.total_seconds()\n",
    "\n",
    "# Aggregate Practice Session Data\n",
    "practice_sessions['SessionDate'] = pd.to_datetime(practice_sessions['LapStartDate']).dt.date\n",
    "practice_sessions['year'] = practice_sessions['year'].astype(int)\n",
    "\n",
    "# Calculate Average Lap Time per Driver per Session\n",
    "avg_practice_times = practice_sessions.groupby(['Driver', 'year', 'standardized_name', 'session'])['LapTime_seconds'].mean().reset_index()\n",
    "\n",
    "# Preview Practice Session Data\n",
    "avg_practice_times.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7d386d6e",
   "metadata": {},
   "source": [
    "### 3.3 Map Drivers and Races"
   ]
  },
  {
   "cell_type": "code",
   "id": "3f38099e",
   "metadata": {},
   "source": [
    "# Standardize Driver Codes and Names in Drivers DataFrame\n",
    "drivers['code'] = drivers['code'].str.upper()\n",
    "drivers['driver_name'] = drivers['forename'] + ' ' + drivers['surname']\n",
    "drivers['driver_name_standardized'] = drivers['driver_name'].apply(standardize_driver_name)\n",
    "\n",
    "# Create Mappings for Drivers\n",
    "code_to_id = drivers.set_index('code')['driverId'].to_dict()\n",
    "name_to_id = drivers.set_index('driver_name_standardized')['driverId'].to_dict()\n",
    "\n",
    "# Map driverId using Driver Codes\n",
    "avg_practice_times['driverId'] = avg_practice_times['Driver'].map(code_to_id)\n",
    "\n",
    "# For Missing driverIds, Map Using Standardized Names\n",
    "avg_practice_times.loc[avg_practice_times['driverId'].isna(), 'driverId'] = avg_practice_times.loc[\n",
    "    avg_practice_times['driverId'].isna(), 'Driver'\n",
    "].apply(standardize_driver_name).map(name_to_id)\n",
    "\n",
    "# Check for Missing driverIds\n",
    "missing_driverIds = avg_practice_times[avg_practice_times['driverId'].isna()][['Driver']].drop_duplicates()\n",
    "if not missing_driverIds.empty:\n",
    "    print('Missing driverIds after merging:', missing_driverIds)\n",
    "\n",
    "# Standardize Event Names in Races DataFrame\n",
    "races['standardized_name'] = races['name'].apply(standardize_event_name)\n",
    "races['standardized_name'] = races['standardized_name'].str.lower()\n",
    "\n",
    "# Create Mapping from (year, standardized_name) to raceId\n",
    "races_mapping = races[['raceId', 'year', 'standardized_name']].copy()\n",
    "\n",
    "# Map raceId in avg_practice_times\n",
    "avg_practice_times = avg_practice_times.merge(\n",
    "    races_mapping,\n",
    "    on=['year', 'standardized_name'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Check for Missing raceIds\n",
    "missing_raceIds = avg_practice_times[avg_practice_times['raceId'].isna()][['standardized_name', 'year']].drop_duplicates()\n",
    "if not missing_raceIds.empty:\n",
    "    print('Missing raceIds after merging:', missing_raceIds)\n",
    "\n",
    "# Drop Rows with Missing driverId or raceId\n",
    "avg_practice_times.dropna(subset=['driverId', 'raceId'], inplace=True)\n",
    "\n",
    "# Preview Mapped Practice Session Data\n",
    "avg_practice_times.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1a61fbc6",
   "metadata": {},
   "source": [
    "### 3.4 Pivot Practice Sessions and Merge with Results"
   ]
  },
  {
   "cell_type": "code",
   "id": "3687d575",
   "metadata": {},
   "source": [
    "# Pivot Sessions to Columns\n",
    "avg_practice_times_pivot = avg_practice_times.pivot_table(\n",
    "    index=['driverId', 'raceId'],\n",
    "    columns='session',\n",
    "    values='LapTime_seconds'\n",
    ").reset_index().rename_axis(None, axis=1)\n",
    "\n",
    "# Rename Session Columns if Necessary\n",
    "avg_practice_times_pivot.rename(columns={'FP1': 'FP1_time', 'FP2': 'FP2_time', 'FP3': 'FP3_time'}, inplace=True)\n",
    "\n",
    "# Merge Practice Session Data with Results\n",
    "results = results.merge(avg_practice_times_pivot, on=['driverId', 'raceId'], how='left')\n",
    "\n",
    "# Handle Missing Values\n",
    "results[['FP1_time', 'FP2_time', 'FP3_time']] = results[['FP1_time', 'FP2_time', 'FP3_time']].fillna(results[['FP1_time', 'FP2_time', 'FP3_time']].mean())\n",
    "\n",
    "# Preview Results DataFrame with Practice Times\n",
    "results.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "01f3f515",
   "metadata": {},
   "source": [
    "### 3.5 Preprocess Weather Data and Merge"
   ]
  },
  {
   "cell_type": "code",
   "id": "d2f71c74",
   "metadata": {},
   "source": [
    "# Rename Columns for Consistency\n",
    "weather.rename(columns={'EventName': 'name', 'Year': 'year', 'SessionName': 'session'}, inplace=True)\n",
    "\n",
    "# Standardize Event Names\n",
    "weather['standardized_name'] = weather['name'].apply(standardize_event_name)\n",
    "weather['standardized_name'] = weather['standardized_name'].str.lower()\n",
    "\n",
    "# Aggregate Weather Data\n",
    "weather_features = ['AirTemp', 'Humidity', 'Pressure', 'TrackTemp', 'WindSpeed']\n",
    "weather_avg = weather.groupby(['year', 'standardized_name', 'session'])[weather_features].mean().reset_index()\n",
    "\n",
    "# Add 'session' column to races DataFrame\n",
    "races['session'] = 'Race'  # or 'race' depending on the naming convention\n",
    "\n",
    "# Ensure 'year' is integer\n",
    "races['year'] = races['year'].astype(int)\n",
    "\n",
    "# Merge weather data into races DataFrame\n",
    "races = races.merge(\n",
    "    weather_avg,\n",
    "    on=['year', 'standardized_name', 'session'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Now merge races DataFrame into results\n",
    "results = results.merge(\n",
    "    races[['raceId', 'AirTemp', 'Humidity', 'Pressure', 'TrackTemp', 'WindSpeed']],\n",
    "    on='raceId',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Handle Missing Values\n",
    "results[weather_features] = results[weather_features].fillna(results[weather_features].mean())\n",
    "\n",
    "# Preview Results DataFrame with Weather Data\n",
    "results.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5e4b3e07",
   "metadata": {},
   "source": [
    "### 3.6 Merge and Preprocess Other DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "id": "d69d8860",
   "metadata": {},
   "source": [
    "# Merge Results with Races\n",
    "results = results.merge(\n",
    "    races[['raceId', 'year', 'round', 'circuitId', 'date', 'name', 'standardized_name']],\n",
    "    on='raceId',\n",
    "    how='left',\n",
    "    suffixes=('', '_race')\n",
    ")\n",
    "\n",
    "# Merge with Drivers\n",
    "drivers['dob'] = pd.to_datetime(drivers['dob'], errors='coerce')\n",
    "results = results.merge(\n",
    "    drivers[['driverId', 'driverRef', 'forename', 'surname', 'dob', 'nationality']],\n",
    "    on='driverId',\n",
    "    how='left',\n",
    "    suffixes=('', '_driver')\n",
    ")\n",
    "# Rename columns to avoid duplicates\n",
    "results.rename(columns={\n",
    "    'nationality': 'nationality_driver',\n",
    "    'driverRef': 'driverRef_driver',\n",
    "    'forename': 'forename_driver',\n",
    "    'surname': 'surname_driver',\n",
    "    'dob': 'dob_driver'\n",
    "}, inplace=True)\n",
    "\n",
    "# Merge with Constructors\n",
    "results = results.merge(\n",
    "    constructors[['constructorId', 'name', 'nationality']],\n",
    "    on='constructorId',\n",
    "    how='left',\n",
    "    suffixes=('', '_constructor')\n",
    ")\n",
    "# Rename columns to avoid duplicates\n",
    "results.rename(columns={\n",
    "    'name': 'name_constructor',\n",
    "    'nationality': 'nationality_constructor'\n",
    "}, inplace=True)\n",
    "\n",
    "# Merge with Circuits\n",
    "results = results.merge(\n",
    "    circuits[['circuitId', 'name', 'location', 'country']],\n",
    "    on='circuitId',\n",
    "    how='left',\n",
    "    suffixes=('', '_circuit')\n",
    ")\n",
    "# Rename columns to avoid duplicates\n",
    "results.rename(columns={\n",
    "    'name': 'name_circuit',\n",
    "    'location': 'location_circuit',\n",
    "    'country': 'country_circuit'\n",
    "}, inplace=True)\n",
    "\n",
    "# Merge with Status\n",
    "results = results.merge(status, on='statusId', how='left', suffixes=('', '_status'))\n",
    "\n",
    "# Check for Duplicate Columns\n",
    "duplicate_columns = results.columns[results.columns.duplicated()]\n",
    "if duplicate_columns.any():\n",
    "    print(f\"Duplicate columns in results DataFrame after merges: {duplicate_columns.tolist()}\")\n",
    "else:\n",
    "    print(\"No duplicate columns found in results DataFrame after merges.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e092bb49",
   "metadata": {},
   "source": [
    "### 3.7 Data Cleaning and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "id": "e0b3914f",
   "metadata": {},
   "source": [
    "# Convert Date Columns to Datetime\n",
    "results['date'] = pd.to_datetime(results['date'], errors='coerce')\n",
    "results['dob_driver'] = pd.to_datetime(results['dob_driver'], errors='coerce')\n",
    "\n",
    "# Handle Missing Values in 'position'\n",
    "results['position'] = pd.to_numeric(results['position'], errors='coerce')\n",
    "results['position'] = results['position'].fillna(99).astype(int)\n",
    "\n",
    "# Convert Time Columns to Total Seconds\n",
    "def time_to_seconds(time_str):\n",
    "    if pd.isnull(time_str):\n",
    "        return np.nan\n",
    "    if isinstance(time_str, str) and ':' in time_str:\n",
    "        mins, secs = time_str.split(':')\n",
    "        return int(mins) * 60 + float(secs)\n",
    "    elif isinstance(time_str, (int, float)):\n",
    "        return float(time_str)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "results['fastestLapTime_seconds'] = results['fastestLapTime'].apply(time_to_seconds)\n",
    "\n",
    "# Calculate Driver Age at the Time of Race\n",
    "results['driver_age'] = (results['date'] - results['dob_driver']).dt.days / 365.25\n",
    "\n",
    "# Calculate Cumulative Points Up to Each Race\n",
    "results = results.sort_values(['driverId', 'year', 'round'])\n",
    "results['cumulative_points'] = results.groupby('driverId')['points'].cumsum()\n",
    "\n",
    "# Average Finishing Position\n",
    "driver_performance = results.groupby('driverId')['positionOrder'].mean().reset_index()\n",
    "driver_performance.rename(columns={'positionOrder': 'avg_finish_position'}, inplace=True)\n",
    "\n",
    "# Merge Driver Performance with Results\n",
    "results = results.merge(driver_performance, on='driverId', how='left')\n",
    "\n",
    "# Average Lap Time per Driver\n",
    "lap_times['milliseconds'] = lap_times['milliseconds'].fillna(lap_times['milliseconds'].mean())\n",
    "avg_lap_times = lap_times.groupby('driverId')['milliseconds'].mean().reset_index()\n",
    "avg_lap_times.rename(columns={'milliseconds': 'avg_lap_time_ms'}, inplace=True)\n",
    "\n",
    "# Merge Average Lap Times with Results\n",
    "results = results.merge(avg_lap_times, on='driverId', how='left')\n",
    "\n",
    "# Handle Missing Lap Times\n",
    "results['avg_lap_time_ms'] = results['avg_lap_time_ms'].fillna(results['avg_lap_time_ms'].mean())\n",
    "\n",
    "# Qualifying Position\n",
    "qualifying_positions = qualifying.groupby('driverId')['position'].mean().reset_index()\n",
    "qualifying_positions.rename(columns={'position': 'avg_qualifying_position'}, inplace=True)\n",
    "\n",
    "# Merge Qualifying Positions with Results\n",
    "results = results.merge(qualifying_positions, on='driverId', how='left')\n",
    "\n",
    "# Handle Missing Qualifying Positions\n",
    "results['avg_qualifying_position'] = results['avg_qualifying_position'].fillna(results['avg_qualifying_position'].mean())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d8e4466b",
   "metadata": {},
   "source": [
    "# Preprocess Lap Times in Practice Sessions\n",
    "def preprocess_data(results_data):\n",
    "    def convert_lap_time(time_str):\n",
    "        if pd.isna(time_str):\n",
    "            return np.nan\n",
    "        try:\n",
    "            # Split minutes and the rest\n",
    "            minutes, rest = time_str.split(':')\n",
    "            # Split seconds and milliseconds\n",
    "            seconds, milliseconds = rest.split('.')\n",
    "            \n",
    "            total_seconds = (int(minutes) * 60 + \n",
    "                           int(seconds) + \n",
    "                           int(milliseconds) / 1000)\n",
    "            return total_seconds\n",
    "        except (ValueError, AttributeError):\n",
    "            return np.nan\n",
    "    \n",
    "    # Convert lap times to seconds using the custom function\n",
    "    for col in ['fastestLapTime', 'FP1_time', 'FP2_time', 'FP3_time']:\n",
    "        if col in results_data.columns:\n",
    "            results_data[col] = results_data[col].apply(convert_lap_time)\n",
    "    \n",
    "    # Handle missing values\n",
    "    results_data['fastestLapTime'].fillna(results_data['fastestLapTime'].mean(), inplace=True)\n",
    "    results_data['fastestLapSpeed'].fillna(results_data['fastestLapSpeed'].mean(), inplace=True)\n",
    "    \n",
    "    # Fill missing practice times\n",
    "    practice_cols = ['FP1_time', 'FP2_time', 'FP3_time']\n",
    "    results_data[practice_cols] = results_data[practice_cols].fillna(results_data[practice_cols].mean())\n",
    "    \n",
    "    # Convert 'position' to integer and handle invalid values\n",
    "    results_data['position'] = pd.to_numeric(results_data['position'], errors='coerce')\n",
    "    results_data['position'] = results_data['position'].apply(\n",
    "        lambda x: x if pd.isna(x) or (x >= 1 and x <= 20) else np.nan\n",
    "    )\n",
    "    \n",
    "    return results_data"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b77acb5d",
   "metadata": {},
   "source": [
    "### 3.8 Calculate Reliability Metrics"
   ]
  },
  {
   "cell_type": "code",
   "id": "85c7ed3f",
   "metadata": {},
   "source": [
    "# Classify Status Codes into Driver and Constructor Related\n",
    "\n",
    "# Driver-Related Status IDs\n",
    "driver_related_status_ids = [\n",
    "    2,11,12,13,14,15,16,17,18,19,21,28,34,35,40,43,44,48,50,53,54,55,56,58,59,60,61,62,\n",
    "    65,66,67,68,69,71,73,74,75,77,81,82,84,85,86,87,88,89,90,94,95,96,97,98,99,100,101,\n",
    "    103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,123,124,\n",
    "    125,127,130,131,132,133,134,135,136,138,139,141\n",
    "]\n",
    "\n",
    "# Constructor-Related Status IDs\n",
    "constructor_related_status_ids = [\n",
    "    1,3,4,5,6,7,8,9,10,20,22,23,24,25,26,27,29,30,31,32,33,37,38,39,41,42,46,47,49,51,\n",
    "    128,129,130,131,132,133,134,135,136,137,138,140,141\n",
    "]\n",
    "\n",
    "# Calculate Driver Reliability\n",
    "driver_status = results[['driverId', 'statusId']]\n",
    "driver_status['driver_issue'] = driver_status['statusId'].isin(driver_related_status_ids)\n",
    "driver_reliability = driver_status.groupby('driverId')['driver_issue'].apply(lambda x: 1 - x.mean()).reset_index()\n",
    "driver_reliability.rename(columns={'driver_issue': 'driver_reliability'}, inplace=True)\n",
    "\n",
    "# Handle Missing or Extreme Values in Driver Reliability\n",
    "driver_reliability['driver_reliability'] = driver_reliability['driver_reliability'].fillna(driver_reliability['driver_reliability'].mean())\n",
    "driver_reliability['driver_reliability'] = driver_reliability['driver_reliability'].clip(lower=0.5, upper=1.0)\n",
    "\n",
    "# Calculate Constructor Reliability\n",
    "constructor_status = results[['constructorId', 'statusId']]\n",
    "constructor_status['constructor_issue'] = constructor_status['statusId'].isin(constructor_related_status_ids)\n",
    "constructor_reliability = constructor_status.groupby('constructorId')['constructor_issue'].apply(lambda x: 1 - x.mean()).reset_index()\n",
    "constructor_reliability.rename(columns={'constructor_issue': 'constructor_reliability'}, inplace=True)\n",
    "\n",
    "# Handle Missing or Extreme Values in Constructor Reliability\n",
    "constructor_reliability['constructor_reliability'] = constructor_reliability['constructor_reliability'].fillna(constructor_reliability['constructor_reliability'].mean())\n",
    "constructor_reliability['constructor_reliability'] = constructor_reliability['constructor_reliability'].clip(lower=0.5, upper=1.0)\n",
    "\n",
    "# Merge Reliability Metrics with Results\n",
    "results = results.merge(driver_reliability, on='driverId', how='left')\n",
    "results = results.merge(constructor_reliability, on='constructorId', how='left')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4736e8f1",
   "metadata": {},
   "source": [
    "### 3.9 Calculate Circuit-Specific Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "id": "a4670e20",
   "metadata": {},
   "source": [
    "# Calculate Driver's Average Finish Position at Each Circuit\n",
    "circuit_performance = results.groupby(['driverId', 'circuitId'])['positionOrder'].mean().reset_index()\n",
    "circuit_performance.rename(columns={'positionOrder': 'avg_finish_position_circuit'}, inplace=True)\n",
    "\n",
    "# Merge Circuit Performance with Results\n",
    "results = results.merge(circuit_performance, on=['driverId', 'circuitId'], how='left')\n",
    "\n",
    "# Calculate Driver's Average Lap Time at Each Circuit\n",
    "lap_times = lap_times.merge(results[['raceId', 'circuitId']], on='raceId', how='left')\n",
    "avg_lap_times_circuit = lap_times.groupby(['driverId', 'circuitId'])['milliseconds'].mean().reset_index()\n",
    "avg_lap_times_circuit.rename(columns={'milliseconds': 'avg_lap_time_ms_circuit'}, inplace=True)\n",
    "\n",
    "# Merge Circuit Lap Times with Results\n",
    "results = results.merge(avg_lap_times_circuit, on=['driverId', 'circuitId'], how='left')\n",
    "\n",
    "# Handle Missing Values\n",
    "results['avg_finish_position_circuit'] = results['avg_finish_position_circuit'].fillna(results['avg_finish_position'])\n",
    "results['avg_lap_time_ms_circuit'] = results['avg_lap_time_ms_circuit'].fillna(results['avg_lap_time_ms'])\n",
    "\n",
    "# Handle Zero or NaN in avg_finish_position_circuit\n",
    "results['avg_finish_position_circuit'] = results['avg_finish_position_circuit'].replace(0, np.nan)\n",
    "results['avg_finish_position_circuit'] = results['avg_finish_position_circuit'].fillna(results['avg_finish_position'].mean())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "23a13149",
   "metadata": {},
   "source": [
    "### 3.10 Prepare Data for Agent Initialization"
   ]
  },
  {
   "cell_type": "code",
   "id": "b7c7d606",
   "metadata": {},
   "source": [
    "# Prepare a DataFrame with data for the specified race\n",
    "# (We'll specify the raceId later in the simulation parameters)\n",
    "def get_race_drivers_data(specified_raceId):\n",
    "    specified_race_results = results[results['raceId'] == specified_raceId]\n",
    "    return preprocess_data(specified_race_results)\n",
    "\n",
    "# Create a Dictionary for Driver Names\n",
    "drivers['driver_name'] = drivers['forename'] + ' ' + drivers['surname']\n",
    "driver_mapping = drivers[['driverId', 'driver_name']].copy()\n",
    "driver_mapping.set_index('driverId', inplace=True)\n",
    "driver_names = driver_mapping['driver_name'].to_dict()\n",
    "\n",
    "def calculate_aggression(driver_results):\n",
    "    if len(driver_results) == 0:\n",
    "        return 0.5  # Default aggression for new drivers\n",
    "    \n",
    "    # Only consider recent races for more current behavior\n",
    "    recent_results = driver_results.sort_values('date', ascending=False).head(20)\n",
    "    \n",
    "    # Calculate overtaking metrics\n",
    "    positions_gained = recent_results['grid'] - recent_results['positionOrder']\n",
    "    \n",
    "    # Calculate risk metrics\n",
    "    dnf_rate = (recent_results['status'] != 'Finished').mean()\n",
    "    incidents = (recent_results['statusId'].isin([\n",
    "        4,  # Collision\n",
    "        5,  # Spun off\n",
    "        6,  # Accident\n",
    "        20, # Collision damage\n",
    "        82, # Collision with another driver\n",
    "    ])).mean()\n",
    "    \n",
    "    # Calculate overtaking success rate (normalized between 0-1)\n",
    "    positive_overtakes = (positions_gained > 0).sum()\n",
    "    negative_overtakes = (positions_gained < 0).sum()\n",
    "    total_overtake_attempts = positive_overtakes + negative_overtakes\n",
    "    overtake_success_rate = positive_overtakes / total_overtake_attempts if total_overtake_attempts > 0 else 0.5\n",
    "    \n",
    "    # Normalize average positions gained (0-1)\n",
    "    avg_positions_gained = positions_gained[positions_gained > 0].mean() if len(positions_gained[positions_gained > 0]) > 0 else 0\n",
    "    max_possible_gain = 20  # Maximum grid positions that could be gained\n",
    "    normalized_gains = np.clip(avg_positions_gained / max_possible_gain, 0, 1)\n",
    "    \n",
    "    # Normalize risk factors (0-1)\n",
    "    normalized_dnf = np.clip(dnf_rate, 0, 1)\n",
    "    normalized_incidents = np.clip(incidents, 0, 1)\n",
    "    \n",
    "    # Calculate component scores (each between 0-1)\n",
    "    overtaking_component = (normalized_gains * 0.6 + overtake_success_rate * 0.4)\n",
    "    risk_component = (normalized_dnf * 0.5 + normalized_incidents * 0.5)\n",
    "    \n",
    "    # Combine components with weights (ensuring sum of weights = 1)\n",
    "    weights = {\n",
    "        'overtaking': 0.4,  # Aggressive overtaking\n",
    "        'risk': 0.5,       # Risk-taking behavior\n",
    "        'baseline': 0.1    # Baseline aggression\n",
    "    }\n",
    "    \n",
    "    aggression = (\n",
    "        overtaking_component * weights['overtaking'] +\n",
    "        risk_component * weights['risk'] +\n",
    "        0.5 * weights['baseline']  # Baseline aggression factor\n",
    "    )\n",
    "    \n",
    "    # Add small random variation while maintaining 0-1 bounds\n",
    "    variation = np.random.normal(0, 0.02)\n",
    "    aggression = np.clip(aggression + variation, 0, 1)\n",
    "    \n",
    "    # Log calculation components\n",
    "    print(f\"\\nAggression Calculation Components for Driver {recent_results['driverId'].iloc[0]}:\")\n",
    "    print(f\"Normalized Positions Gained: {normalized_gains:.3f}\")\n",
    "    print(f\"Overtake Success Rate: {overtake_success_rate:.3f}\")\n",
    "    print(f\"Normalized DNF Rate: {normalized_dnf:.3f}\")\n",
    "    print(f\"Normalized Incident Rate: {normalized_incidents:.3f}\")\n",
    "    print(f\"Overtaking Component: {overtaking_component:.3f}\")\n",
    "    print(f\"Risk Component: {risk_component:.3f}\")\n",
    "    print(f\"Final Aggression Score: {aggression:.3f}\")\n",
    "    \n",
    "    return aggression\n",
    "\n",
    "# Example interpretation of aggression scores:\n",
    "# 0.0-0.2: Very conservative driver\n",
    "# 0.2-0.4: Conservative driver\n",
    "# 0.4-0.6: Balanced driver\n",
    "# 0.6-0.8: Aggressive driver\n",
    "# 0.8-1.0: Very aggressive driver\n",
    "\n",
    "def calculate_skill(driver_data, results_data, circuit_id):\n",
    "    driver_results = results_data[\n",
    "        (results_data['driverId'] == driver_data['driverId']) & \n",
    "        (results_data['circuitId'] == circuit_id)\n",
    "    ].sort_values('date', ascending=False).head(10)  # Use last 10 races at circuit\n",
    "    \n",
    "    if len(driver_results) == 0:\n",
    "        return 0.5  # Default skill\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    avg_finish_pos = driver_results['positionOrder'].mean()\n",
    "    avg_quali_pos = driver_results['grid'].mean()\n",
    "    points_per_race = driver_results['points'].mean()\n",
    "    fastest_laps = (driver_results['rank'] == 1).mean()  # Add fastest lap consideration\n",
    "    \n",
    "    # Improved normalization (exponential decay for positions)\n",
    "    normalized_finish_pos = np.exp(-avg_finish_pos/5) # Better spread of values\n",
    "    normalized_quali_pos = np.exp(-avg_quali_pos/5)\n",
    "    \n",
    "    # Points normalization with improved scaling\n",
    "    max_points_per_race = 26  # Maximum possible points (25 + 1 fastest lap)\n",
    "    normalized_points = points_per_race / max_points_per_race\n",
    "    \n",
    "    # Weighted combination with more factors\n",
    "    weights = {\n",
    "        'finish': 0.35,\n",
    "        'quali': 0.25,\n",
    "        'points': 0.25,\n",
    "        'fastest_laps': 0.15\n",
    "    }\n",
    "    \n",
    "    skill = (\n",
    "        weights['finish'] * normalized_finish_pos +\n",
    "        weights['quali'] * normalized_quali_pos +\n",
    "        weights['points'] * normalized_points +\n",
    "        weights['fastest_laps'] * fastest_laps\n",
    "    )\n",
    "    \n",
    "    # Add random variation to prevent identical skills\n",
    "    skill = np.clip(skill + np.random.normal(0, 0.05), 0.1, 1.0)\n",
    "    \n",
    "    return skill"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d0a132fa",
   "metadata": {},
   "source": [
    "## 4. Define Function to Initialize Agents with Specified Conditions"
   ]
  },
  {
   "cell_type": "code",
   "id": "6eeb63a0",
   "metadata": {},
   "source": [
    "# Function to Initialize Agents\n",
    "def initialize_agents(race_data, weather_conditions, fp_times):\n",
    "    driver_agents = []\n",
    "    \n",
    "    # Calculate default aggression across all drivers\n",
    "    all_drivers_aggression = []\n",
    "    for driver_id in race_data['driverId'].unique():\n",
    "        driver_results = results[(results['driverId'] == driver_id) & (results['grid'].notnull()) & (results['positionOrder'].notnull())]\n",
    "        driver_results = driver_results.sort_values('date', ascending=False).head(20)\n",
    "        aggression = calculate_aggression(driver_results)\n",
    "        if aggression is not None:\n",
    "            all_drivers_aggression.append(aggression)\n",
    "    default_aggression = np.mean(all_drivers_aggression) if all_drivers_aggression else 0.5\n",
    "    \n",
    "    for idx, driver_data in race_data.iterrows():\n",
    "        driverId = driver_data['driverId']\n",
    "        circuitId = driver_data['circuitId']\n",
    "        # Handle NaN or zero in avg_finish_position_circuit\n",
    "        avg_finish_pos_circuit = driver_data['avg_finish_position_circuit']\n",
    "        if pd.isnull(avg_finish_pos_circuit) or avg_finish_pos_circuit == 0:\n",
    "            avg_finish_pos_circuit = driver_data['avg_finish_position']\n",
    "            \n",
    "        # Calculate skill using the new function\n",
    "        skill = calculate_skill(driver_data, results, circuitId)\n",
    "        \n",
    "        if skill is None:\n",
    "            # If the driver has no data for the circuit, use a default skill value\n",
    "            skill = 0.5\n",
    "        \n",
    "        # Calculate aggression based on the last 20 races\n",
    "        driver_results = results[(results['driverId'] == driverId) & (results['grid'].notnull()) & (results['positionOrder'].notnull())]\n",
    "        driver_results = driver_results.sort_values('date', ascending=False).head(20)\n",
    "        aggression = calculate_aggression(driver_results)\n",
    "        \n",
    "        # If the driver has no race history, use the default aggression\n",
    "        if aggression is None:\n",
    "            aggression = default_aggression\n",
    "            \n",
    "        # Reliability: From calculated reliability metric\n",
    "        reliability = driver_data['driver_reliability']\n",
    "        # Cap reliability to reasonable bounds\n",
    "        reliability = np.clip(reliability, 0.5, 1.0)\n",
    "        # Practice Performance: From provided FP1-3 times\n",
    "        practice_performance = fp_times.get(driverId, driver_data['avg_lap_time_ms_circuit'])\n",
    "        # Adjust practice performance based on weather conditions\n",
    "        weather_factor = 1.0  # Placeholder for weather impact\n",
    "        if weather_conditions == 'wet':\n",
    "            weather_factor = 1.05\n",
    "        elif weather_conditions == 'hot':\n",
    "            weather_factor = 0.98\n",
    "        practice_performance *= weather_factor\n",
    "        agent = DriverAgent(driverId, skill, aggression, reliability, practice_performance)\n",
    "        driver_agents.append(agent)\n",
    "        \n",
    "        # Add logging here\n",
    "        driver_name = driver_names.get(driverId, f\"Driver {driverId}\")\n",
    "        print(f\"Initialized {driver_name}: Skill={skill:.2f}, Aggression={aggression:.2f}, Reliability={reliability:.2f}, PracticePerformance={practice_performance:.2f}\")\n",
    "    \n",
    "    return driver_agents"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a0ba61ff",
   "metadata": {},
   "source": [
    "## 5. Define DriverAgent Class with Circuit and Weather Influence"
   ]
  },
  {
   "cell_type": "code",
   "id": "8e3f0dd5",
   "metadata": {},
   "source": [
    "class DriverAgent:\n",
    "    def __init__(self, driverId, skill, aggression, reliability, practice_performance):\n",
    "        self.driverId = driverId\n",
    "        self.skill = skill\n",
    "        self.aggression = aggression\n",
    "        self.reliability = reliability\n",
    "        self.practice_performance = practice_performance\n",
    "        self.total_time_ms = 0\n",
    "        self.position = None\n",
    "        self.status = 'Running'\n",
    "        self.consecutive_mistakes = 0\n",
    "        self.tire_wear = 1.0\n",
    "        self.laps_completed = 0\n",
    "        \n",
    "    def simulate_lap(self, base_lap_time, current_lap, total_laps):\n",
    "        # More significant skill impact (up to 15% difference)\n",
    "        skill_adjustment = 1 - (self.skill * 0.15)\n",
    "        \n",
    "        # Progressive tire wear effect\n",
    "        self.tire_wear = 1.0 + (current_lap / total_laps) * 0.2 * (1 - self.skill)\n",
    "        \n",
    "        # Larger standard deviation for more variation\n",
    "        base_std_dev = base_lap_time * 0.03  # 3% base variation\n",
    "        \n",
    "        # Aggression affects both performance and mistakes\n",
    "        aggression_factor = 1.0\n",
    "        if self.aggression > 0.7:  # High aggression\n",
    "            aggression_factor = 0.98  # Faster but...\n",
    "            mistake_chance = self.aggression * (1 - self.skill) * 0.1\n",
    "            if random.random() < mistake_chance:\n",
    "                self.consecutive_mistakes += 1\n",
    "                aggression_factor = 1.1  # Major mistake\n",
    "        else:\n",
    "            self.consecutive_mistakes = max(0, self.consecutive_mistakes - 1)\n",
    "        \n",
    "        # Calculate final lap time with all factors\n",
    "        mean_lap_time = (\n",
    "            base_lap_time * \n",
    "            skill_adjustment * \n",
    "            aggression_factor * \n",
    "            self.tire_wear\n",
    "        )\n",
    "        \n",
    "        # More variation for midfield and backmarkers\n",
    "        std_dev = base_std_dev * (2 - self.skill)\n",
    "        \n",
    "        lap_time = np.random.normal(mean_lap_time, std_dev)\n",
    "        \n",
    "        # Ensure realistic limits\n",
    "        min_possible = base_lap_time * 0.95\n",
    "        max_possible = base_lap_time * 1.5\n",
    "        lap_time = np.clip(lap_time, min_possible, max_possible)\n",
    "        \n",
    "        self.total_time_ms += lap_time\n",
    "        \n",
    "        # Adjusted reliability risk calculation\n",
    "        reliability_risk = (\n",
    "            (1 - self.reliability) ** 2 *\n",
    "            (current_lap / total_laps) ** 0.5 *\n",
    "            (1 + self.consecutive_mistakes * 0.5)\n",
    "        )\n",
    "    \n",
    "        # Cap the reliability risk\n",
    "        reliability_risk = min(reliability_risk, 0.2)\n",
    "    \n",
    "        if random.random() < reliability_risk:\n",
    "            self.status = 'Retired'\n",
    "            self.laps_completed = current_lap  # Track laps completed upon retirement\n",
    "            \n",
    "        if self.status == 'Running':\n",
    "            self.laps_completed += 1\n",
    "            \n",
    "        # Add logging for lap time components\n",
    "        print(f\"Driver {self.driverId} Lap {current_lap}:\")\n",
    "        print(f\"  Base Lap Time: {base_lap_time:.2f}\")\n",
    "        print(f\"  Skill Adjustment: {skill_adjustment:.2f}\")\n",
    "        print(f\"  Aggression Factor: {aggression_factor:.2f}\")\n",
    "        print(f\"  Tire Wear: {self.tire_wear:.2f}\")\n",
    "        print(f\"  Mean Lap Time: {mean_lap_time:.2f}\")\n",
    "        print(f\"  Lap Time: {lap_time:.2f}\")\n",
    "        print(f\"  Total Time: {self.total_time_ms:.2f}\")\n",
    "        print(f\"  Reliability Risk: {reliability_risk:.4f}\")\n",
    "        print(f\"  Status: {self.status}\")\n",
    "        return lap_time"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b89809ac",
   "metadata": {},
   "source": [
    "## 6. Simulate Race with Specified Conditions"
   ]
  },
  {
   "cell_type": "code",
   "id": "ab4d0988",
   "metadata": {},
   "source": [
    "def simulate_race(driver_agents, n_laps, weather_conditions):\n",
    "    # Calculate more realistic base lap times\n",
    "    for agent in driver_agents:\n",
    "        if not np.isnan(agent.practice_performance):\n",
    "            base_time = agent.practice_performance\n",
    "        else:\n",
    "            # Use performance relative to the fastest practice time\n",
    "            fastest_practice = min(a.practice_performance for a in driver_agents \n",
    "                                if not np.isnan(a.practice_performance))\n",
    "            base_time = fastest_practice * (1 + (1 - agent.skill) * 0.2)\n",
    "        \n",
    "        # Apply weather effects\n",
    "        weather_impact = {\n",
    "            'dry': 1.0,\n",
    "            'wet': 1.1 + (1 - agent.skill) * 0.1,  # Less skilled drivers struggle more in wet\n",
    "            'hot': 1.02 + (1 - agent.reliability) * 0.05  # Less reliable cars struggle more in heat\n",
    "        }\n",
    "        agent.base_lap_time = base_time * weather_impact.get(weather_conditions, 1.0)\n",
    "    \n",
    "    # Simulate each lap with position battles\n",
    "    for lap in range(1, n_laps + 1):\n",
    "        # Update running order each lap\n",
    "        running_agents = [a for a in driver_agents if a.status == 'Running']\n",
    "        running_agents.sort(key=lambda x: x.total_time_ms)\n",
    "        \n",
    "        for i, agent in enumerate(running_agents):\n",
    "            # Adjust base time based on position (slipstream effect)\n",
    "            position_factor = 1.0\n",
    "            if i > 0:  # Not leading\n",
    "                gap_to_front = (agent.total_time_ms - running_agents[i-1].total_time_ms)\n",
    "                if 500 < gap_to_front < 2000:  # In slipstream range\n",
    "                    position_factor = 0.995\n",
    "            \n",
    "            # Simulate lap with current race conditions\n",
    "            agent.simulate_lap(agent.base_lap_time * position_factor, lap, n_laps)\n",
    "    \n",
    "    # Final classification\n",
    "    finished_drivers = [a for a in driver_agents if a.status == 'Running']\n",
    "    retired_drivers = [a for a in driver_agents if a.status == 'Retired']\n",
    "\n",
    "    # Sort finished drivers by total time\n",
    "    finished_drivers.sort(key=lambda x: x.total_time_ms)\n",
    "    for pos, agent in enumerate(finished_drivers, 1):\n",
    "        agent.position = pos\n",
    "\n",
    "    # Sort retired drivers by laps completed and total time\n",
    "    retired_drivers.sort(key=lambda x: (-x.laps_completed, x.total_time_ms))\n",
    "    for idx, agent in enumerate(retired_drivers, start=len(finished_drivers) + 1):\n",
    "        agent.position = idx\n",
    "\n",
    "    # Combine all drivers for final results\n",
    "    all_drivers = finished_drivers + retired_drivers\n",
    "\n",
    "    return all_drivers"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3a8fef85",
   "metadata": {},
   "source": [
    "## 7. Run Monte Carlo Simulation with Specified Inputs"
   ]
  },
  {
   "cell_type": "code",
   "id": "1f3d6cd7",
   "metadata": {},
   "source": [
    "# Simulation Parameters\n",
    "n_simulations = 10000  # Adjust as needed\n",
    "n_laps = 50  # Placeholder for number of laps\n",
    "\n",
    "# Specify Race, Weather, and FP1-3 Data\n",
    "specified_raceId = 1000  # Example raceId (should be a valid raceId from your dataset)\n",
    "specified_weather = 'dry'  # Options: 'dry', 'wet', 'hot'\n",
    "\n",
    "# Get Race Data for the Specified Race\n",
    "race_data = get_race_drivers_data(specified_raceId)\n",
    "\n",
    "if race_data.empty:\n",
    "    print(f\"No data found for raceId {specified_raceId}. Please choose a valid raceId.\")\n",
    "else:\n",
    "    # Example FP1-3 times (this should be provided as input)\n",
    "    fp_times_example = {}\n",
    "\n",
    "    # Assume we have practice times for the specified race\n",
    "    practice_times_race = avg_practice_times_pivot[avg_practice_times_pivot['raceId'] == specified_raceId]\n",
    "    for idx, row in practice_times_race.iterrows():\n",
    "        driverId = row['driverId']\n",
    "        practice_times = [row.get('FP1_time', np.nan), row.get('FP2_time', np.nan), row.get('FP3_time', np.nan)]\n",
    "        practice_times = [pt for pt in practice_times if not np.isnan(pt)]\n",
    "        if practice_times:\n",
    "            fp_times_example[driverId] = np.mean(practice_times)\n",
    "        else:\n",
    "            # If no practice times, use average lap time at circuit\n",
    "            driver_data = race_data[race_data['driverId'] == driverId].iloc[0]\n",
    "            fp_times_example[driverId] = driver_data['avg_lap_time_ms_circuit']\n",
    "\n",
    "    # Initialize Agents\n",
    "    driver_agents_init = initialize_agents(race_data, specified_weather, fp_times_example)\n",
    "\n",
    "    # Run Simulations\n",
    "    simulation_results = []\n",
    "\n",
    "    for sim in tqdm(range(n_simulations)):\n",
    "        # Deep copy of agents\n",
    "        agents = [DriverAgent(agent.driverId, agent.skill, agent.aggression, agent.reliability, agent.practice_performance) for agent in driver_agents_init]\n",
    "        # Simulate Race\n",
    "        agents = simulate_race(agents, n_laps, specified_weather)\n",
    "        # Collect results\n",
    "        sim_result = {agent.driverId: agent.position for agent in agents}\n",
    "        simulation_results.append(sim_result)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9e6e4e1a",
   "metadata": {},
   "source": [
    "# Print Driver Agents\n",
    "print(\"Driver Agents:\")\n",
    "for agent in driver_agents_init:\n",
    "    driver_name = driver_names.get(agent.driverId, f\"Driver {agent.driverId}\")\n",
    "    print(f\"{driver_name}: Skill={agent.skill:.2f}, Aggression={agent.aggression:.2f}, Reliability={agent.reliability:.2f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b532d4c0",
   "metadata": {},
   "source": [
    "## 8. Aggregate Simulation Results"
   ]
  },
  {
   "cell_type": "code",
   "id": "ba7236a3",
   "metadata": {},
   "source": [
    "# Aggregate Results into a DataFrame\n",
    "if race_data.empty:\n",
    "    print(\"Simulation was not run due to lack of race data.\")\n",
    "else:\n",
    "    sim_df = pd.DataFrame(simulation_results)\n",
    "\n",
    "    # Calculate Probabilities of Finishing Positions\n",
    "    position_probs = sim_df.apply(lambda x: x.value_counts(normalize=True)).fillna(0) * 100\n",
    "    position_probs = position_probs.transpose()\n",
    "\n",
    "    # Prepare Data for Visualization\n",
    "    position_probs.reset_index(inplace=True)\n",
    "    position_probs.rename(columns={'index': 'driverId'}, inplace=True)\n",
    "\n",
    "    # Merge with Driver Names\n",
    "    position_probs['driver_name'] = position_probs['driverId'].map(driver_names)\n",
    "\n",
    "    # Sort by Expected Finishing Position\n",
    "    expected_positions = sim_df.mean().sort_values()\n",
    "    position_probs['expected_position'] = position_probs['driverId'].map(expected_positions)\n",
    "    position_probs.sort_values('expected_position', inplace=True)\n",
    "\n",
    "    # Merge Actual Positions\n",
    "    actual_positions = race_data[['driverId', 'positionOrder']].drop_duplicates()\n",
    "    position_probs = position_probs.merge(actual_positions, on='driverId', how='left')\n",
    "\n",
    "    # Display Probabilities\n",
    "    position_probs.fillna(0, inplace=True)\n",
    "    #display(position_probs.head(20))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bf8253d0",
   "metadata": {},
   "source": [
    "## 9. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "id": "f36f21fb",
   "metadata": {},
   "source": [
    "# Plot Probability Distribution of Finishing Positions\n",
    "if race_data.empty:\n",
    "    print(\"Visualization skipped due to lack of simulation results.\")\n",
    "else:\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    positions = list(range(1, len(race_data['driverId'].unique()) + 2))  # Positions up to number of drivers + 1\n",
    "\n",
    "    for idx, row in position_probs.iterrows():\n",
    "        probabilities = [row.get(pos, 0) for pos in positions]\n",
    "        ax.plot(positions, probabilities, label=row['driver_name'])\n",
    "\n",
    "    ax.set_xlabel('Finishing Position')\n",
    "    ax.set_ylabel('Probability (%)')\n",
    "    ax.set_title('Probability Distribution of Finishing Positions')\n",
    "    ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.05))\n",
    "    plt.show()\n",
    "\n",
    "# Plot Predicted vs Actual Positions\n",
    "if race_data.empty:\n",
    "    print(\"Visualization skipped due to lack of simulation results.\")\n",
    "else:\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Expected positions from simulations\n",
    "    position_probs['predicted_position'] = position_probs['expected_position']\n",
    "    \n",
    "    # Actual positions from race data\n",
    "    position_probs['actual_position'] = position_probs['positionOrder']\n",
    "    \n",
    "    # Remove drivers without actual positions\n",
    "    comparison_df = position_probs.dropna(subset=['actual_position'])\n",
    "    \n",
    "    # Plot\n",
    "    ax.scatter(comparison_df['actual_position'], comparison_df['predicted_position'], c='blue')\n",
    "    \n",
    "    # Add labels\n",
    "    for idx, row in comparison_df.iterrows():\n",
    "        ax.text(row['actual_position'], row['predicted_position'], row['driver_name'])\n",
    "    \n",
    "    ax.set_xlabel('Actual Position')\n",
    "    ax.set_ylabel('Predicted Position (Average)')\n",
    "    ax.set_title('Predicted vs Actual Finishing Positions')\n",
    "    ax.plot([1, 20], [1, 20], 'r--')  # Diagonal line\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error\n",
    "\n",
    "def calculate_prediction_metrics(position_probs):\n",
    "    # Prepare comparison dataframe\n",
    "    comparison_df = position_probs.copy()\n",
    "    comparison_df['predicted_position'] = comparison_df['expected_position']\n",
    "    comparison_df['actual_position'] = comparison_df['positionOrder']\n",
    "    comparison_df = comparison_df.dropna(subset=['actual_position'])\n",
    "    \n",
    "    # Calculate absolute errors for each prediction\n",
    "    comparison_df['abs_error'] = abs(comparison_df['predicted_position'] - comparison_df['actual_position'])\n",
    "    \n",
    "    # Sort by absolute error\n",
    "    comparison_df = comparison_df.sort_values('abs_error')\n",
    "    \n",
    "    # Remove 2 closest and 2 farthest predictions\n",
    "    trimmed_df = comparison_df.iloc[2:-2]\n",
    "    \n",
    "    # Calculate metrics on trimmed data\n",
    "    y_true = trimmed_df['actual_position'].values\n",
    "    y_pred = trimmed_df['predicted_position'].values\n",
    "    \n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = root_mean_squared_error(y_true, y_pred)\n",
    "    \n",
    "    # Print detailed metrics\n",
    "    print(\"\\nPrediction Metrics (excluding 2 closest and 2 farthest predictions):\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.2f} positions\")\n",
    "    print(f\"Root Mean Square Error (RMSE): {rmse:.2f} positions\")\n",
    "    \n",
    "    # Print excluded predictions\n",
    "    print(\"\\nExcluded Closest Predictions:\")\n",
    "    for _, row in comparison_df.head(2).iterrows():\n",
    "        print(f\"{row['driver_name']}: Predicted {row['predicted_position']:.1f}, Actual {row['actual_position']}, Error {row['abs_error']:.1f}\")\n",
    "    \n",
    "    print(\"\\nExcluded Farthest Predictions:\")\n",
    "    for _, row in comparison_df.tail(2).iterrows():\n",
    "        print(f\"{row['driver_name']}: Predicted {row['predicted_position']:.1f}, Actual {row['actual_position']}, Error {row['abs_error']:.1f}\")\n",
    "    \n",
    "    return mae, rmse, trimmed_df\n",
    "\n",
    "# Usage\n",
    "mae, rmse, trimmed_results = calculate_prediction_metrics(position_probs)"
   ],
   "id": "94b58916a00f99a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6e870ac5",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "\n",
    "In this enhanced notebook, we've:\n",
    "\n",
    "- **Adjusted Skill and Aggression Calculations**: Ensured values are normalized and scaled appropriately to prevent unrealistic simulation outcomes.\n",
    "- **Modified Lap Time Simulation**: Adjusted the lap time calculation to incorporate skill and aggression in a way that introduces realistic variability.\n",
    "- **Handled NaN and Zero Values**: Implemented checks and default values for skill and reliability to prevent unrealistic simulation results.\n",
    "- **Capped Attribute Values**: Set reasonable bounds for skill and reliability to avoid extreme lap times and excessive retirements.\n",
    "- **Included Only Participating Drivers**: Adjusted the code to include only the drivers who are actually participating in the specified race.\n",
    "- **Ran Monte Carlo Simulations**: Simulated multiple races under the specified conditions to predict possible outcomes.\n",
    "- **Visualized Results**: Plotted probability distributions of finishing positions and compared predicted positions with actual race results.\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "- **Integrate Live Data Feeds**: Implement functions to update agent attributes with live data during practice or qualifying sessions.\n",
    "- **Enhance Weather Modeling**: Incorporate more sophisticated weather impact models based on historical performance in various conditions.\n",
    "- **Expand Feature Set**: Include additional factors such as tire choices, pit stop strategies, and driver form trends.\n",
    "- **Improve Agent Modeling**: Utilize machine learning models to predict agent performance more accurately based on historical data.\n",
    "\n",
    "By addressing the issues in the simulation and adding comparative visualizations, our race predictor now provides more realistic and insightful predictions of race outcomes."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load your predefined train and test splits\n",
    "train_split = pd.read_csv('train_split.csv')  # Contains 'raceId', 'driverId', 'positionOrder'\n",
    "test_split = pd.read_csv('test_split.csv')\n"
   ],
   "id": "f6e71e8eaeaf5d66",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Ensure 'results' DataFrame is already available from your existing code\n",
    "\n",
    "# Training data\n",
    "training_results = results[results['raceId'].isin(train_split['raceId'])].copy()\n",
    "\n",
    "# Test data\n",
    "test_results = results[results['raceId'].isin(test_split['raceId'])].copy()\n"
   ],
   "id": "5d64dbb815cebafb",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
