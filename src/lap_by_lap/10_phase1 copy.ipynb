{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Phase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Phase 1\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "from dataclasses import dataclass, field\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import os\n",
    "\n",
    "# Define the RaceFeatures dataclass\n",
    "@dataclass\n",
    "class RaceFeatures:\n",
    "    \"\"\"Data structure for race features\"\"\"\n",
    "    static_features: List[str] = field(default_factory=lambda: [\n",
    "        # Existing static features\n",
    "        'driver_overall_skill', 'driver_circuit_skill', 'driver_consistency',\n",
    "        'driver_reliability', 'driver_aggression', 'driver_risk_taking',\n",
    "        'fp1_median_time', 'fp2_median_time', 'fp3_median_time', 'quali_time',\n",
    "        # New static feature\n",
    "        'constructor_performance',\n",
    "        # Add 'circuitId' as a static feature\n",
    "        'circuitId'\n",
    "    ])\n",
    "    \n",
    "    dynamic_features: List[str] = field(default_factory=lambda: [\n",
    "        # Existing dynamic features\n",
    "        'tire_age', 'fuel_load', 'track_position', 'track_temp',\n",
    "        'air_temp', 'humidity', 'tire_compound', 'TrackStatus', 'is_pit_lap',\n",
    "    ])\n",
    "    \n",
    "    target: str = 'milliseconds'\n",
    "\n",
    "# Define the F1Dataset class\n",
    "class F1Dataset(Dataset):\n",
    "    def __init__(self, sequences, static_features, targets):\n",
    "        self.sequences = torch.FloatTensor(sequences)\n",
    "        self.static_features = torch.FloatTensor(static_features)\n",
    "        self.targets = torch.FloatTensor(targets)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'sequence': self.sequences[idx],\n",
    "            'static': self.static_features[idx],\n",
    "            'target': self.targets[idx]\n",
    "        }\n",
    "\n",
    "# Define the F1DataPreprocessor class\n",
    "class F1DataPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.static_scaler = StandardScaler()\n",
    "        self.dynamic_scaler = StandardScaler()\n",
    "        self.lap_time_scaler = StandardScaler()\n",
    "        self.race_features = RaceFeatures()\n",
    "\n",
    "    def prepare_sequence_data(self, df: pd.DataFrame, window_size: int = 3) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Prepare sequential data with sliding window without applying scaling.\n",
    "        \"\"\"\n",
    "        sequences = []\n",
    "        static_features = []\n",
    "        targets = []\n",
    "        \n",
    "        # Sort the dataframe to ensure consistent ordering\n",
    "        df = df.sort_values(['raceId', 'driverId', 'lap'])\n",
    "        \n",
    "        # Group by race and driver\n",
    "        for (race_id, driver_id), group in df.groupby(['raceId', 'driverId']):\n",
    "            group = group.sort_values('lap')\n",
    "            \n",
    "            # Extract static features (assumed to be constant per driver per race)\n",
    "            static = group[self.race_features.static_features].iloc[0].values\n",
    "            \n",
    "            # Extract dynamic features and target\n",
    "            lap_times = group[self.race_features.target].values.reshape(-1, 1)\n",
    "            dynamic = group[self.race_features.dynamic_features].values\n",
    "            \n",
    "            # Create sequences\n",
    "            for i in range(len(lap_times) - window_size):\n",
    "                sequence_lap_times = lap_times[i:i+window_size]\n",
    "                sequence_dynamic = dynamic[i:i+window_size]\n",
    "                sequence = np.hstack((sequence_lap_times, sequence_dynamic))\n",
    "                sequences.append(sequence)\n",
    "                static_features.append(static)\n",
    "                targets.append(lap_times[i + window_size][0])\n",
    "        \n",
    "        return np.array(sequences), np.array(static_features), np.array(targets)\n",
    "\n",
    "\n",
    "class F1PredictionModel(nn.Module):\n",
    "    def __init__(self, sequence_dim, static_dim, hidden_dim=64, num_layers=2, dropout_prob=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        # LSTM for sequential features with dropout\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=sequence_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout_prob\n",
    "        )\n",
    "\n",
    "        # Static features processing with dropout\n",
    "        self.static_network = nn.Sequential(\n",
    "            nn.Linear(static_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob)\n",
    "        )\n",
    "\n",
    "        # Combine everything\n",
    "        self.final_network = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, sequence, static):\n",
    "        # Process sequence through LSTM\n",
    "        lstm_out, _ = self.lstm(sequence)\n",
    "        lstm_out = lstm_out[:, -1, :]  # Output of the last time step\n",
    "\n",
    "        # Process static features directly\n",
    "        static_out = self.static_network(static)\n",
    "\n",
    "        # Combine LSTM output and static features\n",
    "        combined = torch.cat([lstm_out, static_out], dim=1)\n",
    "\n",
    "        # Final prediction\n",
    "        prediction = self.final_network(combined)\n",
    "\n",
    "        return prediction.squeeze()\n",
    "\n",
    "\n",
    "# Define the training function\n",
    "def train_model(model: nn.Module, \n",
    "                train_loader: DataLoader,\n",
    "                val_loader: DataLoader,\n",
    "                epochs: int = 10,\n",
    "                learning_rate: float = 0.001,\n",
    "                device: Optional[str] = None) -> Dict[str, List[float]]:\n",
    "    \"\"\"\n",
    "    Train the model and return training history\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "    history = {'train_loss': [], 'val_loss': []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            sequences = batch['sequence'].to(device)\n",
    "            static = batch['static'].to(device)\n",
    "            targets = batch['target'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(sequences, static)\n",
    "            loss = criterion(predictions, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "    \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                sequences = batch['sequence'].to(device)\n",
    "                static = batch['static'].to(device)\n",
    "                targets = batch['target'].to(device)\n",
    "                \n",
    "                predictions = model(sequences, static)\n",
    "                loss = criterion(predictions, targets)\n",
    "                val_losses.append(loss.item())\n",
    "        \n",
    "        # Record metrics\n",
    "        train_loss = np.mean(train_losses)\n",
    "        val_loss = np.mean(val_losses)\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs}:')\n",
    "        print(f'Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}')\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Define a function to save the model\n",
    "def save_model_with_preprocessor(model, preprocessor, sequence_dim, static_dim, path: str):\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'lap_time_scaler': preprocessor.lap_time_scaler,\n",
    "        'dynamic_scaler': preprocessor.dynamic_scaler, \n",
    "        'static_scaler': preprocessor.static_scaler,\n",
    "        'sequence_dim': sequence_dim,\n",
    "        'static_dim': static_dim\n",
    "    }, path)\n",
    "    print(f\"Model and preprocessor saved to {path}\")\n",
    "\n",
    "\n",
    "# Now, integrate your code snippets into data preprocessing\n",
    "def load_and_preprocess_data() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load data from CSV files and preprocess it to create the enhanced_laps DataFrame.\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    na_values = ['\\\\N', 'NaN', '']\n",
    "    lap_times = pd.read_csv('../../data/raw_data/lap_times.csv', na_values=na_values)\n",
    "    drivers = pd.read_csv('../../data/raw_data/drivers.csv', na_values=na_values)\n",
    "    races = pd.read_csv('../../data/raw_data/races.csv', na_values=na_values)\n",
    "    circuits = pd.read_csv('../../data/raw_data/circuits.csv', na_values=na_values)\n",
    "    pit_stops = pd.read_csv('../../data/raw_data/pit_stops.csv', na_values=na_values)\n",
    "    pit_stops.rename(columns={'milliseconds' : 'pitstop_milliseconds'}, inplace=True)\n",
    "    results = pd.read_csv('../../data/raw_data/results.csv', na_values=na_values)\n",
    "    results.rename(columns={'milliseconds' : 'racetime_milliseconds'}, inplace=True)\n",
    "\n",
    "    qualifying = pd.read_csv('../../data/raw_data/qualifying.csv', na_values=na_values)\n",
    "    status = pd.read_csv('../../data/raw_data/status.csv', na_values=na_values)\n",
    "    weather_data = pd.read_csv('../../data/raw_data/ff1_weather.csv', na_values=na_values)\n",
    "    practice_sessions = pd.read_csv('../../data/raw_data/ff1_laps.csv', na_values=na_values)\n",
    "    # Load the tire data\n",
    "    tire_data = pd.read_csv('../../data/raw_data/ff1_laps.csv', na_values=na_values)\n",
    "\n",
    "\n",
    "    # Convert date columns to datetime\n",
    "    races['date'] = pd.to_datetime(races['date'])\n",
    "    results['date'] = results['raceId'].map(races.set_index('raceId')['date'])\n",
    "    lap_times['date'] = lap_times['raceId'].map(races.set_index('raceId')['date'])\n",
    "    \n",
    "    # Merge dataframes\n",
    "    laps = lap_times.merge(drivers, on='driverId', how='left')\n",
    "    print(laps.shape)\n",
    "    laps = laps.merge(races, on='raceId', how='left', suffixes=('', '_race'))\n",
    "    laps.rename(columns={'quali_time' : 'quali_date_time'}, inplace=True)\n",
    "    print(laps.shape)\n",
    "    laps = laps.merge(circuits, on='circuitId', how='left')\n",
    "    print(laps.shape)\n",
    "    laps = laps.merge(results[['raceId', 'driverId', 'positionOrder', 'grid', 'racetime_milliseconds', 'fastestLap', 'statusId']], on=['raceId', 'driverId'], how='left')\n",
    "    print(laps.shape)\n",
    "    laps = laps.merge(status, on='statusId', how='left')\n",
    "    print(laps.shape)\n",
    "    laps = laps.merge(pit_stops[['raceId', 'driverId', 'lap', 'pitstop_milliseconds']], on=['raceId', 'driverId', 'lap'], how='left')\n",
    "    print(laps.shape)\n",
    "    laps['pitstop_milliseconds'].fillna(0, inplace=True)  # Assuming 0 if no pit stop\n",
    "    print(laps.shape)\n",
    "\n",
    "    # Load additional data\n",
    "    constructors = pd.read_csv('../../data/raw_data/constructors.csv', na_values=na_values)\n",
    "    constructor_results = pd.read_csv('../../data/raw_data/constructor_results.csv', na_values=na_values)\n",
    "    constructor_standings = pd.read_csv('../../data/raw_data/constructor_standings.csv', na_values=na_values)\n",
    "    \n",
    "    # Merge constructors with drivers\n",
    "    results = results.merge(constructors[['constructorId', 'name', 'nationality']], on='constructorId', how='left')\n",
    "    results.rename(columns={'name': 'constructor_name', 'nationality': 'constructor_nationality'}, inplace=True)\n",
    "    \n",
    "    # Map driverId to constructorId\n",
    "    driver_constructor = results[['raceId', 'driverId', 'constructorId']].drop_duplicates()\n",
    "    \n",
    "    # Merge driver_constructor into laps\n",
    "    laps = laps.merge(driver_constructor, on=['raceId', 'driverId'], how='left')\n",
    "    \n",
    "    # Add constructor performance metrics\n",
    "    # For simplicity, we'll use the constructor standings position as a performance metric\n",
    "    constructor_standings_latest = constructor_standings.sort_values('raceId', ascending=False).drop_duplicates('constructorId')\n",
    "    constructor_standings_latest = constructor_standings_latest[['constructorId', 'points', 'position']]\n",
    "    constructor_standings_latest.rename(columns={'points': 'constructor_points', 'position': 'constructor_position'}, inplace=True)\n",
    "    \n",
    "    laps = laps.merge(constructor_standings_latest, on='constructorId', how='left')\n",
    "    \n",
    "    # Fill missing constructor performance data\n",
    "    laps['constructor_points'].fillna(laps['constructor_points'].mean(), inplace=True)\n",
    "    laps['constructor_position'].fillna(laps['constructor_position'].max(), inplace=True)\n",
    "    \n",
    "    # Add constructor performance as a static feature\n",
    "    laps['constructor_performance'] = laps['constructor_points']\n",
    "    \n",
    "    # Add circuit characteristics\n",
    "    # For simplicity, let's assume circuit length and type are available in circuits.csv\n",
    "    circuits['circuit_length'] = 5.0  # Placeholder value, replace with actual data if available\n",
    "    circuits['circuit_type'] = 'Permanent'  # Options could be 'Permanent', 'Street', 'Hybrid'\n",
    "    \n",
    "    # Merge circuit data into laps\n",
    "    laps = laps.merge(circuits[['circuitId', 'circuit_length', 'circuit_type']], on='circuitId', how='left')\n",
    "    \n",
    "    # Encode circuit_type as a categorical variable\n",
    "    circuit_type_mapping = {'Permanent': 0, 'Street': 1, 'Hybrid': 2}\n",
    "    laps['circuit_type_encoded'] = laps['circuit_type'].map(circuit_type_mapping)\n",
    "    \n",
    "    # Add weather information\n",
    "    # Filter weather data to include only the Race session\n",
    "    weather_data = weather_data[weather_data['SessionName'] == 'R']\n",
    "    \n",
    "    # Merge weather data with races to get raceId\n",
    "    weather_data = weather_data.merge(\n",
    "        races[['raceId', 'year', 'name']], \n",
    "        left_on=['EventName', 'Year'],\n",
    "        right_on=['name', 'year'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Compute cumulative time from the start of the race for each driver\n",
    "    laps.sort_values(['raceId', 'driverId', 'lap'], inplace=True)\n",
    "    laps['cumulative_milliseconds'] = laps.groupby(['raceId', 'driverId'])['milliseconds'].cumsum()\n",
    "    laps['seconds_from_start'] = laps['cumulative_milliseconds'] / 1000\n",
    "    print(laps.shape)\n",
    "    \n",
    "    # Use 'Time' in weather_data as 'seconds_from_start'\n",
    "    weather_data['seconds_from_start'] = weather_data['Time']\n",
    "\n",
    "    \n",
    "    \n",
    "    # Standardize text data\n",
    "    tire_data['Compound'] = tire_data['Compound'].str.upper()\n",
    "    tire_data['EventName'] = tire_data['EventName'].str.strip().str.upper()\n",
    "    races['name'] = races['name'].str.strip().str.upper()\n",
    "    \n",
    "    # Filter for race sessions only\n",
    "    tire_data = tire_data[tire_data['SessionName'] == 'R']\n",
    "    \n",
    "    # Merge with races to get raceId\n",
    "    tire_data = tire_data.merge(\n",
    "        races[['raceId', 'year', 'name']],\n",
    "        left_on=['Year', 'EventName'],\n",
    "        right_on=['year', 'name'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Map driver codes to driverId\n",
    "    tire_data['Driver'] = tire_data['Driver'].str.strip().str.upper()\n",
    "    drivers['code'] = drivers['code'].str.strip().str.upper()\n",
    "    driver_code_to_id = drivers.set_index('code')['driverId'].to_dict()\n",
    "    tire_data['driverId'] = tire_data['Driver'].map(driver_code_to_id)\n",
    "    \n",
    "    # Rename 'LapNumber' to 'lap' and ensure integer type\n",
    "    tire_data.rename(columns={'LapNumber': 'lap'}, inplace=True)\n",
    "    tire_data['lap'] = tire_data['lap'].astype(int)\n",
    "    laps['lap'] = laps['lap'].astype(int)\n",
    "    \n",
    "    # Create compound mapping (ordered from hardest to softest)\n",
    "    compound_mapping = {\n",
    "        'UNKNOWN': 0,\n",
    "        'HARD': 1,\n",
    "        'MEDIUM': 2,\n",
    "        'SOFT': 3,\n",
    "        'INTERMEDIATE': 4,\n",
    "        'WET': 5\n",
    "    }\n",
    "    \n",
    "    # Merge tire_data with laps\n",
    "    laps = laps.merge(\n",
    "        tire_data[['raceId', 'driverId', 'lap', 'Compound', 'TrackStatus']],\n",
    "        on=['raceId', 'driverId', 'lap'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    \n",
    "    # Handle missing compounds and apply numeric encoding\n",
    "    laps['Compound'].fillna('UNKNOWN', inplace=True)\n",
    "    laps['tire_compound'] = laps['Compound'].map(compound_mapping)\n",
    "    \n",
    "    # Drop the original Compound column if desired\n",
    "    laps.drop('Compound', axis=1, inplace=True)\n",
    "    \n",
    "    # Standardize names\n",
    "    practice_sessions['EventName'] = practice_sessions['EventName'].str.strip().str.upper()\n",
    "    races['name'] = races['name'].str.strip().str.upper()\n",
    "    \n",
    "    # Merge practice_sessions with races to get raceId\n",
    "    practice_sessions = practice_sessions.merge(\n",
    "        races[['raceId', 'year', 'name']],\n",
    "        left_on=['Year', 'EventName'],\n",
    "        right_on=['year', 'name'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Map driver codes to driverId\n",
    "    practice_sessions['Driver'] = practice_sessions['Driver'].str.strip().str.upper()\n",
    "    drivers['code'] = drivers['code'].str.strip().str.upper()\n",
    "    driver_code_to_id = drivers.set_index('code')['driverId'].to_dict()\n",
    "    practice_sessions['driverId'] = practice_sessions['Driver'].map(driver_code_to_id)\n",
    "    \n",
    "    # Convert LapTime to milliseconds\n",
    "    practice_sessions['LapTime_ms'] = practice_sessions['LapTime'].apply(lambda x: pd.to_timedelta(x).total_seconds() * 1000)\n",
    "    \n",
    "    # Calculate median lap times for each driver in each session\n",
    "    session_medians = practice_sessions.groupby(['raceId', 'driverId', 'SessionName'])['LapTime_ms'].median().reset_index()\n",
    "    \n",
    "    # Pivot the data to have sessions as columns\n",
    "    session_medians_pivot = session_medians.pivot_table(\n",
    "        index=['raceId', 'driverId'],\n",
    "        columns='SessionName',\n",
    "        values='LapTime_ms'\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    session_medians_pivot.rename(columns={\n",
    "        'FP1': 'fp1_median_time',\n",
    "        'FP2': 'fp2_median_time',\n",
    "        'FP3': 'fp3_median_time',\n",
    "        'Q': 'quali_time'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    laps = laps.merge(\n",
    "    session_medians_pivot,\n",
    "    on=['raceId', 'driverId'],\n",
    "    how='left'\n",
    "    )\n",
    "    \n",
    "    # Fill missing practice times with global median or a placeholder value\n",
    "    global_median_fp1 = laps['fp1_median_time'].median()\n",
    "    laps['fp1_median_time'].fillna(global_median_fp1, inplace=True)\n",
    "    \n",
    "    # Repeat for other sessions\n",
    "    global_median_fp2 = laps['fp2_median_time'].median()\n",
    "    laps['fp2_median_time'].fillna(global_median_fp2, inplace=True)\n",
    "    \n",
    "    global_median_fp3 = laps['fp3_median_time'].median()\n",
    "    laps['fp3_median_time'].fillna(global_median_fp3, inplace=True)\n",
    "    \n",
    "    global_median_quali = laps['quali_time'].median()\n",
    "    laps['quali_time'].fillna(global_median_quali, inplace=True)\n",
    "\n",
    "    \n",
    "    # Create a binary indicator for pit stops\n",
    "    laps['is_pit_lap'] = laps['pitstop_milliseconds'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "    \n",
    "    # Define a function to match weather data to laps\n",
    "    def match_weather_to_lap(race_laps, race_weather):\n",
    "        \"\"\"\n",
    "        For each lap, find the closest weather measurement in time\n",
    "        \"\"\"\n",
    "        race_laps = race_laps.sort_values('seconds_from_start')\n",
    "        race_weather = race_weather.sort_values('seconds_from_start')\n",
    "        merged = pd.merge_asof(\n",
    "            race_laps,\n",
    "            race_weather,\n",
    "            on='seconds_from_start',\n",
    "            direction='nearest'\n",
    "        )\n",
    "        return merged\n",
    "\n",
    "    # Apply matching per race\n",
    "    matched_laps_list = []\n",
    "    for race_id in laps['raceId'].unique():\n",
    "        print(f'Matching for {race_id}')\n",
    "        race_laps = laps[laps['raceId'] == race_id]\n",
    "        race_weather = weather_data[weather_data['raceId'] == race_id]\n",
    "        \n",
    "        if not race_weather.empty:\n",
    "            matched = match_weather_to_lap(race_laps, race_weather)\n",
    "            print(f\"Matched DataFrame shape: {matched.shape}\")\n",
    "            matched_laps_list.append(matched)\n",
    "        else:\n",
    "            matched_laps_list.append(race_laps)  # No weather data for this race\n",
    "\n",
    "    # Concatenate all matched laps\n",
    "    laps = pd.concat(matched_laps_list, ignore_index=True)\n",
    "    print(laps.shape)\n",
    "    \n",
    "    # Fill missing weather data with default values\n",
    "    laps['track_temp'] = laps['TrackTemp'].fillna(25.0)\n",
    "    laps['air_temp'] = laps['AirTemp'].fillna(20.0)\n",
    "    laps['humidity'] = laps['Humidity'].fillna(50.0)\n",
    "    \n",
    "    # Calculate driver aggression and skill\n",
    "    # Create driver names\n",
    "    drivers['driver_name'] = drivers['forename'] + ' ' + drivers['surname']\n",
    "    driver_mapping = drivers[['driverId', 'driver_name']].copy()\n",
    "    driver_mapping.set_index('driverId', inplace=True)\n",
    "    driver_names = driver_mapping['driver_name'].to_dict()\n",
    "    \n",
    "    # Map statusId to status descriptions\n",
    "    status_dict = status.set_index('statusId')['status'].to_dict()\n",
    "    results['status'] = results['statusId'].map(status_dict)\n",
    "    \n",
    "    # Calculate driver aggression and skill\n",
    "    def calculate_aggression(driver_results):\n",
    "        if len(driver_results) == 0:\n",
    "            return 0.5  # Default aggression for new drivers\n",
    "        \n",
    "        # Only consider recent races for more current behavior\n",
    "        recent_results = driver_results.sort_values('date', ascending=False).head(20)\n",
    "        \n",
    "        # Calculate overtaking metrics\n",
    "        positions_gained = recent_results['grid'] - recent_results['positionOrder']\n",
    "        \n",
    "        # Calculate risk metrics\n",
    "        dnf_rate = (recent_results['status'] != 'Finished').mean()\n",
    "        incidents = (recent_results['statusId'].isin([\n",
    "            4,  # Collision\n",
    "            5,  # Spun off\n",
    "            6,  # Accident\n",
    "            20, # Collision damage\n",
    "            82, # Collision with another driver\n",
    "        ])).mean()\n",
    "        \n",
    "        # Calculate overtaking success rate (normalized between 0-1)\n",
    "        positive_overtakes = (positions_gained > 0).sum()\n",
    "        negative_overtakes = (positions_gained < 0).sum()\n",
    "        total_overtake_attempts = positive_overtakes + negative_overtakes\n",
    "        overtake_success_rate = positive_overtakes / total_overtake_attempts if total_overtake_attempts > 0 else 0.5\n",
    "        \n",
    "        # Normalize average positions gained (0-1)\n",
    "        avg_positions_gained = positions_gained[positions_gained > 0].mean() if len(positions_gained[positions_gained > 0]) > 0 else 0\n",
    "        max_possible_gain = 20  # Maximum grid positions that could be gained\n",
    "        normalized_gains = np.clip(avg_positions_gained / max_possible_gain, 0, 1)\n",
    "        \n",
    "        # Normalize risk factors (0-1)\n",
    "        normalized_dnf = np.clip(dnf_rate, 0, 1)\n",
    "        normalized_incidents = np.clip(incidents, 0, 1)\n",
    "        \n",
    "        # Calculate component scores (each between 0-1)\n",
    "        overtaking_component = (normalized_gains * 0.6 + overtake_success_rate * 0.4)\n",
    "        risk_component = (normalized_dnf * 0.5 + normalized_incidents * 0.5)\n",
    "        \n",
    "        # Combine components with weights (ensuring sum of weights = 1)\n",
    "        weights = {\n",
    "            'overtaking': 0.4,  # Aggressive overtaking\n",
    "            'risk': 0.5,       # Risk-taking behavior\n",
    "            'baseline': 0.1    # Baseline aggression\n",
    "        }\n",
    "        \n",
    "        aggression = (\n",
    "            overtaking_component * weights['overtaking'] +\n",
    "            risk_component * weights['risk'] +\n",
    "            0.5 * weights['baseline']  # Baseline aggression factor\n",
    "        )\n",
    "        \n",
    "        # Add small random variation while maintaining 0-1 bounds\n",
    "        variation = np.random.normal(0, 0.02)\n",
    "        aggression = np.clip(aggression + variation, 0, 1)\n",
    "        \n",
    "        return aggression\n",
    "    \n",
    "    # Modify calculate_skill function\n",
    "    def calculate_skill(driver_data, results_data, circuit_id, constructor_performance):\n",
    "        driver_results = results_data[\n",
    "            (results_data['driverId'] == driver_data['driverId']) & \n",
    "            (results_data['circuitId'] == circuit_id)\n",
    "        ].sort_values('date', ascending=False).head(10)  # Use last 10 races at circuit\n",
    "        \n",
    "        if len(driver_results) == 0:\n",
    "            return 0.5  # Default skill\n",
    "        \n",
    "        # Calculate performance metrics\n",
    "        avg_finish_pos = driver_results['positionOrder'].mean()\n",
    "        avg_quali_pos = driver_results['grid'].mean()\n",
    "        points_per_race = driver_results['points'].mean()\n",
    "        fastest_laps = (driver_results['rank'] == 1).mean()\n",
    "        \n",
    "        # Include constructor performance\n",
    "        constructor_factor = np.exp(-constructor_performance / 100)\n",
    "        \n",
    "        # Improved normalization (exponential decay for positions)\n",
    "        normalized_finish_pos = np.exp(-avg_finish_pos/5) # Better spread of values\n",
    "        normalized_quali_pos = np.exp(-avg_quali_pos/5)\n",
    "        \n",
    "        # Points normalization with improved scaling\n",
    "        max_points_per_race = 26  # Maximum possible points (25 + 1 fastest lap)\n",
    "        normalized_points = points_per_race / max_points_per_race\n",
    "        \n",
    "        # Weighted combination with more factors\n",
    "        weights = {\n",
    "            'finish': 0.35,\n",
    "            'quali': 0.25,\n",
    "            'points': 0.25,\n",
    "            'fastest_laps': 0.15\n",
    "        }\n",
    "        \n",
    "        skill = (\n",
    "            weights['finish'] * normalized_finish_pos +\n",
    "            weights['quali'] * normalized_quali_pos +\n",
    "            weights['points'] * normalized_points +\n",
    "            weights['fastest_laps'] * fastest_laps +\n",
    "            0.1 * constructor_factor  # Adjust weight as needed\n",
    "        )\n",
    "        \n",
    "        # Add random variation to prevent identical skills\n",
    "        skill = np.clip(skill + np.random.normal(0, 0.05), 0.1, 1.0)\n",
    "    \n",
    "        return skill\n",
    "    \n",
    "    # First merge results with races to get circuitId\n",
    "    results = results.merge(\n",
    "        races[['raceId', 'circuitId']], \n",
    "        on='raceId',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # Now calculate driver aggression and skill\n",
    "    driver_aggression = {}\n",
    "    driver_skill = {}\n",
    "    for driver_id in drivers['driverId'].unique():\n",
    "        driver_results = results[results['driverId'] == driver_id]\n",
    "        aggression = calculate_aggression(driver_results)\n",
    "        driver_aggression[driver_id] = aggression\n",
    "        \n",
    "        # Now we have circuit_id from the merge\n",
    "        recent_race = driver_results.sort_values('date', ascending=False).head(1)\n",
    "        if not recent_race.empty:\n",
    "            circuit_id = recent_race['circuitId'].iloc[0]\n",
    "            constructor_performance = laps.loc[laps['driverId'] == driver_id, 'constructor_performance'].mean()\n",
    "            skill = calculate_skill({'driverId': driver_id}, results, circuit_id, constructor_performance)\n",
    "            driver_skill[driver_id] = skill\n",
    "        else:\n",
    "            driver_skill[driver_id] = 0.5  # Default skill for new drivers\n",
    "    \n",
    "    # Map calculated aggression and skill back to laps DataFrame\n",
    "    laps['driver_aggression'] = laps['driverId'].map(driver_aggression)\n",
    "    laps['driver_overall_skill'] = laps['driverId'].map(driver_skill)\n",
    "    laps['driver_circuit_skill'] = laps['driver_overall_skill']  # For simplicity, using overall skill\n",
    "    laps['driver_consistency'] = 0.5  # Placeholder\n",
    "    laps['driver_reliability'] = 0.5  # Placeholder\n",
    "    laps['driver_risk_taking'] = laps['driver_aggression']  # Assuming similar to aggression\n",
    "    \n",
    "    # Dynamic features\n",
    "    laps['tire_age'] = laps.groupby(['raceId', 'driverId'])['lap'].cumcount()\n",
    "    laps['fuel_load'] = laps.groupby(['raceId', 'driverId'])['lap'].transform(lambda x: x.max() - x + 1)\n",
    "    laps['track_position'] = laps['position']  # Assuming 'position' is available in laps data\n",
    "    \n",
    "    # Ensure that all required columns are present\n",
    "    # Create an instance of RaceFeatures\n",
    "    race_features = RaceFeatures()\n",
    "\n",
    "    \n",
    "    laps['TrackStatus'].fillna(1, inplace=True)  # 1 = regular racing status\n",
    "    \n",
    "    # Update required columns\n",
    "    required_columns = race_features.static_features + race_features.dynamic_features\n",
    "    # Ensure all required columns are present in laps\n",
    "    missing_columns = set(required_columns) - set(laps.columns)\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Missing required columns: {missing_columns}\")\n",
    "    \n",
    "    # Drop rows with missing values in required columns\n",
    "    laps = laps[laps['year'] >= 2018]\n",
    "    laps = laps.dropna(subset=required_columns)\n",
    "    \n",
    "    return laps\n",
    "\n",
    "# Update the main function\n",
    "def main():\n",
    "    # Load and preprocess data\n",
    "    enhanced_laps = load_and_preprocess_data()\n",
    "    \n",
    "    preprocessor = F1DataPreprocessor()\n",
    "    sequences, static, targets = preprocessor.prepare_sequence_data(enhanced_laps, window_size=3)\n",
    "    \n",
    "    # Verify that lengths are consistent\n",
    "    print(f\"Sequences length: {len(sequences)}\")\n",
    "    print(f\"Static features length: {len(static)}\")\n",
    "    print(f\"Targets length: {len(targets)}\")\n",
    "    \n",
    "    # Split data into training and validation sets before fitting scalers\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    train_seq, val_seq, train_static, val_static, train_targets, val_targets = train_test_split(\n",
    "        sequences, static, targets, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Fit scalers on training data only\n",
    "    # Fit lap_time_scaler on training targets\n",
    "    preprocessor.lap_time_scaler.fit(train_targets.reshape(-1, 1))\n",
    "    \n",
    "    # Fit static_scaler on training static features\n",
    "    preprocessor.static_scaler.fit(train_static)\n",
    "    \n",
    "    # Fit dynamic_scaler on training dynamic features (excluding 'tire_compound')\n",
    "    dynamic_features_to_scale = [\n",
    "        col for col in preprocessor.race_features.dynamic_features \n",
    "        if col not in ['tire_compound']\n",
    "    ]\n",
    "    \n",
    "    # Extract dynamic features from training sequences\n",
    "    train_dynamic = train_seq[:, :, 1:]  # Exclude lap times\n",
    "    train_dynamic_flat = train_dynamic.reshape(-1, train_dynamic.shape[2])\n",
    "    \n",
    "    # Separate 'tire_compound' and other dynamic features\n",
    "    tire_compound_index = preprocessor.race_features.dynamic_features.index('tire_compound')\n",
    "    train_tire_compound = train_dynamic_flat[:, tire_compound_index]\n",
    "    train_other_dynamic = np.delete(train_dynamic_flat, tire_compound_index, axis=1)\n",
    "    \n",
    "    preprocessor.dynamic_scaler.fit(train_other_dynamic)\n",
    "    \n",
    "    # Transform training data\n",
    "    train_targets_scaled = preprocessor.lap_time_scaler.transform(train_targets.reshape(-1, 1)).flatten()\n",
    "    train_static_scaled = preprocessor.static_scaler.transform(train_static)\n",
    "    \n",
    "    # Transform dynamic features\n",
    "    train_other_dynamic_scaled = preprocessor.dynamic_scaler.transform(train_other_dynamic)\n",
    "    \n",
    "    # Reconstruct training sequences\n",
    "    train_dynamic_scaled = np.hstack((train_tire_compound.reshape(-1, 1), train_other_dynamic_scaled))\n",
    "    train_dynamic_scaled = train_dynamic_scaled.reshape(train_seq.shape[0], train_seq.shape[1], -1)\n",
    "    \n",
    "    train_seq_scaled = np.concatenate((\n",
    "        preprocessor.lap_time_scaler.transform(train_seq[:, :, 0].reshape(-1, 1)).reshape(train_seq.shape[0], train_seq.shape[1], 1),\n",
    "        train_dynamic_scaled\n",
    "    ), axis=2)\n",
    "    \n",
    "    # Transform validation data\n",
    "    val_targets_scaled = preprocessor.lap_time_scaler.transform(val_targets.reshape(-1, 1)).flatten()\n",
    "    val_static_scaled = preprocessor.static_scaler.transform(val_static)\n",
    "    \n",
    "    val_dynamic = val_seq[:, :, 1:]  # Exclude lap times\n",
    "    val_dynamic_flat = val_dynamic.reshape(-1, val_dynamic.shape[2])\n",
    "    \n",
    "    val_tire_compound = val_dynamic_flat[:, tire_compound_index]\n",
    "    val_other_dynamic = np.delete(val_dynamic_flat, tire_compound_index, axis=1)\n",
    "    \n",
    "    val_other_dynamic_scaled = preprocessor.dynamic_scaler.transform(val_other_dynamic)\n",
    "    \n",
    "    # Reconstruct validation sequences\n",
    "    val_dynamic_scaled = np.hstack((val_tire_compound.reshape(-1, 1), val_other_dynamic_scaled))\n",
    "    val_dynamic_scaled = val_dynamic_scaled.reshape(val_seq.shape[0], val_seq.shape[1], -1)\n",
    "    \n",
    "    val_seq_scaled = np.concatenate((\n",
    "        preprocessor.lap_time_scaler.transform(val_seq[:, :, 0].reshape(-1, 1)).reshape(val_seq.shape[0], val_seq.shape[1], 1),\n",
    "        val_dynamic_scaled\n",
    "    ), axis=2)\n",
    "    \n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(\n",
    "        F1Dataset(train_seq_scaled, train_static_scaled, train_targets_scaled),\n",
    "        batch_size=64,\n",
    "        shuffle=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        F1Dataset(val_seq_scaled, val_static_scaled, val_targets_scaled),\n",
    "        batch_size=64,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # Initialize model\n",
    "    model = F1PredictionModel(\n",
    "        sequence_dim=train_seq_scaled.shape[2],\n",
    "        static_dim=train_static_scaled.shape[1]\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    history = train_model(\n",
    "        model, \n",
    "        train_loader, \n",
    "        val_loader, \n",
    "        epochs=50, \n",
    "        learning_rate=0.001\n",
    "    )\n",
    "    \n",
    "    # Save the trained model\n",
    "    save_model_with_preprocessor(\n",
    "        model, \n",
    "        preprocessor, \n",
    "        train_seq_scaled.shape[2], \n",
    "        train_static_scaled.shape[1], \n",
    "        'f1_prediction_model.pth'\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Phase 2\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, Dict, List\n",
    "\n",
    "# Define the Race class\n",
    "class Race:\n",
    "    def __init__(self, race_id, circuit_id, total_laps, weather_conditions):\n",
    "        self.race_id = race_id\n",
    "        self.circuit_id = circuit_id\n",
    "        self.total_laps = total_laps\n",
    "        self.weather_conditions = weather_conditions  # Dictionary with lap-wise weather data\n",
    "        self.drivers = []\n",
    "        self.lap_data = {}  # To store lap times and positions for each driver\n",
    "\n",
    "# %%\n",
    "class Driver:\n",
    "    def __init__(self, driver_id, name, static_features, initial_dynamic_features, start_position, pit_strategy, starting_compound):\n",
    "        self.driver_id = driver_id\n",
    "        self.name = name\n",
    "        self.static_features = static_features\n",
    "        self.dynamic_features = initial_dynamic_features\n",
    "        self.sequence = None  # To store previous laps' data\n",
    "        self.current_position = start_position  # Updated each lap\n",
    "        self.start_position = start_position  # Initial grid position\n",
    "        self.pit_strategy = pit_strategy  # List of tuples: [(lap_number, new_compound), ...]\n",
    "        self.starting_compound = starting_compound  # Starting tire compound\n",
    "\n",
    "# %%\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Update the RaceSimulator class\n",
    "class RaceSimulator:\n",
    "    def __init__(self, model, preprocessor):\n",
    "        self.model = model\n",
    "        self.preprocessor = preprocessor\n",
    "        self.race_features = RaceFeatures()\n",
    "        self.pit_stop_duration = 25_000  # Average pit stop duration in milliseconds\n",
    "        self.tire_compound_effects = {\n",
    "            3: {'base_speed': 0.98, 'degradation_per_lap': 500},   # Soft\n",
    "            2: {'base_speed': 0.99, 'degradation_per_lap': 300},  # Medium  \n",
    "            1: {'base_speed': 1.0, 'degradation_per_lap': 200},    # Hard\n",
    "            4: {'base_speed': 1.05, 'degradation_per_lap': 200},    # Intermediate\n",
    "            5: {'base_speed': 1.1, 'degradation_per_lap': 200},    # Wet\n",
    "        }\n",
    "        \n",
    "    def initialize_sequence(self, driver):\n",
    "        # Initialize with zeros or previous laps (e.g., from practice sessions)\n",
    "        window_size = 3  # Assuming a window size of 3\n",
    "        sequence_dim = len(self.preprocessor.race_features.dynamic_features) + 1  # Lap time + dynamic features\n",
    "        \n",
    "        # For simplicity, initialize with zeros\n",
    "        initial_sequence = np.zeros((window_size, sequence_dim))\n",
    "        return initial_sequence\n",
    "\n",
    "    def update_dynamic_features(self, driver, lap, race):\n",
    "        # Update features like tire_age, fuel_load, etc.\n",
    "        driver.dynamic_features['tire_age'] += 1\n",
    "        driver.dynamic_features['fuel_load'] -= 1.5  # Example consumption per lap\n",
    "\n",
    "        # Check for pit stop\n",
    "        pit_stops = [stop for stop in driver.pit_strategy if stop[0] == lap]\n",
    "        if pit_stops:\n",
    "            driver.dynamic_features['is_pit_lap'] = 1\n",
    "            driver.dynamic_features['tire_age'] = 0  # Reset tire age after pit stop\n",
    "\n",
    "            # Change tire compound to the specified compound\n",
    "            new_compound = pit_stops[0][1]\n",
    "            driver.dynamic_features['tire_compound'] = new_compound\n",
    "        else:\n",
    "            driver.dynamic_features['is_pit_lap'] = 0\n",
    "\n",
    "        # Update weather conditions (if any changes)\n",
    "        weather = race.weather_conditions.get(lap, {})\n",
    "        driver.dynamic_features['track_temp'] = weather.get('track_temp', driver.dynamic_features['track_temp'])\n",
    "        driver.dynamic_features['air_temp'] = weather.get('air_temp', driver.dynamic_features['air_temp'])\n",
    "        driver.dynamic_features['humidity'] = weather.get('humidity', driver.dynamic_features['humidity'])\n",
    "        driver.dynamic_features['TrackStatus'] = weather.get('TrackStatus', 1)\n",
    "\n",
    "    def simulate_driver_lap(self, driver):\n",
    "        # Prepare input data\n",
    "        sequence = driver.sequence\n",
    "        static = driver.static_features\n",
    "\n",
    "        # Ensure correct data types and shapes\n",
    "        sequence_tensor = torch.FloatTensor(sequence).unsqueeze(0)  # Shape: (1, window_size, sequence_dim)\n",
    "        static_tensor = torch.FloatTensor(static).unsqueeze(0)  # Shape: (1, static_dim)\n",
    "\n",
    "        # Predict lap time\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            prediction = self.model(sequence_tensor, static_tensor)\n",
    "            lap_time_normalized = prediction.item()\n",
    "\n",
    "        # Inverse transform to get actual lap time\n",
    "        base_lap_time = self.preprocessor.lap_time_scaler.inverse_transform([[lap_time_normalized]])[0][0]\n",
    "\n",
    "        # Adjust lap time based on tire degradation, fuel load, and randomness\n",
    "        lap_time = self.adjust_lap_time(base_lap_time, driver)\n",
    "\n",
    "        return lap_time\n",
    "    \n",
    "    def adjust_lap_time(self, lap_time, driver):\n",
    "        # Get tire compound effects\n",
    "        compound = driver.dynamic_features['tire_compound']\n",
    "        compound_effect = self.tire_compound_effects.get(compound, {'base_speed':1.0, 'degradation_rate':0.04})\n",
    "        base_speed = compound_effect['base_speed']\n",
    "        degradation_rate = compound_effect['degradation_rate']\n",
    "\n",
    "        # Adjust lap time based on tire compound base speed\n",
    "        lap_time *= base_speed\n",
    "\n",
    "        # Adjust lap time based on tire degradation\n",
    "        tire_age = driver.dynamic_features['tire_age']\n",
    "        tire_wear_factor = degradation_rate * tire_age\n",
    "        lap_time += lap_time * tire_wear_factor\n",
    "\n",
    "        # Add pit stop duration if it's a pit lap\n",
    "        if driver.dynamic_features['is_pit_lap'] == 1:\n",
    "            lap_time += self.pit_stop_duration\n",
    "\n",
    "        return lap_time\n",
    "    \n",
    "    def update_driver_sequence(self, driver, lap_time):\n",
    "        # Update the sequence with the new lap data\n",
    "        driver.sequence = np.roll(driver.sequence, -1, axis=0)\n",
    "\n",
    "        # Prepare new sequence entry\n",
    "        dynamic_features_to_scale = [\n",
    "            col for col in self.preprocessor.race_features.dynamic_features\n",
    "            if col not in ['tire_compound']\n",
    "        ]\n",
    "        tire_compound_value = driver.dynamic_features['tire_compound']\n",
    "        other_dynamic_feature_values = np.array([\n",
    "            driver.dynamic_features[feature] for feature in dynamic_features_to_scale\n",
    "        ])\n",
    "        other_dynamic_features_scaled = self.preprocessor.dynamic_scaler.transform(\n",
    "            other_dynamic_feature_values.reshape(1, -1)\n",
    "        ).flatten()\n",
    "\n",
    "        dynamic_features_combined = np.hstack((tire_compound_value, other_dynamic_features_scaled))\n",
    "\n",
    "        lap_time_normalized = self.preprocessor.lap_time_scaler.transform([[lap_time]]).flatten()\n",
    "\n",
    "        # Combine lap time and dynamic features\n",
    "        new_sequence_entry = np.hstack((lap_time_normalized, dynamic_features_combined))\n",
    "\n",
    "        # Place new entry at the end of the sequence\n",
    "        driver.sequence[-1] = new_sequence_entry\n",
    "\n",
    "    def update_driver_sequence(self, driver, lap_time):\n",
    "        # Update the sequence with the new lap data\n",
    "        driver.sequence = np.roll(driver.sequence, -1, axis=0)\n",
    "        \n",
    "        # Prepare new sequence entry\n",
    "        dynamic_features_to_scale = [\n",
    "            col for col in self.preprocessor.race_features.dynamic_features \n",
    "            if col not in ['tire_compound']\n",
    "        ]\n",
    "        tire_compound_value = driver.dynamic_features['tire_compound']\n",
    "        other_dynamic_feature_values = np.array([\n",
    "            driver.dynamic_features[feature] for feature in dynamic_features_to_scale\n",
    "        ])\n",
    "        other_dynamic_features_scaled = self.preprocessor.dynamic_scaler.transform(\n",
    "            other_dynamic_feature_values.reshape(1, -1)\n",
    "        ).flatten()\n",
    "        \n",
    "        dynamic_features_combined = np.hstack((tire_compound_value, other_dynamic_features_scaled))\n",
    "        \n",
    "        lap_time_normalized = self.preprocessor.lap_time_scaler.transform([[lap_time]]).flatten()\n",
    "        \n",
    "        # Combine lap time and dynamic features\n",
    "        new_sequence_entry = np.hstack((lap_time_normalized, dynamic_features_combined))\n",
    "        \n",
    "        # Place new entry at the end of the sequence\n",
    "        driver.sequence[-1] = new_sequence_entry\n",
    "\n",
    "    def update_positions(self, race, lap_times):\n",
    "        # Sort drivers based on cumulative race time\n",
    "        cumulative_times = {}\n",
    "        for driver in race.drivers:\n",
    "            # Sum of lap times up to the previous lap\n",
    "            total_time = sum(race.lap_data[driver.driver_id]['lap_times'])\n",
    "            # Add current lap time\n",
    "            total_time += lap_times[driver.driver_id]\n",
    "            cumulative_times[driver.driver_id] = total_time\n",
    "        \n",
    "        # For the first lap, use start positions\n",
    "        if len(race.lap_data[driver.driver_id]['lap_times']) == 0:\n",
    "            # Use start positions to break ties\n",
    "            sorted_drivers = sorted(\n",
    "                cumulative_times.items(), \n",
    "                key=lambda x: (x[1], [d.start_position for d in race.drivers if d.driver_id == x[0]][0])\n",
    "            )\n",
    "        else:\n",
    "            # Update positions based on cumulative times\n",
    "            sorted_drivers = sorted(cumulative_times.items(), key=lambda x: x[1])\n",
    "        \n",
    "        # Update driver positions\n",
    "        for position, (driver_id, _) in enumerate(sorted_drivers, start=1):\n",
    "            driver = next(d for d in race.drivers if d.driver_id == driver_id)\n",
    "            driver.current_position = position\n",
    "\n",
    "    def simulate_race(self, race: Race):\n",
    "        \"\"\"\n",
    "        Simulate the race lap by lap for all drivers.\n",
    "        \"\"\"\n",
    "        # Initialize lap data storage\n",
    "        for driver in race.drivers:\n",
    "            race.lap_data[driver.driver_id] = {\n",
    "                'lap_times': [],\n",
    "                'positions': []\n",
    "            }\n",
    "            # Initialize driver sequence with zeros or previous data\n",
    "            driver.sequence = self.initialize_sequence(driver)\n",
    "        \n",
    "        # Simulate each lap\n",
    "        for lap in range(1, race.total_laps + 1):\n",
    "            lap_times = {}\n",
    "            # Simulate lap for each driver\n",
    "            for driver in race.drivers:\n",
    "                # Update driver's dynamic features\n",
    "                self.update_dynamic_features(driver, lap, race)\n",
    "                \n",
    "                # Simulate lap time\n",
    "                lap_time = self.simulate_driver_lap(driver)\n",
    "                lap_times[driver.driver_id] = lap_time\n",
    "                \n",
    "                # Update driver's sequence\n",
    "                self.update_driver_sequence(driver, lap_time)\n",
    "            \n",
    "            # Update positions based on lap times\n",
    "            self.update_positions(race, lap_times)\n",
    "            \n",
    "            # Record lap times and positions\n",
    "            for driver in race.drivers:\n",
    "                race.lap_data[driver.driver_id]['lap_times'].append(lap_times[driver.driver_id])\n",
    "                race.lap_data[driver.driver_id]['positions'].append(driver.current_position)\n",
    "        \n",
    "        return race.lap_data\n",
    "\n",
    "# %%\n",
    "def load_model_with_preprocessor(path: str) -> Tuple[F1PredictionModel, F1DataPreprocessor]:\n",
    "    \"\"\"Load saved model and preprocessor\"\"\"\n",
    "    checkpoint = torch.load(path, map_location=torch.device('cpu'))\n",
    "    \n",
    "    model = F1PredictionModel(\n",
    "        sequence_dim=checkpoint['sequence_dim'], \n",
    "        static_dim=checkpoint['static_dim']\n",
    "    )\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    preprocessor = F1DataPreprocessor()\n",
    "    preprocessor.lap_time_scaler = checkpoint['lap_time_scaler']\n",
    "    preprocessor.dynamic_scaler = checkpoint['dynamic_scaler']\n",
    "    preprocessor.static_scaler = checkpoint['static_scaler']\n",
    "    \n",
    "    return model, preprocessor\n",
    "\n",
    "# %%\n",
    "def plot_race_positions(race):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    for driver in race.drivers:\n",
    "        positions = race.lap_data[driver.driver_id]['positions']\n",
    "        plt.plot(range(1, race.total_laps + 1), positions, label=driver.name)\n",
    "    \n",
    "    plt.gca().invert_yaxis()  # Invert y-axis so that position 1 is at the top\n",
    "    plt.xlabel('Lap')\n",
    "    plt.ylabel('Position')\n",
    "    plt.title('Race Simulation: Driver Positions Over Laps')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_lap_times(race):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    for driver in race.drivers:\n",
    "        lap_times = race.lap_data[driver.driver_id]['lap_times']\n",
    "        plt.plot(range(1, race.total_laps + 1), lap_times, label=driver.name)\n",
    "    \n",
    "    plt.xlabel('Lap')\n",
    "    plt.ylabel('Lap Time (ms)')\n",
    "    plt.title('Race Simulation: Driver Lap Times')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def create_lap_times_dataframe(race) -> pd.DataFrame:\n",
    "    data = {'Lap': []}\n",
    "    total_laps = race.total_laps\n",
    "    for driver in race.drivers:\n",
    "        data[driver.name] = race.lap_data[driver.driver_id]['lap_times']\n",
    "    data['Lap'] = list(range(1, total_laps + 1))\n",
    "    lap_times_df = pd.DataFrame(data)\n",
    "    return lap_times_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the Race\n",
    "race = Race(\n",
    "    race_id=1,\n",
    "    circuit_id=1,\n",
    "    total_laps=50,\n",
    "    weather_conditions={\n",
    "        # You can define weather changes per lap if desired\n",
    "        # For simplicity, we keep it constant\n",
    "    }\n",
    ")\n",
    "\n",
    "compound_mapping = {\n",
    "        'UNKNOWN': 0,\n",
    "        'HARD': 1,\n",
    "        'MEDIUM': 2,\n",
    "        'SOFT': 3,\n",
    "        'INTERMEDIATE': 4,\n",
    "        'WET': 5\n",
    "    }\n",
    "\n",
    "\n",
    "# Define drivers with varying skills, attributes, and pit strategies\n",
    "drivers_data = [\n",
    "    {\n",
    "        'driver_id': 1,\n",
    "        'name': 'Driver A',\n",
    "        'static_features': [\n",
    "            0.85,    # driver_overall_skill\n",
    "            0.80,    # driver_circuit_skill\n",
    "            0.75,    # driver_consistency\n",
    "            0.90,    # driver_reliability\n",
    "            0.60,    # driver_aggression\n",
    "            0.55,    # driver_risk_taking\n",
    "            88000,   # fp1_median_time\n",
    "            87500,   # fp2_median_time\n",
    "            87000,   # fp3_median_time\n",
    "            86000,   # quali_time\n",
    "            310,     # constructor_performance\n",
    "            1        # circuitId\n",
    "        ],\n",
    "        'initial_dynamic_features': {\n",
    "            'tire_age': 0,\n",
    "            'fuel_load': 100.0,  # Starting fuel load\n",
    "            'track_position': 1,\n",
    "            'track_temp': 35.0,\n",
    "            'air_temp': 25.0,\n",
    "            'humidity': 50.0,\n",
    "            'TrackStatus': 1,\n",
    "            'is_pit_lap': 0\n",
    "        },\n",
    "        'start_position': 1,\n",
    "        'pit_strategy': [(20, 3), (35, 2)],  # Pit on lap 20 to Soft, lap 35 to Medium\n",
    "        'starting_compound': 1  # Starting on Hard compound\n",
    "    },\n",
    "    # Define other drivers similarly, with their own pit strategies\n",
    "    {\n",
    "        'driver_id': 2,\n",
    "        'name': 'Driver B',\n",
    "        'static_features': [\n",
    "            0.80,\n",
    "            0.78,\n",
    "            0.72,\n",
    "            0.88,\n",
    "            0.65,\n",
    "            0.60,\n",
    "            88200,\n",
    "            87700,\n",
    "            87200,\n",
    "            86200,\n",
    "            300,\n",
    "            1\n",
    "        ],\n",
    "        'initial_dynamic_features': {\n",
    "            'tire_age': 0,\n",
    "            'fuel_load': 100.0,\n",
    "            'track_position': 2,\n",
    "            'track_temp': 35.0,\n",
    "            'air_temp': 25.0,\n",
    "            'humidity': 50.0,\n",
    "            'TrackStatus': 1,\n",
    "            'is_pit_lap': 0\n",
    "        },\n",
    "        'start_position': 2,\n",
    "        'pit_strategy': [(18, 1), (34, 3)],\n",
    "        'starting_compound': 1  # Starting on Hard compound\n",
    "    },\n",
    "    # Add more drivers with their own pit strategies\n",
    "    {\n",
    "        'driver_id': 3,\n",
    "        'name': 'Driver C',\n",
    "        'static_features': [\n",
    "            0.78,\n",
    "            0.75,\n",
    "            0.70,\n",
    "            0.85,\n",
    "            0.70,\n",
    "            0.65,\n",
    "            88500,\n",
    "            88000,\n",
    "            87500,\n",
    "            86500,\n",
    "            280,\n",
    "            1\n",
    "        ],\n",
    "        'initial_dynamic_features': {\n",
    "            'tire_age': 0,\n",
    "            'fuel_load': 100.0,\n",
    "            'track_position': 3,\n",
    "            'track_temp': 35.0,\n",
    "            'air_temp': 25.0,\n",
    "            'humidity': 50.0,\n",
    "            'TrackStatus': 1,\n",
    "            'is_pit_lap': 0\n",
    "        },\n",
    "        'start_position': 3,\n",
    "        'pit_strategy': [(22, 2), (38, 2)],\n",
    "        'starting_compound': 1  # Starting on Hard compound\n",
    "    },\n",
    "    # Add more drivers with their own pit strategies\n",
    "    {\n",
    "        'driver_id': 4,\n",
    "        'name': 'Driver D',\n",
    "        'static_features': [\n",
    "            0.78,\n",
    "            0.75,\n",
    "            0.70,\n",
    "            0.85,\n",
    "            0.70,\n",
    "            0.65,\n",
    "            88500,\n",
    "            88000,\n",
    "            87500,\n",
    "            86500,\n",
    "            280,\n",
    "            1\n",
    "        ],\n",
    "        'initial_dynamic_features': {\n",
    "            'tire_age': 0,\n",
    "            'fuel_load': 100.0,\n",
    "            'track_position': 3,\n",
    "            'track_temp': 35.0,\n",
    "            'air_temp': 25.0,\n",
    "            'humidity': 50.0,\n",
    "            'TrackStatus': 1,\n",
    "            'is_pit_lap': 0\n",
    "        },\n",
    "        'start_position': 3,\n",
    "        'pit_strategy': [(22, 2), (38, 2)],\n",
    "        'starting_compound': 1  # Starting on Hard compound\n",
    "    },\n",
    "    # Add more drivers with their own pit strategies\n",
    "    {\n",
    "        'driver_id': 5,\n",
    "        'name': 'Driver E',\n",
    "        'static_features': [\n",
    "            0.78,\n",
    "            0.75,\n",
    "            0.70,\n",
    "            0.85,\n",
    "            0.70,\n",
    "            0.65,\n",
    "            88500,\n",
    "            88000,\n",
    "            87500,\n",
    "            86500,\n",
    "            280,\n",
    "            1\n",
    "        ],\n",
    "        'initial_dynamic_features': {\n",
    "            'tire_age': 0,\n",
    "            'fuel_load': 100.0,\n",
    "            'track_position': 3,\n",
    "            'track_temp': 35.0,\n",
    "            'air_temp': 25.0,\n",
    "            'humidity': 50.0,\n",
    "            'TrackStatus': 1,\n",
    "            'is_pit_lap': 0\n",
    "        },\n",
    "        'start_position': 3,\n",
    "        'pit_strategy': [(22, 2), (38, 2)],\n",
    "        'starting_compound': 1  # Starting on Hard compound\n",
    "    }\n",
    "    \n",
    "]\n",
    "\n",
    "# Create the simulator\n",
    "model, preprocessor = load_model_with_preprocessor('f1_prediction_model.pth')\n",
    "simulator = RaceSimulator(model, preprocessor)\n",
    "\n",
    "# Add drivers to the race\n",
    "for d in drivers_data:\n",
    "    driver = Driver(\n",
    "        driver_id=d['driver_id'],\n",
    "        name=d['name'],\n",
    "        static_features=d['static_features'],\n",
    "        initial_dynamic_features=d['initial_dynamic_features'],\n",
    "        start_position=d['start_position'],\n",
    "        pit_strategy=d['pit_strategy'],\n",
    "        starting_compound=d['starting_compound']\n",
    "    )\n",
    "\n",
    "    # Set starting compound\n",
    "    driver.dynamic_features['tire_compound'] = driver.starting_compound\n",
    "\n",
    "    # Scale static features\n",
    "    static_features_scaled = preprocessor.static_scaler.transform([driver.static_features]).flatten()\n",
    "    driver.static_features = static_features_scaled\n",
    "\n",
    "    # Define the features to scale\n",
    "    dynamic_features_to_scale = [\n",
    "        col for col in preprocessor.race_features.dynamic_features\n",
    "        if col not in ['tire_compound']\n",
    "    ]\n",
    "\n",
    "    # Extract 'tire_compound' separately\n",
    "    tire_compound_value = driver.dynamic_features['tire_compound']\n",
    "\n",
    "    # Extract and scale other dynamic features\n",
    "    other_dynamic_feature_values = np.array([\n",
    "        driver.dynamic_features[feature] for feature in dynamic_features_to_scale\n",
    "    ])\n",
    "    other_dynamic_features_scaled = preprocessor.dynamic_scaler.transform(\n",
    "        other_dynamic_feature_values.reshape(1, -1)\n",
    "    ).flatten()\n",
    "\n",
    "    # Combine 'tire_compound' (not scaled) with the scaled dynamic features\n",
    "    dynamic_features_combined = np.hstack((tire_compound_value, other_dynamic_features_scaled))\n",
    "\n",
    "    # Initialize the driver's sequence\n",
    "    lap_times = [90000, 89500, 89200]  # Example initial lap times\n",
    "    lap_times_scaled = preprocessor.lap_time_scaler.transform(\n",
    "        np.array(lap_times).reshape(-1, 1)\n",
    "    ).flatten()\n",
    "    sequence = np.hstack((\n",
    "        lap_times_scaled.reshape(-1, 1),\n",
    "        np.tile(dynamic_features_combined, (3, 1))\n",
    "    ))\n",
    "    driver.sequence = sequence\n",
    "    driver.dynamic_features_scaled = dynamic_features_combined\n",
    "\n",
    "    # Add driver to the race\n",
    "    race.drivers.append(driver)\n",
    "\n",
    "# Simulate the race\n",
    "race_lap_data = simulator.simulate_race(race)\n",
    "\n",
    "# Plot the race positions\n",
    "plot_race_positions(race)\n",
    "\n",
    "# Plot the lap times\n",
    "plot_lap_times(race)\n",
    "\n",
    "# Create a DataFrame of lap times\n",
    "lap_times_df = create_lap_times_dataframe(race)\n",
    "print(lap_times_df.head())\n",
    "\n",
    "# Optionally, save lap times to CSV\n",
    "lap_times_df.to_csv('race_lap_times.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
