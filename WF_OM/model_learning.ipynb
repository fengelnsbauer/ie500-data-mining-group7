{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To Do: \n",
    "\n",
    "Andere Modelle implementieren,\n",
    "\n",
    "Evalutaion erstellen der verschiedenen Modelle und vergleichen,\n",
    "\n",
    "Schauen ob schon erste Testläufe mit den bereits preprocesseden daten möglich sind, \n",
    "\n",
    "Pipeline\n",
    "\n",
    "Hyper Parameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data \n",
    "And getting familiar with data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gt/wnv6zp0s7w92jy1_p2n6shsr0000gn/T/ipykernel_22388/849369748.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../data/processed/export_v1.csv') #not fully preprocessed yet\n"
     ]
    }
   ],
   "source": [
    "#Import Data\n",
    "df = pd.read_csv('../data/processed/export_v1.csv') #not fully preprocessed yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultId</th>\n",
       "      <th>raceId</th>\n",
       "      <th>driverId</th>\n",
       "      <th>constructorId</th>\n",
       "      <th>number</th>\n",
       "      <th>grid</th>\n",
       "      <th>year</th>\n",
       "      <th>round</th>\n",
       "      <th>circuitId</th>\n",
       "      <th>race_name</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_pit_stop_lap</th>\n",
       "      <th>std_pit_stop_lap</th>\n",
       "      <th>avg_pit_stop_driver</th>\n",
       "      <th>avg_pit_stop_team</th>\n",
       "      <th>avg_pit_stop_track</th>\n",
       "      <th>avg_pit_stop_season</th>\n",
       "      <th>rolling_avg_pit_stop_driver</th>\n",
       "      <th>rolling_avg_pit_stop_team</th>\n",
       "      <th>rolling_avg_pit_stop_track</th>\n",
       "      <th>rolling_avg_pit_stop_season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   resultId  raceId  driverId  constructorId number  grid  year  round  \\\n",
       "0         1      18         1              1     22     1  2008      1   \n",
       "1         2      18         2              2      3     5  2008      1   \n",
       "2         3      18         3              3      7     7  2008      1   \n",
       "3         4      18         4              4      5    11  2008      1   \n",
       "4         5      18         5              1     23     3  2008      1   \n",
       "\n",
       "   circuitId              race_name  ... avg_pit_stop_lap std_pit_stop_lap  \\\n",
       "0          1  Australian Grand Prix  ...              NaN              NaN   \n",
       "1          1  Australian Grand Prix  ...              NaN              NaN   \n",
       "2          1  Australian Grand Prix  ...              NaN              NaN   \n",
       "3          1  Australian Grand Prix  ...              NaN              NaN   \n",
       "4          1  Australian Grand Prix  ...              NaN              NaN   \n",
       "\n",
       "  avg_pit_stop_driver avg_pit_stop_team avg_pit_stop_track  \\\n",
       "0                 NaN               NaN                NaN   \n",
       "1                 NaN               NaN                NaN   \n",
       "2                 NaN               NaN                NaN   \n",
       "3                 NaN               NaN                NaN   \n",
       "4                 NaN               NaN                NaN   \n",
       "\n",
       "  avg_pit_stop_season rolling_avg_pit_stop_driver rolling_avg_pit_stop_team  \\\n",
       "0                 NaN                         NaN                       NaN   \n",
       "1                 NaN                         NaN                       NaN   \n",
       "2                 NaN                         NaN                       NaN   \n",
       "3                 NaN                         NaN                       NaN   \n",
       "4                 NaN                         NaN                       NaN   \n",
       "\n",
       "  rolling_avg_pit_stop_track rolling_avg_pit_stop_season  \n",
       "0                        NaN                         NaN  \n",
       "1                        NaN                         NaN  \n",
       "2                        NaN                         NaN  \n",
       "3                        NaN                         NaN  \n",
       "4                        NaN                         NaN  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26699 entries, 0 to 26698\n",
      "Data columns (total 43 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   resultId                     26699 non-null  int64  \n",
      " 1   raceId                       26699 non-null  int64  \n",
      " 2   driverId                     26699 non-null  int64  \n",
      " 3   constructorId                26699 non-null  int64  \n",
      " 4   number                       26699 non-null  object \n",
      " 5   grid                         26699 non-null  int64  \n",
      " 6   year                         26699 non-null  int64  \n",
      " 7   round                        26699 non-null  int64  \n",
      " 8   circuitId                    26699 non-null  int64  \n",
      " 9   race_name                    26699 non-null  object \n",
      " 10  race_date                    26699 non-null  object \n",
      " 11  race_time                    26699 non-null  object \n",
      " 12  fp1_date                     26699 non-null  object \n",
      " 13  fp2_date                     26699 non-null  object \n",
      " 14  fp3_date                     26699 non-null  object \n",
      " 15  fp1_time                     26699 non-null  object \n",
      " 16  fp2_time                     26699 non-null  object \n",
      " 17  fp3_time                     26699 non-null  object \n",
      " 18  quali_time                   26699 non-null  object \n",
      " 19  quali_date                   26699 non-null  object \n",
      " 20  race_location                26699 non-null  object \n",
      " 21  race_country                 26699 non-null  object \n",
      " 22  race_lat                     26699 non-null  float64\n",
      " 23  race_lng                     26699 non-null  float64\n",
      " 24  race_alt                     26699 non-null  int64  \n",
      " 25  min_pit_stop_duration        5518 non-null   float64\n",
      " 26  max_pit_stop_duration        5518 non-null   float64\n",
      " 27  avg_pit_stop_duration        5518 non-null   float64\n",
      " 28  std_pit_stop_duration        5518 non-null   float64\n",
      " 29  milliseconds_count           5518 non-null   float64\n",
      " 30  pit_stop_count               5518 non-null   float64\n",
      " 31  min_pit_stop_lap             5518 non-null   float64\n",
      " 32  max_pit_stop_lap             5518 non-null   float64\n",
      " 33  avg_pit_stop_lap             5518 non-null   float64\n",
      " 34  std_pit_stop_lap             5518 non-null   float64\n",
      " 35  avg_pit_stop_driver          5518 non-null   float64\n",
      " 36  avg_pit_stop_team            5518 non-null   float64\n",
      " 37  avg_pit_stop_track           5518 non-null   float64\n",
      " 38  avg_pit_stop_season          5518 non-null   float64\n",
      " 39  rolling_avg_pit_stop_driver  5518 non-null   float64\n",
      " 40  rolling_avg_pit_stop_team    5518 non-null   float64\n",
      " 41  rolling_avg_pit_stop_track   5518 non-null   float64\n",
      " 42  rolling_avg_pit_stop_season  5518 non-null   float64\n",
      "dtypes: float64(20), int64(9), object(14)\n",
      "memory usage: 8.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In which shape is the preprocessed data? Are additional preprocessing techniques necessary for different models ?\n",
    "\n",
    "Is there already an train-test(-validation) split?\n",
    "\n",
    "Binning, Boosting & stratified sampling\n",
    "\n",
    "Encoding necessary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = df['position'] #target variable not yet in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test Split (mit stratified sampling)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test, df_target_train, df_target_test = train_test_split(\n",
    "    df, df_target,test_size=0.2, random_state=42, stratify=df_target)\n",
    "\n",
    "print(\"=======TRAIN=========\")\n",
    "display(df_train)\n",
    "display(df_target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_wo_target = df_test.drop(columns=['position'])\n",
    "df_train_wo_target = df_train.drop(columns=['position'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forrest\n",
    "\n",
    "Hyperparameters that can be optimized are  max_depth, n_estimators, min_samples_leaf, min_samples_split, max_features, criterion: {“gini”, “entropy”}.\n",
    "\n",
    "Random_state is only used for the reproducibility of results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(max_depth=2, random_state=0) #Modell initialisieren\n",
    "\n",
    "random_forest.fit(df_train, df_target_train) #Lernvorgang des Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf_prediction = random_forest.predict(df_test_wo_target) #Vorhersage des Modells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter tuning trough grid search\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definiere das Modell\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Definiere den Parameter-Raster\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Führe die Grid-Suche durch\n",
    "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(df_train_wo_target, df_target_train)\n",
    "\n",
    "# Beste Parameter anzeigen\n",
    "print(\"Beste Parameter:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "Assumes different attributes are independent of each other. (Did we remove duplicates/ very similar attributes?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html) is implemented in different variations in scikit-learn.\n",
    "They differ mainly by the assumptions they make regarding the distribution of $P(x_i|y)$\n",
    "\n",
    "\n",
    "- [```GaussianNB``` class](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB) implements the Naive Bayes classifier for continious (numeric) features. Likelihood of the features is assumed to be Gaussian\n",
    "- [```MultinomialNB``` class](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html) implements the Naive Bayes classifier for discrete (categorical) features (multinomially distributed data)\n",
    "- [```BernoulliNB``` class](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html) assumes multivariate Bernoulli distributions\n",
    "- [```CategoricalNB``` class](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.CategoricalNB.html) assumes that each feature has its own categorical distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could the assumption about the distributions of $P(x_i|y)$ be regarded as an hyperparameter wich can be optimized? \n",
    "\n",
    "Only 4 Options, so try what works best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "naive_bayes = GaussianNB()\n",
    "naive_bayes.fit(df_train, df_target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nb_prediction = naive_bayes.predict(df_test_wo_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Models\n",
    "\n",
    "(Eventuell seperates Dokument)\n",
    "\n",
    "### Confusion Matrix for Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "display(df_target_test)\n",
    "display(df_rf_prediction) #still need to predict\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(df_target_test, df_rf_prediction))\n",
    "print()\n",
    "\n",
    "print(\"Accuracy: {}\".format(accuracy_score(df_target_test, df_rf_prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificaion Report (Recall and Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(df_target_test, df_rf_prediction, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement a cross validation split to get a better estimate about performance of used models.\n",
    "#Example for Random Forrest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual Evaluation (ROC Curves)\n",
    "\n",
    "Classifiers necessary which deliver confidence scores of their predicitons. It has to be possible to apply the  ```predict_proba()``` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembles\n",
    "\n",
    "Let the different models vote for final prediction.\n",
    "\n",
    "Possabilities: \n",
    "Stacking,\n",
    "Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking\n",
    "\n",
    "Stacking example for the Random Forrest and Naive Bayes Classifier with a Decision Tree classifier as the meta classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stacking Example for Naive Bayes and Random Forrest\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier #Meta Learner\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Stacking: scikit-learn has no implementation for Stacking. You can use this -> https://rasbt.gith2ub.io/mlxtend/\n",
    "# HINT: mlxtend can only work with numerical labels. You can use the LabelEncoder to transform your labels.\n",
    "\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "estimators = {'RandomForrest': RandomForestClassifier(max_depth=2, random_state=0), 'NaiveBayes': GaussianNB()} #Possible to extend to even more classifiers\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "df_target_train_encoded = encoder.fit_transform(df_target_train)\n",
    "df_target_test_encoded = encoder.transform(df_target_test)\n",
    "\n",
    "ensemble = StackingClassifier(\n",
    "    classifiers=list(estimators.values()),\n",
    "    meta_classifier=DecisionTreeClassifier()\n",
    ")\n",
    "estimators['Stacking'] = ensemble\n",
    "\n",
    "for e_name, e in estimators.items():\n",
    "    evaluate_classifier(e_name, e, df_train_wo_target, df_target_train_encoded, df_test_wo_target, df_target_test)\n",
    "\n",
    "#Does it improve accuracy?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
