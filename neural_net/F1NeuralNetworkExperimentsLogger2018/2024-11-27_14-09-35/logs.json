{
    "used_features": [
        "fp3_avg_is_on_fresh_tyres",
        "fp1_avg_sector_2",
        "fp1_avg_lap_time",
        "fp1_avg_speedST",
        "fp2_avg_sector_1",
        "fp2_avg_sector_2",
        "fp2_avg_lap_time",
        "fp2_avg_speedST",
        "fp3_avg_sector_1",
        "fp3_avg_sector_2",
        "fp3_avg_lap_time",
        "fp3_avg_speedST",
        "q1_time",
        "q2_time",
        "q3_time",
        "q_position",
        "min_pit_stop_duration",
        "avg_pit_stop_duration",
        "rolling_avg_pit_stop_driver",
        "rolling_avg_pit_stop_team",
        "race_lat",
        "race_lng",
        "race_alt",
        "race_date",
        "year",
        "round",
        "driver_nationality",
        "constructorId"
    ],
    "model_architecture": "Sequential(\n  (0): Linear(in_features=28, out_features=64, bias=True)\n  (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (2): ReLU()\n  (3): Dropout(p=0.2, inplace=False)\n  (4): Linear(in_features=64, out_features=128, bias=True)\n  (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (6): ReLU()\n  (7): Dropout(p=0.3, inplace=False)\n  (8): Linear(in_features=128, out_features=256, bias=True)\n  (9): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (10): ReLU()\n  (11): Dropout(p=0.3, inplace=False)\n  (12): Linear(in_features=256, out_features=128, bias=True)\n  (13): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (14): ReLU()\n  (15): Dropout(p=0.2, inplace=False)\n  (16): Linear(in_features=128, out_features=64, bias=True)\n  (17): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (18): ReLU()\n  (19): Linear(in_features=64, out_features=1, bias=True)\n)",
    "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    base_momentum: 0.85\n    betas: (0.95, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    initial_lr: 4e-05\n    lr: 3.9999999999999996e-05\n    max_lr: 0.001\n    max_momentum: 0.95\n    maximize: False\n    min_lr: 4e-09\n    weight_decay: 0.01\n)",
    "scheduler": "<torch.optim.lr_scheduler.OneCycleLR object at 0x319cd2120>",
    "hyperparameters": {
        "input_dim": "28",
        "hidden_dim": "64",
        "output_dim": "1",
        "lr": "0.001",
        "loss_fn": "<class 'torch.nn.modules.loss.L1Loss'>"
    },
    "metrics": [
        {
            "step": 49,
            "metrics": {
                "train_loss": 9.285612106323242,
                "epoch": 0.0
            }
        },
        {
            "step": 99,
            "metrics": {
                "train_loss": 10.587369918823242,
                "epoch": 0.0
            }
        },
        {
            "step": 149,
            "metrics": {
                "train_loss": 8.52114486694336,
                "epoch": 0.0
            }
        },
        {
            "step": 199,
            "metrics": {
                "train_loss": 10.789648056030273,
                "epoch": 1.0
            }
        },
        {
            "step": 249,
            "metrics": {
                "train_loss": 9.539556503295898,
                "epoch": 1.0
            }
        },
        {
            "step": 299,
            "metrics": {
                "train_loss": 9.330022811889648,
                "epoch": 1.0
            }
        },
        {
            "step": 349,
            "metrics": {
                "train_loss": 11.022699356079102,
                "epoch": 1.0
            }
        },
        {
            "step": 399,
            "metrics": {
                "train_loss": 8.956977844238281,
                "epoch": 2.0
            }
        },
        {
            "step": 449,
            "metrics": {
                "train_loss": 8.043917655944824,
                "epoch": 2.0
            }
        },
        {
            "step": 499,
            "metrics": {
                "train_loss": 8.684003829956055,
                "epoch": 2.0
            }
        }
    ]
}