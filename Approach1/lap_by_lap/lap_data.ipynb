{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4159f14525e9c7a3",
   "metadata": {},
   "source": [
    "# F1 Lap Times Data Processing and Feature Engineering\n",
    "\n",
    "This notebook loads raw Formula 1 data, preprocesses it, and engineers new features related to driver performance attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d5ebfee093a65a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T08:55:38.499684Z",
     "start_time": "2024-11-27T08:55:38.491229Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427bd22b0a0eef0",
   "metadata": {},
   "source": [
    "## Define NA Values and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6530622aa97d9663",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T08:55:39.637466Z",
     "start_time": "2024-11-27T08:55:38.513792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded Successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c3/96l18xtx7fz9rgy3dxg2crdm0000gn/T/ipykernel_57706/3712708636.py:15: DtypeWarning: Columns (18,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  practice_sessions = pd.read_csv('../../data/raw_data/ff1_free_practice.csv', na_values=na_values)\n",
      "/var/folders/c3/96l18xtx7fz9rgy3dxg2crdm0000gn/T/ipykernel_57706/3712708636.py:17: DtypeWarning: Columns (13,14,15,16,17,18,19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  preprocessed = pd.read_csv('../../data/processed/export_v1.csv', na_values=na_values)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print('Data Loaded Successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bba90e9a72c6198",
   "metadata": {},
   "source": [
    "## Inspect Lap Times Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96b8935d37d3bfd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T08:55:40.023766Z",
     "start_time": "2024-11-27T08:55:40.017503Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raceId</th>\n",
       "      <th>driverId</th>\n",
       "      <th>lap</th>\n",
       "      <th>position</th>\n",
       "      <th>time</th>\n",
       "      <th>milliseconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>841</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1:38.109</td>\n",
       "      <td>98109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>841</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1:33.006</td>\n",
       "      <td>93006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>841</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1:32.713</td>\n",
       "      <td>92713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>841</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1:32.803</td>\n",
       "      <td>92803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>841</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1:32.342</td>\n",
       "      <td>92342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   raceId  driverId  lap  position      time  milliseconds\n",
       "0     841        20    1         1  1:38.109         98109\n",
       "1     841        20    2         1  1:33.006         93006\n",
       "2     841        20    3         1  1:32.713         92713\n",
       "3     841        20    4         1  1:32.803         92803\n",
       "4     841        20    5         1  1:32.342         92342"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lap_times.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cd2f8d9dea8bb0",
   "metadata": {},
   "source": [
    "## Merge Lap Times with Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "662433b2ccd54e10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T08:55:40.492290Z",
     "start_time": "2024-11-27T08:55:40.057899Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merge lap times with preprocessed data on 'raceId' and 'driverId'\n",
    "data = lap_times.merge(preprocessed, on=['raceId', 'driverId'], how='left')\n",
    "\n",
    "# Drop the 'time' column and rename 'milliseconds' to 'lap_time'\n",
    "if 'time' in data.columns:\n",
    "    data.drop(columns=['time'], inplace=True)\n",
    "if 'milliseconds' in data.columns:\n",
    "    data.rename(columns={'milliseconds': 'lap_time'}, inplace=True)\n",
    "else:\n",
    "    print('Column \"milliseconds\" not found in merged data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d620bf2ae77af7",
   "metadata": {},
   "source": [
    "## Define Functions and Classes for Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "663a8b69c694a8bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T08:55:41.114901Z",
     "start_time": "2024-11-27T08:55:41.099161Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_lap_data(lap_times_df: pd.DataFrame, races_df: pd.DataFrame, results_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prepare lap times data by merging with races and results data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    lap_times_df: DataFrame containing lap times\n",
    "    races_df: DataFrame containing race information\n",
    "    results_df: DataFrame containing race results\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with merged lap times, race dates, and circuit information\n",
    "    \"\"\"\n",
    "    # Get required columns from races\n",
    "    race_info = races_df[['raceId', 'date', 'year', 'circuitId']].copy()\n",
    "    \n",
    "    # Merge lap times with race information\n",
    "    enhanced_laps = lap_times_df.merge(\n",
    "        race_info,\n",
    "        on='raceId',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Convert date to datetime\n",
    "    enhanced_laps['date'] = pd.to_datetime(enhanced_laps['date'])\n",
    "    \n",
    "    return enhanced_laps\n",
    "\n",
    "class LapAttributeCalculator:\n",
    "    def __init__(self, lap_times_df: pd.DataFrame, races_df: pd.DataFrame, results_df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Initialize with required dataframes.\n",
    "        \"\"\"\n",
    "        # Merge results with races to include 'date'\n",
    "        if 'date' not in results_df.columns:\n",
    "            print('Merging results with races to include \"date\" column.')\n",
    "            results_df = results_df.merge(races_df[['raceId', 'date']], on='raceId', how='left')\n",
    "            if 'date' not in results_df.columns:\n",
    "                raise KeyError('After merging, \"date\" column is still missing in results_df.')\n",
    "        else:\n",
    "            results_df['date'] = pd.to_datetime(results_df['date'])\n",
    "        \n",
    "        self.results = results_df.copy()\n",
    "        self.base_data = prepare_lap_data(lap_times_df, races_df, results_df)\n",
    "        \n",
    "    def add_driver_attributes(self, n_previous_races: int = 20) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Add driver performance attributes to each lap.\n",
    "        \"\"\"\n",
    "        enhanced_laps = self.base_data.copy()\n",
    "        print(f\"Starting with {len(enhanced_laps)} laps\")\n",
    "        \n",
    "        # Ensure 'driverId' is present in base_data\n",
    "        if 'driverId' not in enhanced_laps.columns:\n",
    "            raise KeyError('driverId column is missing from the base data.')\n",
    "            \n",
    "        # Process each unique driver-race combination\n",
    "        unique_combinations = enhanced_laps[['driverId', 'raceId', 'date', 'circuitId']].drop_duplicates()\n",
    "        print(f\"Processing {len(unique_combinations)} unique driver-race combinations\")\n",
    "        \n",
    "        attributes_list = []\n",
    "        for _, combo in unique_combinations.iterrows():\n",
    "            # Get previous results for this driver up to this race\n",
    "            previous_results = self.results[\n",
    "                (self.results['driverId'] == combo['driverId']) &\n",
    "                (self.results['date'] < combo['date'])\n",
    "            ].sort_values('date', ascending=False).head(n_previous_races)\n",
    "            \n",
    "            # Calculate attributes\n",
    "            attributes = {\n",
    "                'raceId': combo['raceId'],\n",
    "                'driverId': combo['driverId'],\n",
    "                **self._calculate_driver_attributes(\n",
    "                    previous_results,\n",
    "                    combo['circuitId'],\n",
    "                    combo['date']\n",
    "                )\n",
    "            }\n",
    "            attributes_list.append(attributes)\n",
    "        \n",
    "        # Convert to DataFrame and merge with laps\n",
    "        print(\"Creating attributes DataFrame...\")\n",
    "        attributes_df = pd.DataFrame(attributes_list)\n",
    "        \n",
    "        # Merge attributes with original lap data\n",
    "        print(\"Merging attributes with lap data...\")\n",
    "        enhanced_laps = enhanced_laps.merge(\n",
    "            attributes_df,\n",
    "            on=['raceId', 'driverId'],\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        print(f\"Final dataframe has {len(enhanced_laps)} rows and {len(enhanced_laps.columns)} columns\")\n",
    "        return enhanced_laps\n",
    "    \n",
    "    def _calculate_driver_attributes(self, previous_results: pd.DataFrame, \n",
    "                                   circuit_id: int, race_date: pd.Timestamp) -> Dict[str, float]:\n",
    "        \"\"\"Calculate all driver attributes based on previous races.\"\"\"\n",
    "        if previous_results.empty:\n",
    "            return self._get_default_attributes()\n",
    "        \n",
    "        # Calculate attributes\n",
    "        circuit_results = previous_results[previous_results['circuitId'] == circuit_id]\n",
    "        \n",
    "        attributes = {\n",
    "            # Skill metrics\n",
    "            'driver_overall_skill': self._calculate_skill(previous_results),\n",
    "            'driver_circuit_skill': self._calculate_skill(circuit_results) if not circuit_results.empty else 0.5,\n",
    "            \n",
    "            # Race performance metrics\n",
    "            'driver_consistency': self._calculate_consistency(previous_results),\n",
    "            'driver_reliability': self._calculate_reliability(previous_results),\n",
    "            'driver_aggression': self._calculate_aggression(previous_results),\n",
    "            'driver_risk_taking': self._calculate_risk_taking(previous_results),\n",
    "            \n",
    "            # Position and points metrics\n",
    "            'avg_finish_position': previous_results['positionOrder'].mean(),\n",
    "            'avg_grid_position': previous_results['grid'].mean(),\n",
    "            'points_per_race': previous_results['points'].mean(),\n",
    "            \n",
    "            # Overtaking metrics\n",
    "            **self._calculate_overtaking_metrics(previous_results),\n",
    "            \n",
    "            # DNF and completion metrics\n",
    "            **self._calculate_completion_metrics(previous_results),\n",
    "            \n",
    "            # Circuit specific performance\n",
    "            **self._calculate_circuit_metrics(circuit_results)\n",
    "        }\n",
    "        \n",
    "        return attributes\n",
    "    \n",
    "    def _calculate_overtaking_metrics(self, results: pd.DataFrame) -> Dict[str, float]:\n",
    "        \"\"\"Calculate overtaking-related metrics.\"\"\"\n",
    "        if results.empty:\n",
    "            return {'overtakes_per_race': 0.5, 'overtake_success_rate': 0.5}\n",
    "            \n",
    "        positions_gained = results['grid'] - results['positionOrder']\n",
    "        positive_overtakes = (positions_gained > 0).sum()\n",
    "        total_overtakes = len(positions_gained[positions_gained != 0])\n",
    "        \n",
    "        return {\n",
    "            'overtakes_per_race': positions_gained.mean(),\n",
    "            'overtake_success_rate': positive_overtakes / total_overtakes if total_overtakes > 0 else 0.5\n",
    "        }\n",
    "    \n",
    "    def _calculate_reliability(self, driver_results: pd.DataFrame) -> float:\n",
    "        \"\"\"Calculate driver reliability score.\"\"\"\n",
    "        if driver_results.empty:\n",
    "            return 0.5\n",
    "            \n",
    "        # Calculate finish rate\n",
    "        finish_rate = (driver_results['statusId'] == 1).mean()  # Status 1 = Finished\n",
    "        \n",
    "        # Calculate mechanical failure rate\n",
    "        mechanical_status_ids = [2, 3, 4, 5, 6]  # Mechanical failures\n",
    "        mechanical_failure_rate = (driver_results['statusId'].isin(mechanical_status_ids)).mean()\n",
    "        \n",
    "        # Combine metrics\n",
    "        reliability = (finish_rate * 0.7 + (1 - mechanical_failure_rate) * 0.3)\n",
    "        \n",
    "        return np.clip(reliability, 0.5, 1.0)\n",
    "    \n",
    "    def _calculate_completion_metrics(self, results: pd.DataFrame) -> Dict[str, float]:\n",
    "        \"\"\"Calculate race completion metrics.\"\"\"\n",
    "        if results.empty:\n",
    "            return {'race_completion_rate': 0.5, 'dnf_rate': 0.5}\n",
    "            \n",
    "        completion_rate = (results['statusId'] == 1).mean()\n",
    "        dnf_rate = (results['statusId'] != 1).mean()\n",
    "        \n",
    "        return {\n",
    "            'race_completion_rate': completion_rate,\n",
    "            'dnf_rate': dnf_rate\n",
    "        }\n",
    "    \n",
    "    def _calculate_circuit_metrics(self, circuit_results: pd.DataFrame) -> Dict[str, float]:\n",
    "        \"\"\"Calculate circuit-specific performance metrics.\"\"\"\n",
    "        if circuit_results.empty:\n",
    "            return {\n",
    "                'circuit_avg_position': 10.0,\n",
    "                'circuit_points_average': 0.0,\n",
    "                'circuit_completion_rate': 0.5\n",
    "            }\n",
    "            \n",
    "        return {\n",
    "            'circuit_avg_position': circuit_results['positionOrder'].mean(),\n",
    "            'circuit_points_average': circuit_results['points'].mean(),\n",
    "            'circuit_completion_rate': (circuit_results['statusId'] == 1).mean()\n",
    "        }\n",
    "    \n",
    "    def _calculate_risk_taking(self, driver_results: pd.DataFrame) -> float:\n",
    "        \"\"\"Calculate driver risk-taking score.\"\"\"\n",
    "        if driver_results.empty:\n",
    "            return 0.5\n",
    "            \n",
    "        # Calculate various risk metrics\n",
    "        positions_gained = driver_results['grid'] - driver_results['positionOrder']\n",
    "        big_gains = (positions_gained > 5).mean()  # Significant position improvements\n",
    "        incident_rate = (driver_results['statusId'].isin([4, 5, 6, 20, 82])).mean()\n",
    "        \n",
    "        # Combine metrics\n",
    "        risk_score = (big_gains * 0.6 + incident_rate * 0.4)\n",
    "        \n",
    "        return np.clip(risk_score, 0, 1)\n",
    "    \n",
    "    def _calculate_consistency(self, driver_results: pd.DataFrame) -> float:\n",
    "        \"\"\"Calculate driver consistency score.\"\"\"\n",
    "        if driver_results.empty:\n",
    "            return 0.5\n",
    "            \n",
    "        # Calculate position variance\n",
    "        pos_std = driver_results['positionOrder'].std()\n",
    "        normalized_std = np.exp(-pos_std/5)  # Lower std = higher consistency\n",
    "        \n",
    "        # Calculate finish rate in points\n",
    "        points_finish_rate = (driver_results['points'] > 0).mean()\n",
    "        \n",
    "        # Combine metrics\n",
    "        consistency = (normalized_std * 0.6 + points_finish_rate * 0.4)\n",
    "        \n",
    "        return np.clip(consistency, 0, 1)\n",
    "    \n",
    "    def _calculate_aggression(self, driver_results: pd.DataFrame) -> float:\n",
    "        \"\"\"Calculate driver aggression score based on overtaking and incidents.\"\"\"\n",
    "        if driver_results.empty:\n",
    "            return 0.5\n",
    "            \n",
    "        # Calculate overtaking metrics\n",
    "        positions_gained = driver_results['grid'] - driver_results['positionOrder']\n",
    "        positive_overtakes = (positions_gained > 0).sum()\n",
    "        negative_overtakes = (positions_gained < 0).sum()\n",
    "        total_overtake_attempts = positive_overtakes + negative_overtakes\n",
    "        \n",
    "        # Calculate incident rates\n",
    "        incident_status_ids = [4, 5, 6, 20, 82]  # Collisions, accidents, etc.\n",
    "        incident_rate = (driver_results['statusId'].isin(incident_status_ids)).mean()\n",
    "        \n",
    "        # Calculate components\n",
    "        overtake_success = positive_overtakes / total_overtake_attempts if total_overtake_attempts > 0 else 0.5\n",
    "        avg_positions_gained = positions_gained[positions_gained > 0].mean() if (positions_gained > 0).any() else 0\n",
    "        \n",
    "        # Normalize and combine\n",
    "        normalized_gains = np.clip(avg_positions_gained / 20, 0, 1)  # 20 as max possible positions gained\n",
    "        \n",
    "        # Weight the components\n",
    "        aggression = (\n",
    "            normalized_gains * 0.4 +\n",
    "            overtake_success * 0.3 +\n",
    "            incident_rate * 0.3\n",
    "        )\n",
    "        \n",
    "        return np.clip(aggression, 0, 1)\n",
    "    \n",
    "    def _get_default_attributes(self) -> Dict[str, float]:\n",
    "        \"\"\"Return default attributes for drivers with no previous races.\"\"\"\n",
    "        return {\n",
    "            'driver_overall_skill': 0.5,\n",
    "            'driver_circuit_skill': 0.5,\n",
    "            'driver_consistency': 0.5,\n",
    "            'driver_reliability': 0.5,\n",
    "            'driver_aggression': 0.5,\n",
    "            'driver_risk_taking': 0.5,\n",
    "            'avg_finish_position': 10.0,\n",
    "            'avg_grid_position': 10.0,\n",
    "            'points_per_race': 0.0,\n",
    "            'overtakes_per_race': 0.0,\n",
    "            'overtake_success_rate': 0.5,\n",
    "            'race_completion_rate': 0.5,\n",
    "            'dnf_rate': 0.5,\n",
    "            'circuit_avg_position': 10.0,\n",
    "            'circuit_points_average': 0.0,\n",
    "            'circuit_completion_rate': 0.5\n",
    "        }\n",
    "    \n",
    "    def _calculate_skill(self, results: pd.DataFrame) -> float:\n",
    "        \"\"\"Calculate driver skill score.\"\"\"\n",
    "        if results.empty:\n",
    "            return 0.5\n",
    "            \n",
    "        avg_finish_pos = results['positionOrder'].mean()\n",
    "        avg_quali_pos = results['grid'].mean()\n",
    "        points_per_race = results['points'].mean()\n",
    "        \n",
    "        # Normalize metrics\n",
    "        norm_finish = np.exp(-avg_finish_pos/5)\n",
    "        norm_quali = np.exp(-avg_quali_pos/5)\n",
    "        norm_points = points_per_race / 26  # Assuming 26 is the maximum points per race\n",
    "        \n",
    "        skill = (norm_finish * 0.4 + norm_quali * 0.3 + norm_points * 0.3)\n",
    "        return np.clip(skill, 0.1, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898b0a1b430272d",
   "metadata": {},
   "source": [
    "## Initialize Calculator and Add Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1008d56bdddf43df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T08:55:52.909222Z",
     "start_time": "2024-11-27T08:55:41.168653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging results with races to include \"date\" column.\n",
      "Columns in results after merge: ['resultId', 'raceId', 'driverId', 'constructorId', 'number', 'grid', 'position', 'positionText', 'positionOrder', 'points', 'laps', 'time', 'milliseconds', 'fastestLap', 'rank', 'fastestLapTime', 'fastestLapSpeed', 'statusId', 'date', 'circuitId']\n",
      "Starting with 586171 laps\n",
      "Processing 10984 unique driver-race combinations\n",
      "Creating attributes DataFrame...\n",
      "Merging attributes with lap data...\n",
      "Final dataframe has 586171 rows and 25 columns\n"
     ]
    }
   ],
   "source": [
    "# Merge results with races to include 'date'\n",
    "if 'date' not in results.columns:\n",
    "    print('Merging results with races to include \"date\" column.')\n",
    "    results = results.merge(races[['raceId', 'date', 'circuitId']], on='raceId', how='left')\n",
    "    if 'date' not in results.columns:\n",
    "        raise KeyError('After merging, \"date\" column is still missing in results.')\n",
    "    if 'circuitId' not in results.columns:\n",
    "         raise KeyError('After merging, \"circuitId\" column is still missing in results.')\n",
    "else:\n",
    "    results['date'] = pd.to_datetime(results['date'])\n",
    "\n",
    "# Verify that 'date' column is present\n",
    "print('Columns in results after merge:', results.columns.tolist())\n",
    "\n",
    "# Initialize calculator\n",
    "calculator = LapAttributeCalculator(\n",
    "    lap_times_df=lap_times,\n",
    "    races_df=races,\n",
    "    results_df=results\n",
    ")\n",
    "\n",
    "# Add attributes to lap times\n",
    "enhanced_laps = calculator.add_driver_attributes(n_previous_races=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36041ad81a78eaa",
   "metadata": {},
   "source": [
    "## View New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92a32fe00b4c4968",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T08:55:53.193683Z",
     "start_time": "2024-11-27T08:55:53.029986Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New features added:\n",
      "['date', 'year', 'circuitId', 'driver_overall_skill', 'driver_circuit_skill', 'driver_consistency', 'driver_reliability', 'driver_aggression', 'driver_risk_taking', 'avg_finish_position', 'avg_grid_position', 'points_per_race', 'overtakes_per_race', 'overtake_success_rate', 'race_completion_rate', 'dnf_rate', 'circuit_avg_position', 'circuit_points_average', 'circuit_completion_rate']\n",
      "\n",
      "New features statistics:\n",
      "                                date           year      circuitId  \\\n",
      "count                         586171  586171.000000  586171.000000   \n",
      "mean   2011-07-25 08:47:43.732255744    2011.021168      19.414688   \n",
      "min              1996-03-10 00:00:00    1996.000000       1.000000   \n",
      "25%              2004-08-29 00:00:00    2004.000000       7.000000   \n",
      "50%              2012-03-18 00:00:00    2012.000000      13.000000   \n",
      "75%              2018-07-29 00:00:00    2018.000000      21.000000   \n",
      "max              2024-11-03 00:00:00    2024.000000      80.000000   \n",
      "std                              NaN       8.202509      20.562384   \n",
      "\n",
      "       driver_overall_skill  driver_circuit_skill  driver_consistency  \\\n",
      "count         586171.000000         586171.000000       581249.000000   \n",
      "mean               0.183085              0.350214            0.409448   \n",
      "min                0.100000              0.100000            0.071924   \n",
      "25%                0.100000              0.104890            0.324177   \n",
      "50%                0.100798              0.500000            0.391942   \n",
      "75%                0.228367              0.500000            0.482813   \n",
      "max                0.776233              1.000000            1.000000   \n",
      "std                0.130914              0.193822            0.117917   \n",
      "\n",
      "       driver_reliability  driver_aggression  driver_risk_taking  \\\n",
      "count       586171.000000      586171.000000       586171.000000   \n",
      "mean             0.637804           0.287056            0.131670   \n",
      "min              0.500000           0.000000            0.000000   \n",
      "25%              0.500000           0.233268            0.060000   \n",
      "50%              0.570000           0.281667            0.110000   \n",
      "75%              0.775000           0.330000            0.170000   \n",
      "max              1.000000           0.800000            1.000000   \n",
      "std              0.155553           0.081952            0.108544   \n",
      "\n",
      "       avg_finish_position  avg_grid_position  points_per_race  \\\n",
      "count        586171.000000      586171.000000    586171.000000   \n",
      "mean             10.894482          10.658826         3.498523   \n",
      "min               1.200000           1.000000         0.000000   \n",
      "25%               7.950000           6.850000         0.350000   \n",
      "50%              11.250000          10.500000         1.650000   \n",
      "75%              13.750000          14.100000         4.750000   \n",
      "max              24.000000          24.000000        24.700000   \n",
      "std               3.861562           4.875822         4.569925   \n",
      "\n",
      "       overtakes_per_race  overtake_success_rate  race_completion_rate  \\\n",
      "count       586171.000000          586171.000000         586171.000000   \n",
      "mean            -0.235656               0.556899              0.456029   \n",
      "min            -16.450000               0.000000              0.000000   \n",
      "25%             -1.600000               0.437500              0.200000   \n",
      "50%             -0.250000               0.555556              0.450000   \n",
      "75%              1.100000               0.666667              0.700000   \n",
      "max             13.000000               1.000000              1.000000   \n",
      "std              2.238149               0.181615              0.291144   \n",
      "\n",
      "            dnf_rate  circuit_avg_position  circuit_points_average  \\\n",
      "count  586171.000000         586171.000000           586171.000000   \n",
      "mean        0.543971             10.250312                1.902508   \n",
      "min         0.000000              1.000000                0.000000   \n",
      "25%         0.300000              9.000000                0.000000   \n",
      "50%         0.550000             10.000000                0.000000   \n",
      "75%         0.800000             11.000000                1.000000   \n",
      "max         1.000000             33.000000               50.000000   \n",
      "std         0.291144              4.800827                4.502037   \n",
      "\n",
      "       circuit_completion_rate  \n",
      "count            586171.000000  \n",
      "mean                  0.476156  \n",
      "min                   0.000000  \n",
      "25%                   0.000000  \n",
      "50%                   0.500000  \n",
      "75%                   1.000000  \n",
      "max                   1.000000  \n",
      "std                   0.372652  \n"
     ]
    }
   ],
   "source": [
    "# Identify new feature columns\n",
    "new_features = [col for col in enhanced_laps.columns if col not in lap_times.columns]\n",
    "print(\"New features added:\")\n",
    "print(new_features)\n",
    "\n",
    "# Basic statistics of new features\n",
    "print(\"\\nNew features statistics:\")\n",
    "print(enhanced_laps[new_features].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc4a1ecdcefa8f7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T08:55:53.272903Z",
     "start_time": "2024-11-27T08:55:53.202140Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raceId</th>\n",
       "      <th>driverId</th>\n",
       "      <th>lap</th>\n",
       "      <th>milliseconds</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>circuitId</th>\n",
       "      <th>driver_overall_skill</th>\n",
       "      <th>driver_circuit_skill</th>\n",
       "      <th>driver_consistency</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_finish_position</th>\n",
       "      <th>avg_grid_position</th>\n",
       "      <th>points_per_race</th>\n",
       "      <th>overtakes_per_race</th>\n",
       "      <th>overtake_success_rate</th>\n",
       "      <th>race_completion_rate</th>\n",
       "      <th>dnf_rate</th>\n",
       "      <th>circuit_avg_position</th>\n",
       "      <th>circuit_points_average</th>\n",
       "      <th>circuit_completion_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>841</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>98109</td>\n",
       "      <td>2011-03-27</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0.483233</td>\n",
       "      <td>0.258969</td>\n",
       "      <td>0.483917</td>\n",
       "      <td>...</td>\n",
       "      <td>5.75</td>\n",
       "      <td>1.95</td>\n",
       "      <td>13.30</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>841</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>93006</td>\n",
       "      <td>2011-03-27</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0.483233</td>\n",
       "      <td>0.258969</td>\n",
       "      <td>0.483917</td>\n",
       "      <td>...</td>\n",
       "      <td>5.75</td>\n",
       "      <td>1.95</td>\n",
       "      <td>13.30</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>841</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>92713</td>\n",
       "      <td>2011-03-27</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0.483233</td>\n",
       "      <td>0.258969</td>\n",
       "      <td>0.483917</td>\n",
       "      <td>...</td>\n",
       "      <td>5.75</td>\n",
       "      <td>1.95</td>\n",
       "      <td>13.30</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>841</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>92803</td>\n",
       "      <td>2011-03-27</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0.483233</td>\n",
       "      <td>0.258969</td>\n",
       "      <td>0.483917</td>\n",
       "      <td>...</td>\n",
       "      <td>5.75</td>\n",
       "      <td>1.95</td>\n",
       "      <td>13.30</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>841</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>92342</td>\n",
       "      <td>2011-03-27</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0.483233</td>\n",
       "      <td>0.258969</td>\n",
       "      <td>0.483917</td>\n",
       "      <td>...</td>\n",
       "      <td>5.75</td>\n",
       "      <td>1.95</td>\n",
       "      <td>13.30</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586166</th>\n",
       "      <td>1141</td>\n",
       "      <td>815</td>\n",
       "      <td>65</td>\n",
       "      <td>82220</td>\n",
       "      <td>2024-11-03</td>\n",
       "      <td>2024</td>\n",
       "      <td>18</td>\n",
       "      <td>0.211130</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.494178</td>\n",
       "      <td>...</td>\n",
       "      <td>8.65</td>\n",
       "      <td>7.95</td>\n",
       "      <td>6.85</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586167</th>\n",
       "      <td>1141</td>\n",
       "      <td>815</td>\n",
       "      <td>66</td>\n",
       "      <td>82978</td>\n",
       "      <td>2024-11-03</td>\n",
       "      <td>2024</td>\n",
       "      <td>18</td>\n",
       "      <td>0.211130</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.494178</td>\n",
       "      <td>...</td>\n",
       "      <td>8.65</td>\n",
       "      <td>7.95</td>\n",
       "      <td>6.85</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586168</th>\n",
       "      <td>1141</td>\n",
       "      <td>815</td>\n",
       "      <td>67</td>\n",
       "      <td>82143</td>\n",
       "      <td>2024-11-03</td>\n",
       "      <td>2024</td>\n",
       "      <td>18</td>\n",
       "      <td>0.211130</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.494178</td>\n",
       "      <td>...</td>\n",
       "      <td>8.65</td>\n",
       "      <td>7.95</td>\n",
       "      <td>6.85</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586169</th>\n",
       "      <td>1141</td>\n",
       "      <td>815</td>\n",
       "      <td>68</td>\n",
       "      <td>82263</td>\n",
       "      <td>2024-11-03</td>\n",
       "      <td>2024</td>\n",
       "      <td>18</td>\n",
       "      <td>0.211130</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.494178</td>\n",
       "      <td>...</td>\n",
       "      <td>8.65</td>\n",
       "      <td>7.95</td>\n",
       "      <td>6.85</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586170</th>\n",
       "      <td>1141</td>\n",
       "      <td>815</td>\n",
       "      <td>69</td>\n",
       "      <td>82222</td>\n",
       "      <td>2024-11-03</td>\n",
       "      <td>2024</td>\n",
       "      <td>18</td>\n",
       "      <td>0.211130</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.494178</td>\n",
       "      <td>...</td>\n",
       "      <td>8.65</td>\n",
       "      <td>7.95</td>\n",
       "      <td>6.85</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>586171 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        raceId  driverId  lap  milliseconds       date  year  circuitId  \\\n",
       "0          841        20    1         98109 2011-03-27  2011          1   \n",
       "1          841        20    2         93006 2011-03-27  2011          1   \n",
       "2          841        20    3         92713 2011-03-27  2011          1   \n",
       "3          841        20    4         92803 2011-03-27  2011          1   \n",
       "4          841        20    5         92342 2011-03-27  2011          1   \n",
       "...        ...       ...  ...           ...        ...   ...        ...   \n",
       "586166    1141       815   65         82220 2024-11-03  2024         18   \n",
       "586167    1141       815   66         82978 2024-11-03  2024         18   \n",
       "586168    1141       815   67         82143 2024-11-03  2024         18   \n",
       "586169    1141       815   68         82263 2024-11-03  2024         18   \n",
       "586170    1141       815   69         82222 2024-11-03  2024         18   \n",
       "\n",
       "        driver_overall_skill  driver_circuit_skill  driver_consistency  ...  \\\n",
       "0                   0.483233              0.258969            0.483917  ...   \n",
       "1                   0.483233              0.258969            0.483917  ...   \n",
       "2                   0.483233              0.258969            0.483917  ...   \n",
       "3                   0.483233              0.258969            0.483917  ...   \n",
       "4                   0.483233              0.258969            0.483917  ...   \n",
       "...                      ...                   ...                 ...  ...   \n",
       "586166              0.211130              0.500000            0.494178  ...   \n",
       "586167              0.211130              0.500000            0.494178  ...   \n",
       "586168              0.211130              0.500000            0.494178  ...   \n",
       "586169              0.211130              0.500000            0.494178  ...   \n",
       "586170              0.211130              0.500000            0.494178  ...   \n",
       "\n",
       "        avg_finish_position  avg_grid_position  points_per_race  \\\n",
       "0                      5.75               1.95            13.30   \n",
       "1                      5.75               1.95            13.30   \n",
       "2                      5.75               1.95            13.30   \n",
       "3                      5.75               1.95            13.30   \n",
       "4                      5.75               1.95            13.30   \n",
       "...                     ...                ...              ...   \n",
       "586166                 8.65               7.95             6.85   \n",
       "586167                 8.65               7.95             6.85   \n",
       "586168                 8.65               7.95             6.85   \n",
       "586169                 8.65               7.95             6.85   \n",
       "586170                 8.65               7.95             6.85   \n",
       "\n",
       "        overtakes_per_race  overtake_success_rate  race_completion_rate  \\\n",
       "0                     -3.8               0.312500                   0.8   \n",
       "1                     -3.8               0.312500                   0.8   \n",
       "2                     -3.8               0.312500                   0.8   \n",
       "3                     -3.8               0.312500                   0.8   \n",
       "4                     -3.8               0.312500                   0.8   \n",
       "...                    ...                    ...                   ...   \n",
       "586166                -0.7               0.588235                   0.7   \n",
       "586167                -0.7               0.588235                   0.7   \n",
       "586168                -0.7               0.588235                   0.7   \n",
       "586169                -0.7               0.588235                   0.7   \n",
       "586170                -0.7               0.588235                   0.7   \n",
       "\n",
       "        dnf_rate  circuit_avg_position  circuit_points_average  \\\n",
       "0            0.2                  17.0                     0.0   \n",
       "1            0.2                  17.0                     0.0   \n",
       "2            0.2                  17.0                     0.0   \n",
       "3            0.2                  17.0                     0.0   \n",
       "4            0.2                  17.0                     0.0   \n",
       "...          ...                   ...                     ...   \n",
       "586166       0.3                  10.0                     0.0   \n",
       "586167       0.3                  10.0                     0.0   \n",
       "586168       0.3                  10.0                     0.0   \n",
       "586169       0.3                  10.0                     0.0   \n",
       "586170       0.3                  10.0                     0.0   \n",
       "\n",
       "        circuit_completion_rate  \n",
       "0                           0.0  \n",
       "1                           0.0  \n",
       "2                           0.0  \n",
       "3                           0.0  \n",
       "4                           0.0  \n",
       "...                         ...  \n",
       "586166                      0.5  \n",
       "586167                      0.5  \n",
       "586168                      0.5  \n",
       "586169                      0.5  \n",
       "586170                      0.5  \n",
       "\n",
       "[586171 rows x 23 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhanced_laps.drop(columns=['position', 'time'], axis=1, inplace=True)\n",
    "enhanced_laps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f066c1c28080a65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T08:55:53.297047Z",
     "start_time": "2024-11-27T08:55:53.294456Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "raceId                              int64\n",
       "driverId                            int64\n",
       "lap                                 int64\n",
       "milliseconds                        int64\n",
       "date                       datetime64[ns]\n",
       "year                                int64\n",
       "circuitId                           int64\n",
       "driver_overall_skill              float64\n",
       "driver_circuit_skill              float64\n",
       "driver_consistency                float64\n",
       "driver_reliability                float64\n",
       "driver_aggression                 float64\n",
       "driver_risk_taking                float64\n",
       "avg_finish_position               float64\n",
       "avg_grid_position                 float64\n",
       "points_per_race                   float64\n",
       "overtakes_per_race                float64\n",
       "overtake_success_rate             float64\n",
       "race_completion_rate              float64\n",
       "dnf_rate                          float64\n",
       "circuit_avg_position              float64\n",
       "circuit_points_average            float64\n",
       "circuit_completion_rate           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhanced_laps.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a28eb5f1133d1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T08:55:53.833626Z",
     "start_time": "2024-11-27T08:55:53.831800Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b033f7840cb2301",
   "metadata": {},
   "source": [
    "Phase 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51a682d0b4fe65a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T08:55:54.044900Z",
     "start_time": "2024-11-27T08:55:53.894769Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'RaceFeatures' has no attribute 'static_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 272\u001b[0m\n\u001b[1;32m    269\u001b[0m     save_model(model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_prediction_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 272\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 248\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m    247\u001b[0m     preprocessor \u001b[38;5;241m=\u001b[39m F1DataPreprocessor()\n\u001b[0;32m--> 248\u001b[0m     sequences, static, targets \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_sequence_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43menhanced_laps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;66;03m# Create train and validation loaders\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     train_loader, val_loader \u001b[38;5;241m=\u001b[39m preprocessor\u001b[38;5;241m.\u001b[39mcreate_train_val_loaders(\n\u001b[1;32m    252\u001b[0m         sequences, \n\u001b[1;32m    253\u001b[0m         static, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    256\u001b[0m         val_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m\n\u001b[1;32m    257\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[35], line 67\u001b[0m, in \u001b[0;36mF1DataPreprocessor.prepare_sequence_data\u001b[0;34m(self, df, window_size)\u001b[0m\n\u001b[1;32m     64\u001b[0m group \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlap\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Extract static features (assumed to be constant per driver per race)\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m static \u001b[38;5;241m=\u001b[39m group[\u001b[43mRaceFeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatic_features\u001b[49m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     68\u001b[0m static_features\u001b[38;5;241m.\u001b[39mappend(static)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Extract dynamic features and target\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'RaceFeatures' has no attribute 'static_features'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "from dataclasses import dataclass, field\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "\n",
    "# Define the RaceFeatures dataclass\n",
    "@dataclass\n",
    "class RaceFeatures:\n",
    "    \"\"\"Data structure for race features\"\"\"\n",
    "    static_features: List[str] = field(default_factory=lambda: [\n",
    "        'driver_overall_skill', 'driver_circuit_skill', 'driver_consistency',\n",
    "        'driver_reliability', 'driver_aggression', 'driver_risk_taking'\n",
    "    ])\n",
    "    \n",
    "    dynamic_features: List[str] = field(default_factory=lambda: [\n",
    "        'tire_age', 'fuel_load', 'track_position', 'track_temp',\n",
    "        'air_temp', 'humidity'\n",
    "    ])\n",
    "    \n",
    "    target: str = 'milliseconds'\n",
    "\n",
    "# Define the F1Dataset class\n",
    "class F1Dataset(Dataset):\n",
    "    def __init__(self, sequences, static_features, targets):\n",
    "        self.sequences = torch.FloatTensor(sequences)\n",
    "        self.static_features = torch.FloatTensor(static_features)\n",
    "        self.targets = torch.FloatTensor(targets)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'sequence': self.sequences[idx],\n",
    "            'static': self.static_features[idx],\n",
    "            'target': self.targets[idx]\n",
    "        }\n",
    "\n",
    "# Define the F1DataPreprocessor class\n",
    "class F1DataPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.static_scaler = StandardScaler()\n",
    "        self.dynamic_scaler = StandardScaler()\n",
    "        self.lap_time_scaler = StandardScaler()\n",
    "        \n",
    "    def prepare_sequence_data(self, df: pd.DataFrame, window_size: int = 3) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Prepare sequential data with sliding window and apply scaling\n",
    "        \"\"\"\n",
    "        sequences = []\n",
    "        static_features = []\n",
    "        targets = []\n",
    "        \n",
    "        # Sort the dataframe to ensure consistent ordering\n",
    "        df = df.sort_values(['raceId', 'driverId', 'lap'])\n",
    "        \n",
    "        # Group by race and driver\n",
    "        for (race_id, driver_id), group in df.groupby(['raceId', 'driverId']):\n",
    "            group = group.sort_values('lap')\n",
    "            \n",
    "            # Extract static features (assumed to be constant per driver per race)\n",
    "            static = group[RaceFeatures.static_features].iloc[0].values\n",
    "            static_features.append(static)\n",
    "            \n",
    "            # Extract dynamic features and target\n",
    "            lap_times = group[RaceFeatures.target].values.reshape(-1, 1)  # Shape: (num_laps, 1)\n",
    "            dynamic = group[RaceFeatures.dynamic_features].values  # Shape: (num_laps, num_dynamic_features)\n",
    "            \n",
    "            # Apply scaling\n",
    "            # Note: Scalers should be fitted on the training data to prevent data leakage.\n",
    "            # Here, for simplicity, we're fitting on the entire dataset. For a real-world scenario,\n",
    "            # consider splitting the data first before fitting the scalers.\n",
    "            lap_times_scaled = self.lap_time_scaler.fit_transform(lap_times).flatten()\n",
    "            dynamic_scaled = self.dynamic_scaler.fit_transform(dynamic)\n",
    "            static_scaled = self.static_scaler.fit_transform(static.reshape(1, -1)).flatten()\n",
    "            \n",
    "            # Create sequences\n",
    "            for i in range(len(lap_times_scaled) - window_size):\n",
    "                sequence_lap_times = lap_times_scaled[i:i+window_size].reshape(-1, 1)  # Shape: (window_size, 1)\n",
    "                sequence_dynamic = dynamic_scaled[i:i+window_size]  # Shape: (window_size, num_dynamic_features)\n",
    "                sequence = np.hstack((sequence_lap_times, sequence_dynamic))  # Shape: (window_size, 1 + num_dynamic_features)\n",
    "                sequences.append(sequence)\n",
    "                static_features.append(static_scaled)\n",
    "                targets.append(lap_times_scaled[i + window_size])\n",
    "        \n",
    "        return (np.array(sequences), \n",
    "                np.array(static_features), \n",
    "                np.array(targets))\n",
    "    \n",
    "    def create_train_val_loaders(\n",
    "        self, \n",
    "        sequences: np.ndarray, \n",
    "        static_features: np.ndarray, \n",
    "        targets: np.ndarray,\n",
    "        batch_size: int = 32,\n",
    "        val_split: float = 0.2\n",
    "    ) -> Tuple[DataLoader, DataLoader]:\n",
    "        \"\"\"\n",
    "        Create train and validation dataloaders with given split ratio\n",
    "        \"\"\"\n",
    "        dataset = F1Dataset(sequences, static_features, targets)\n",
    "        \n",
    "        # Calculate lengths for split\n",
    "        val_size = int(len(dataset) * val_split)\n",
    "        train_size = len(dataset) - val_size\n",
    "        \n",
    "        # Split dataset\n",
    "        train_dataset, val_dataset = random_split(\n",
    "            dataset, \n",
    "            [train_size, val_size],\n",
    "            generator=torch.Generator().manual_seed(42)\n",
    "        )\n",
    "        \n",
    "        # Create dataloaders\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True\n",
    "        )\n",
    "        \n",
    "        val_loader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False\n",
    "        )\n",
    "        \n",
    "        return train_loader, val_loader\n",
    "\n",
    "# Define the F1PredictionModel class\n",
    "class F1PredictionModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 sequence_dim: int,\n",
    "                 static_dim: int,\n",
    "                 hidden_dim: int = 64,\n",
    "                 num_layers: int = 2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # LSTM for sequential features\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=sequence_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Static features processing\n",
    "        self.static_network = nn.Sequential(\n",
    "            nn.Linear(static_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        # Combine everything\n",
    "        self.final_network = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, sequence, static):\n",
    "        # Process sequence through LSTM\n",
    "        lstm_out, _ = self.lstm(sequence)\n",
    "        lstm_out = lstm_out[:, -1, :]  # Take the output of the last time step\n",
    "        \n",
    "        # Process static features\n",
    "        static_out = self.static_network(static)\n",
    "        \n",
    "        # Combine LSTM output and static features\n",
    "        combined = torch.cat([lstm_out, static_out], dim=1)\n",
    "        \n",
    "        # Final prediction\n",
    "        prediction = self.final_network(combined)\n",
    "        \n",
    "        return prediction.squeeze()\n",
    "\n",
    "# Define the training function\n",
    "def train_model(model: nn.Module, \n",
    "                train_loader: DataLoader,\n",
    "                val_loader: DataLoader,\n",
    "                epochs: int = 10,\n",
    "                learning_rate: float = 0.001,\n",
    "                device: Optional[str] = None) -> Dict[str, List[float]]:\n",
    "    \"\"\"\n",
    "    Train the model and return training history\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "    history = {'train_loss': [], 'val_loss': []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            sequences = batch['sequence'].to(device)\n",
    "            static = batch['static'].to(device)\n",
    "            targets = batch['target'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(sequences, static)\n",
    "            loss = criterion(predictions, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                sequences = batch['sequence'].to(device)\n",
    "                static = batch['static'].to(device)\n",
    "                targets = batch['target'].to(device)\n",
    "                \n",
    "                predictions = model(sequences, static)\n",
    "                loss = criterion(predictions, targets)\n",
    "                val_losses.append(loss.item())\n",
    "        \n",
    "        # Record losses\n",
    "        train_loss = np.mean(train_losses)\n",
    "        val_loss = np.mean(val_losses)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs}:')\n",
    "        print(f'Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Define a function to save the model\n",
    "def save_model(model: nn.Module, path: str):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"Model saved to {path}\")\n",
    "\n",
    "# New function to load and preprocess the data\n",
    "def load_and_preprocess_data() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load data from CSV files and preprocess it to create the enhanced_laps DataFrame.\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    # Define NA values\n",
    "    na_values = ['\\\\N']\n",
    "    \n",
    "    # Load Data\n",
    "    circuits = pd.read_csv('../../data/raw_data/circuits.csv', na_values=na_values)\n",
    "    constructors = pd.read_csv('../../data/raw_data/constructors.csv', na_values=na_values)\n",
    "    drivers = pd.read_csv('../../data/raw_data/drivers.csv', na_values=na_values)\n",
    "    races = pd.read_csv('../../data/raw_data/races.csv', na_values=na_values)\n",
    "    results = pd.read_csv('../../data/raw_data/results.csv', na_values=na_values)\n",
    "    lap_times = pd.read_csv('../../data/raw_data/lap_times.csv', na_values=na_values)\n",
    "    pit_stops = pd.read_csv('../../data/raw_data/pit_stops.csv', na_values=na_values)\n",
    "    qualifying = pd.read_csv('../../data/raw_data/qualifying.csv', na_values=na_values)\n",
    "    status = pd.read_csv('../../data/raw_data/status.csv', na_values=na_values)\n",
    "    weather_data = pd.read_csv('../../data/raw_data/ff1_weather.csv', na_values=na_values)\n",
    "    practice_sessions = pd.read_csv('../../data/raw_data/ff1_free_practice.csv', na_values=na_values)\n",
    "    \n",
    "    preprocessed = pd.read_csv('../../data/processed/export_v1.csv', na_values=na_values)\n",
    "\n",
    "    # Merge dataframes\n",
    "    laps = lap_times.merge(drivers, on='driverId', how='left')\n",
    "    laps = laps.merge(races, on='raceId', how='left')\n",
    "    laps = laps.merge(circuits, on='circuitId', how='left')\n",
    "\n",
    "    # Add pit stop information\n",
    "    laps = laps.merge(pit_stops[['raceId', 'driverId', 'lap', 'duration']], on=['raceId', 'driverId', 'lap'], how='left')\n",
    "    laps['duration'].fillna(0, inplace=True)  # Assuming 0 if no pit stop\n",
    "\n",
    "    # Add weather information\n",
    "    # This is a placeholder; you'll need to match your actual weather data\n",
    "    laps = laps.merge(weather_data, on=['raceId', 'lap'], how='left')\n",
    "\n",
    "    # Feature Engineering\n",
    "    laps['tire_age'] = laps.groupby(['raceId', 'driverId'])['lap'].cumcount()\n",
    "    laps['fuel_load'] = laps.groupby(['raceId', 'driverId'])['lap'].apply(lambda x: x.max() - x + 1)\n",
    "\n",
    "    # For simplicity, we can assign dummy values to static features\n",
    "    # In a real scenario, you should compute these based on historical data\n",
    "    laps['driver_overall_skill'] = 1.0  # Placeholder\n",
    "    laps['driver_circuit_skill'] = 1.0  # Placeholder\n",
    "    laps['driver_consistency'] = 1.0    # Placeholder\n",
    "    laps['driver_reliability'] = 1.0    # Placeholder\n",
    "    laps['driver_aggression'] = 1.0     # Placeholder\n",
    "    laps['driver_risk_taking'] = 1.0    # Placeholder\n",
    "\n",
    "    # Dynamic features (assuming you have these in your weather_data)\n",
    "    # If not, assign dummy values or extract from available data\n",
    "    laps['track_temp'] = laps['track_temp'].fillna(25.0)  # Placeholder\n",
    "    laps['air_temp'] = laps['air_temp'].fillna(20.0)      # Placeholder\n",
    "    laps['humidity'] = laps['humidity'].fillna(50.0)      # Placeholder\n",
    "\n",
    "    # Ensure that all required columns are present\n",
    "    required_columns = RaceFeatures.static_features + RaceFeatures.dynamic_features + [RaceFeatures.target]\n",
    "    missing_columns = set(required_columns) - set(laps.columns)\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Missing required columns: {missing_columns}\")\n",
    "\n",
    "    # Drop rows with missing values in required columns\n",
    "    laps = laps.dropna(subset=required_columns)\n",
    "\n",
    "    return laps\n",
    "\n",
    "# Update the main function\n",
    "def main():\n",
    "    # Load and preprocess data\n",
    "    enhanced_laps = load_and_preprocess_data()\n",
    "    \n",
    "    preprocessor = F1DataPreprocessor()\n",
    "    sequences, static, targets = preprocessor.prepare_sequence_data(enhanced_laps, window_size=3)\n",
    "    \n",
    "    # Create train and validation loaders\n",
    "    train_loader, val_loader = preprocessor.create_train_val_loaders(\n",
    "        sequences, \n",
    "        static, \n",
    "        targets,\n",
    "        batch_size=32,\n",
    "        val_split=0.2\n",
    "    )\n",
    "    \n",
    "    # Initialize model\n",
    "    model = F1PredictionModel(\n",
    "        sequence_dim=sequences.shape[2],\n",
    "        static_dim=static.shape[1]\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    history = train_model(model, train_loader, val_loader, epochs=20, learning_rate=0.001)\n",
    "    \n",
    "    # Save the trained model\n",
    "    save_model(model, 'f1_prediction_model.pth')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f56b02a0c74eec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
