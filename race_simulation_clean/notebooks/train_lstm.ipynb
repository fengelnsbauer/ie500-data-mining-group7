{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "sys.path.append('../')\n",
    "from models.LSTM.lstm import F1LapTimePredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 18:34:00,345] A new study created in memory with name: no-name-509b15e3-2f4f-4899-8deb-6a036de0f2a6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Model is on correct device: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/I551659/Library/Caches/pypoetry/virtualenvs/ie500-data-mining-group7-LKR-OXJO-py3.12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/Users/I551659/Library/Caches/pypoetry/virtualenvs/ie500-data-mining-group7-LKR-OXJO-py3.12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "[I 2024-12-08 18:45:56,841] Trial 0 finished with value: 0.5420669913291931 and parameters: {'hidden_size': 57, 'num_layers': 3, 'dropout': 0.3477065143509533, 'sequence_length': 3, 'batch_size': 79, 'learning_rate': 0.0017669727888360532, 'weight_decay': 1.7325133396028972e-05}. Best is trial 0 with value: 0.5420669913291931.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Model is on correct device: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/I551659/Library/Caches/pypoetry/virtualenvs/ie500-data-mining-group7-LKR-OXJO-py3.12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "[I 2024-12-08 19:09:11,881] Trial 1 finished with value: 0.5292047262191772 and parameters: {'hidden_size': 134, 'num_layers': 3, 'dropout': 0.2635489357835732, 'sequence_length': 8, 'batch_size': 62, 'learning_rate': 0.0008187608111383791, 'weight_decay': 5.044775595466323e-05}. Best is trial 1 with value: 0.5292047262191772.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: models/lstm_model_20241208_190911.pt\n",
      "Study results saved to: models/lstm_study_20241208_190911.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/I551659/Library/Caches/pypoetry/virtualenvs/ie500-data-mining-group7-LKR-OXJO-py3.12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'F1LapTimePredictor' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 163\u001b[0m\n\u001b[1;32m    160\u001b[0m model_path, study_path \u001b[38;5;241m=\u001b[39m save_training_artifacts(best_model, study)\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# evaluation\u001b[39;00m\n\u001b[0;32m--> 163\u001b[0m \u001b[43mevaluate_and_visualize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessed_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 61\u001b[0m, in \u001b[0;36mevaluate_and_visualize\u001b[0;34m(model, processed_data, save_dir)\u001b[0m\n\u001b[1;32m     58\u001b[0m driver_ids \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     59\u001b[0m lap_numbers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 61\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m val_loader:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'F1LapTimePredictor' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def save_training_artifacts(model, study, save_dir='models'):\n",
    "    \"\"\"Save model, hyperparameters, and study results.\"\"\"\n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Generate timestamp for unique filenames\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Save model weights and architecture\n",
    "    model_path = os.path.join(save_dir, f'lstm_model_{timestamp}.pt')\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'static_feature_size': model.static_network[0].in_features,  # Already an integer\n",
    "        'dynamic_feature_size': model.lstm.input_size,\n",
    "        'hidden_size': model.lstm.hidden_size,\n",
    "        'num_layers': model.lstm.num_layers,\n",
    "        'dropout': model.lstm.dropout if isinstance(model.lstm.dropout, float) else 0.2\n",
    "    }, model_path)\n",
    "    \n",
    "    # Save study results and hyperparameters\n",
    "    study_results = {\n",
    "        'best_params': study.best_params,\n",
    "        'best_value': study.best_value,\n",
    "        'n_trials': len(study.trials),\n",
    "        'study_statistics': {\n",
    "            'best_trial': study.best_trial.number,\n",
    "            'datetime': timestamp,\n",
    "            'trials_dataframe': study.trials_dataframe().to_dict() if hasattr(study, 'trials_dataframe') else None\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    study_path = os.path.join(save_dir, f'lstm_study_{timestamp}.pkl')\n",
    "    with open(study_path, 'wb') as f:\n",
    "        pickle.dump(study_results, f)\n",
    "    \n",
    "    print(f\"Model saved to: {model_path}\")\n",
    "    print(f\"Study results saved to: {study_path}\")\n",
    "    \n",
    "    return model_path, study_path\n",
    "\n",
    "def evaluate_and_visualize(predictor, processed_data, save_dir='models'):\n",
    "    \"\"\"Evaluate model performance and create visualization.\"\"\"\n",
    "    # Create val_loader using predictor's current parameters\n",
    "    val_loader = predictor.create_data_loaders(\n",
    "        batch_size=predictor.best_params['batch_size'], \n",
    "        sequence_length=predictor.best_params['sequence_length']\n",
    "    )[1]\n",
    "    \n",
    "    actual_times = []\n",
    "    predicted_times = []\n",
    "    race_ids = []\n",
    "    driver_ids = []\n",
    "    lap_numbers = []\n",
    "    \n",
    "    # Use predictor.best_model instead of predictor.model\n",
    "    predictor.best_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            dynamic_seq = batch['dynamic_sequence'].to(predictor.device)\n",
    "            static_feat = batch['static_features'].to(predictor.device)\n",
    "            targets = batch['target']\n",
    "            \n",
    "            predictions = predictor.best_model(dynamic_seq, static_feat)\n",
    "            \n",
    "            actual_times.extend(targets.numpy())\n",
    "            predicted_times.extend(predictions.cpu().numpy())\n",
    "            \n",
    "            # Get metadata for current batch\n",
    "            metadata_indices = batch.get('metadata_indices', [])\n",
    "            if metadata_indices:\n",
    "                test_metadata = processed_data['test']['metadata']\n",
    "                race_ids.extend(test_metadata.iloc[metadata_indices]['raceId'].values)\n",
    "                driver_ids.extend(test_metadata.iloc[metadata_indices]['driverId'].values)\n",
    "                lap_numbers.extend(test_metadata.iloc[metadata_indices]['lap'].values)\n",
    "    \n",
    "    # Rest of the function remains the same...\n",
    "\n",
    "# Main execution\n",
    "with open('processed_race_data.pkl', 'rb') as f:\n",
    "    processed_data = pickle.load(f)\n",
    "\n",
    "# Initialize the predictor\n",
    "predictor = F1LapTimePredictor(processed_data)\n",
    "\n",
    "# Run optimization\n",
    "study = predictor.optimize(n_trials=2)\n",
    "\n",
    "# Create and store the best model in the predictor\n",
    "predictor.best_model = predictor.create_best_model(study)\n",
    "predictor.best_params = study.best_params  # Store best parameters\n",
    "\n",
    "# Save training artifacts\n",
    "model_path, study_path = save_training_artifacts(predictor.best_model, study)\n",
    "\n",
    "# evaluation\n",
    "evaluate_and_visualize(predictor, processed_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ie500-data-mining-group7-LKR-OXJO-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
