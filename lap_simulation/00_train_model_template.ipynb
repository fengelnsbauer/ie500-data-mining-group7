{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Import custom modules\n",
    "from data_preparation import load_and_preprocess_data, prepare_sequence_data, split_data_by_race, save_data_splits\n",
    "from features import RaceFeatures\n",
    "from lstm import F1PredictionModel, F1Dataset, F1DataPreprocessor, train_model, save_model_with_preprocessor\n",
    "from evaluation import evaluate_model, plot_predictions\n",
    "\n",
    "def main():\n",
    "    # Load and preprocess data\n",
    "    print(\"Loading and preprocessing data...\")\n",
    "    df = load_and_preprocess_data()\n",
    "\n",
    "    print(df.columns)\n",
    "\n",
    "    # Split data by race to prevent data leakage\n",
    "    print(\"Splitting data...\")\n",
    "    train_df, test_df = split_data_by_race(df, test_size=0.2, random_state=42)\n",
    "    save_data_splits(train_df, test_df)\n",
    "\n",
    "    # Initialize preprocessor and features\n",
    "    preprocessor = F1DataPreprocessor()\n",
    "    race_features = RaceFeatures()\n",
    "\n",
    "    # Prepare sequence data\n",
    "    print(\"Preparing sequence data...\")\n",
    "    sequences_train, static_train, targets_train = prepare_sequence_data(train_df, race_features, window_size=3)\n",
    "    sequences_test, static_test, targets_test = prepare_sequence_data(test_df, race_features, window_size=3)\n",
    "\n",
    "    # Fit scalers on training data and transform all datasets\n",
    "    print(\"Scaling data...\")\n",
    "    preprocessor.fit_scalers(sequences_train, static_train, targets_train)\n",
    "\n",
    "    sequences_train_scaled, static_train_scaled, targets_train_scaled = preprocessor.transform_data(\n",
    "        sequences_train, static_train, targets_train)\n",
    "    sequences_test_scaled, static_test_scaled, targets_test_scaled = preprocessor.transform_data(\n",
    "        sequences_test, static_test, targets_test)\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = F1Dataset(sequences_train_scaled, static_train_scaled, targets_train_scaled)\n",
    "    test_dataset = F1Dataset(sequences_test_scaled, static_test_scaled, targets_test_scaled)\n",
    "\n",
    "    # Initialize the model with default parameters\n",
    "    model = F1PredictionModel(\n",
    "        sequence_dim=sequences_train_scaled.shape[2],\n",
    "        static_dim=static_train_scaled.shape[1],\n",
    "        hidden_dim=64,\n",
    "        num_layers=10,\n",
    "        dropout_prob=0.5\n",
    "    )\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    # Train model\n",
    "    print(\"Training model...\")\n",
    "    history = train_model(\n",
    "        model,\n",
    "        train_loader,\n",
    "        test_loader,  # Using test_loader as validation for now\n",
    "        epochs=10,\n",
    "        learning_rate=0.001\n",
    "    )\n",
    "\n",
    "    # Evaluate on test set\n",
    "    print(\"Evaluating model...\")\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_values = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            sequences = batch['sequence']\n",
    "            static = batch['static']\n",
    "            targets = batch['target']\n",
    "\n",
    "            outputs = model(sequences, static)\n",
    "            predictions.extend(outputs.numpy())\n",
    "            true_values.extend(targets.numpy())\n",
    "\n",
    "    # Inverse transform predictions and true values\n",
    "    predictions = preprocessor.lap_time_scaler.inverse_transform(\n",
    "        np.array(predictions).reshape(-1, 1)).flatten()\n",
    "    true_values = preprocessor.lap_time_scaler.inverse_transform(\n",
    "        np.array(true_values).reshape(-1, 1)).flatten()\n",
    "\n",
    "    # Calculate and display evaluation metrics\n",
    "    metrics = evaluate_model(true_values, predictions)\n",
    "    print(\"Test set metrics:\", metrics)\n",
    "\n",
    "    # Plot results\n",
    "    plot_predictions(true_values, predictions, model_name='LSTM Model')\n",
    "\n",
    "    save_model_with_preprocessor(\n",
    "        model,\n",
    "        preprocessor,\n",
    "        'models/lstm_model.pth'\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "df = pd.read_csv('data/LAPS.csv')\n",
    "\n",
    "profile = ProfileReport(df, title=\"Pandas Profiling Report\")\n",
    "profile.to_file(\"profile_report.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ie500-data-mining-group7-LKR-OXJO-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
