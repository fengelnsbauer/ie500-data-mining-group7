{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/I551659/Documents/GitHub/IE650-RAMP/ie500-data-mining-group7/lap_simulation/data_preparation.py:25: DtypeWarning: Columns (28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  practice_sessions = pd.read_csv('../data/raw_data/ff1_laps.csv', na_values=na_values)\n",
      "/Users/I551659/Documents/GitHub/IE650-RAMP/ie500-data-mining-group7/lap_simulation/data_preparation.py:26: DtypeWarning: Columns (28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  tire_data = pd.read_csv('../data/raw_data/ff1_laps.csv', na_values=na_values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(586171, 15)\n",
      "(586171, 32)\n",
      "(586171, 40)\n",
      "(586171, 45)\n",
      "(586171, 46)\n",
      "(586171, 47)\n",
      "(586171, 47)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/I551659/Documents/GitHub/IE650-RAMP/ie500-data-mining-group7/lap_simulation/data_preparation.py:79: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  laps['pitstop_milliseconds'].fillna(0, inplace=True)  # Assuming 0 if no pit stop\n",
      "/Users/I551659/Documents/GitHub/IE650-RAMP/ie500-data-mining-group7/lap_simulation/data_preparation.py:106: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  laps['constructor_points'].fillna(laps['constructor_points'].mean(), inplace=True)\n",
      "/Users/I551659/Documents/GitHub/IE650-RAMP/ie500-data-mining-group7/lap_simulation/data_preparation.py:107: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  laps['constructor_position'].fillna(laps['constructor_position'].max(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(586171, 56)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/I551659/Documents/GitHub/IE650-RAMP/ie500-data-mining-group7/lap_simulation/data_preparation.py:196: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  laps['Compound'].fillna('UNKNOWN', inplace=True)\n",
      "/Users/I551659/Documents/GitHub/IE650-RAMP/ie500-data-mining-group7/lap_simulation/data_preparation.py:249: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  laps['fp1_median_time'].fillna(global_median_fp1, inplace=True)\n",
      "/Users/I551659/Documents/GitHub/IE650-RAMP/ie500-data-mining-group7/lap_simulation/data_preparation.py:253: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  laps['fp2_median_time'].fillna(global_median_fp2, inplace=True)\n",
      "/Users/I551659/Documents/GitHub/IE650-RAMP/ie500-data-mining-group7/lap_simulation/data_preparation.py:256: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  laps['fp3_median_time'].fillna(global_median_fp3, inplace=True)\n",
      "/Users/I551659/Documents/GitHub/IE650-RAMP/ie500-data-mining-group7/lap_simulation/data_preparation.py:259: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  laps['quali_time'].fillna(global_median_quali, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching for 1\n",
      "Matching for 2\n",
      "Matching for 3\n",
      "Matching for 4\n",
      "Matching for 5\n",
      "Matching for 6\n",
      "Matching for 7\n",
      "Matching for 8\n",
      "Matching for 9\n",
      "Matching for 10\n",
      "Matching for 11\n",
      "Matching for 12\n",
      "Matching for 13\n",
      "Matching for 14\n",
      "Matching for 15\n",
      "Matching for 16\n",
      "Matching for 17\n",
      "Matching for 18\n",
      "Matching for 19\n",
      "Matching for 20\n",
      "Matching for 21\n",
      "Matching for 22\n",
      "Matching for 23\n",
      "Matching for 24\n",
      "Matching for 25\n",
      "Matching for 26\n",
      "Matching for 27\n",
      "Matching for 28\n",
      "Matching for 29\n",
      "Matching for 30\n",
      "Matching for 31\n",
      "Matching for 32\n",
      "Matching for 33\n",
      "Matching for 34\n",
      "Matching for 35\n",
      "Matching for 36\n",
      "Matching for 37\n",
      "Matching for 38\n",
      "Matching for 39\n",
      "Matching for 40\n",
      "Matching for 41\n",
      "Matching for 42\n",
      "Matching for 43\n",
      "Matching for 44\n",
      "Matching for 45\n",
      "Matching for 46\n",
      "Matching for 47\n",
      "Matching for 48\n",
      "Matching for 49\n",
      "Matching for 50\n",
      "Matching for 51\n",
      "Matching for 52\n",
      "Matching for 53\n",
      "Matching for 54\n",
      "Matching for 55\n",
      "Matching for 56\n",
      "Matching for 57\n",
      "Matching for 58\n",
      "Matching for 59\n",
      "Matching for 60\n",
      "Matching for 61\n",
      "Matching for 62\n",
      "Matching for 63\n",
      "Matching for 64\n",
      "Matching for 65\n",
      "Matching for 66\n",
      "Matching for 67\n",
      "Matching for 68\n",
      "Matching for 69\n",
      "Matching for 70\n",
      "Matching for 71\n",
      "Matching for 72\n",
      "Matching for 73\n",
      "Matching for 74\n",
      "Matching for 75\n",
      "Matching for 76\n",
      "Matching for 77\n",
      "Matching for 78\n",
      "Matching for 79\n",
      "Matching for 80\n",
      "Matching for 81\n",
      "Matching for 82\n",
      "Matching for 83\n",
      "Matching for 84\n",
      "Matching for 85\n",
      "Matching for 86\n",
      "Matching for 87\n",
      "Matching for 88\n",
      "Matching for 89\n",
      "Matching for 90\n",
      "Matching for 91\n",
      "Matching for 92\n",
      "Matching for 93\n",
      "Matching for 94\n",
      "Matching for 95\n",
      "Matching for 96\n",
      "Matching for 97\n",
      "Matching for 98\n",
      "Matching for 99\n",
      "Matching for 100\n",
      "Matching for 101\n",
      "Matching for 102\n",
      "Matching for 103\n",
      "Matching for 104\n",
      "Matching for 105\n",
      "Matching for 106\n",
      "Matching for 107\n",
      "Matching for 108\n",
      "Matching for 109\n",
      "Matching for 110\n",
      "Matching for 111\n",
      "Matching for 112\n",
      "Matching for 113\n",
      "Matching for 114\n",
      "Matching for 115\n",
      "Matching for 116\n",
      "Matching for 117\n",
      "Matching for 118\n",
      "Matching for 119\n",
      "Matching for 120\n",
      "Matching for 121\n",
      "Matching for 122\n",
      "Matching for 123\n",
      "Matching for 124\n",
      "Matching for 125\n",
      "Matching for 126\n",
      "Matching for 127\n",
      "Matching for 128\n",
      "Matching for 129\n",
      "Matching for 130\n",
      "Matching for 131\n",
      "Matching for 132\n",
      "Matching for 133\n",
      "Matching for 134\n",
      "Matching for 135\n",
      "Matching for 136\n",
      "Matching for 137\n",
      "Matching for 138\n",
      "Matching for 139\n",
      "Matching for 140\n",
      "Matching for 141\n",
      "Matching for 142\n",
      "Matching for 143\n",
      "Matching for 144\n",
      "Matching for 145\n",
      "Matching for 146\n",
      "Matching for 147\n",
      "Matching for 148\n",
      "Matching for 149\n",
      "Matching for 150\n",
      "Matching for 151\n",
      "Matching for 152\n",
      "Matching for 153\n",
      "Matching for 154\n",
      "Matching for 155\n",
      "Matching for 156\n",
      "Matching for 157\n",
      "Matching for 158\n",
      "Matching for 159\n",
      "Matching for 160\n",
      "Matching for 161\n",
      "Matching for 162\n",
      "Matching for 163\n",
      "Matching for 164\n",
      "Matching for 165\n",
      "Matching for 166\n",
      "Matching for 167\n",
      "Matching for 168\n",
      "Matching for 169\n",
      "Matching for 170\n",
      "Matching for 171\n",
      "Matching for 172\n",
      "Matching for 173\n",
      "Matching for 174\n",
      "Matching for 175\n",
      "Matching for 176\n",
      "Matching for 177\n",
      "Matching for 178\n",
      "Matching for 179\n",
      "Matching for 180\n",
      "Matching for 181\n",
      "Matching for 182\n",
      "Matching for 183\n",
      "Matching for 184\n",
      "Matching for 185\n",
      "Matching for 186\n",
      "Matching for 187\n",
      "Matching for 188\n",
      "Matching for 189\n",
      "Matching for 190\n",
      "Matching for 191\n",
      "Matching for 192\n",
      "Matching for 193\n",
      "Matching for 194\n",
      "Matching for 195\n",
      "Matching for 196\n",
      "Matching for 197\n",
      "Matching for 198\n",
      "Matching for 199\n",
      "Matching for 200\n",
      "Matching for 201\n",
      "Matching for 202\n",
      "Matching for 203\n",
      "Matching for 204\n",
      "Matching for 205\n",
      "Matching for 206\n",
      "Matching for 207\n",
      "Matching for 208\n",
      "Matching for 209\n",
      "Matching for 210\n",
      "Matching for 211\n",
      "Matching for 212\n",
      "Matching for 213\n",
      "Matching for 214\n",
      "Matching for 215\n",
      "Matching for 216\n",
      "Matching for 217\n",
      "Matching for 218\n",
      "Matching for 219\n",
      "Matching for 220\n",
      "Matching for 221\n",
      "Matching for 222\n",
      "Matching for 223\n",
      "Matching for 224\n",
      "Matching for 225\n",
      "Matching for 226\n",
      "Matching for 227\n",
      "Matching for 228\n",
      "Matching for 229\n",
      "Matching for 230\n",
      "Matching for 231\n",
      "Matching for 232\n",
      "Matching for 233\n",
      "Matching for 234\n",
      "Matching for 235\n",
      "Matching for 236\n",
      "Matching for 237\n",
      "Matching for 238\n",
      "Matching for 239\n",
      "Matching for 337\n",
      "Matching for 338\n",
      "Matching for 339\n",
      "Matching for 340\n",
      "Matching for 341\n",
      "Matching for 342\n",
      "Matching for 343\n",
      "Matching for 344\n",
      "Matching for 345\n",
      "Matching for 346\n",
      "Matching for 347\n",
      "Matching for 348\n",
      "Matching for 349\n",
      "Matching for 350\n",
      "Matching for 351\n",
      "Matching for 352\n",
      "Matching for 353\n",
      "Matching for 354\n",
      "Matching for 355\n",
      "Matching for 841\n",
      "Matching for 842\n",
      "Matching for 843\n",
      "Matching for 844\n",
      "Matching for 845\n",
      "Matching for 846\n",
      "Matching for 847\n",
      "Matching for 848\n",
      "Matching for 849\n",
      "Matching for 850\n",
      "Matching for 851\n",
      "Matching for 852\n",
      "Matching for 853\n",
      "Matching for 854\n",
      "Matching for 855\n",
      "Matching for 856\n",
      "Matching for 857\n",
      "Matching for 858\n",
      "Matching for 859\n",
      "Matching for 860\n",
      "Matching for 861\n",
      "Matching for 862\n",
      "Matching for 863\n",
      "Matching for 864\n",
      "Matching for 865\n",
      "Matching for 866\n",
      "Matching for 867\n",
      "Matching for 868\n",
      "Matching for 869\n",
      "Matching for 870\n",
      "Matching for 871\n",
      "Matching for 872\n",
      "Matching for 873\n",
      "Matching for 874\n",
      "Matching for 875\n",
      "Matching for 876\n",
      "Matching for 877\n",
      "Matching for 878\n",
      "Matching for 879\n",
      "Matching for 880\n",
      "Matching for 881\n",
      "Matching for 882\n",
      "Matching for 883\n",
      "Matching for 884\n",
      "Matching for 885\n",
      "Matching for 886\n",
      "Matching for 887\n",
      "Matching for 888\n",
      "Matching for 890\n",
      "Matching for 891\n",
      "Matching for 892\n",
      "Matching for 893\n",
      "Matching for 894\n",
      "Matching for 895\n",
      "Matching for 896\n",
      "Matching for 897\n",
      "Matching for 898\n",
      "Matching for 899\n",
      "Matching for 900\n",
      "Matching for 901\n",
      "Matching for 902\n",
      "Matching for 903\n",
      "Matching for 904\n",
      "Matching for 905\n",
      "Matching for 906\n",
      "Matching for 907\n",
      "Matching for 908\n",
      "Matching for 909\n",
      "Matching for 910\n",
      "Matching for 911\n",
      "Matching for 912\n",
      "Matching for 913\n",
      "Matching for 914\n",
      "Matching for 915\n",
      "Matching for 916\n",
      "Matching for 917\n",
      "Matching for 918\n",
      "Matching for 926\n",
      "Matching for 927\n",
      "Matching for 928\n",
      "Matching for 929\n",
      "Matching for 930\n",
      "Matching for 931\n",
      "Matching for 932\n",
      "Matching for 933\n",
      "Matching for 934\n",
      "Matching for 936\n",
      "Matching for 937\n",
      "Matching for 938\n",
      "Matching for 939\n",
      "Matching for 940\n",
      "Matching for 941\n",
      "Matching for 942\n",
      "Matching for 943\n",
      "Matching for 944\n",
      "Matching for 945\n",
      "Matching for 948\n",
      "Matching for 949\n",
      "Matching for 950\n",
      "Matching for 951\n",
      "Matching for 952\n",
      "Matching for 953\n",
      "Matching for 954\n",
      "Matching for 955\n",
      "Matching for 956\n",
      "Matching for 957\n",
      "Matching for 958\n",
      "Matching for 959\n",
      "Matching for 960\n",
      "Matching for 961\n",
      "Matching for 962\n",
      "Matching for 963\n",
      "Matching for 964\n",
      "Matching for 965\n",
      "Matching for 966\n",
      "Matching for 967\n",
      "Matching for 968\n",
      "Matching for 969\n",
      "Matching for 970\n",
      "Matching for 971\n",
      "Matching for 972\n",
      "Matching for 973\n",
      "Matching for 974\n",
      "Matching for 975\n",
      "Matching for 976\n",
      "Matching for 977\n",
      "Matching for 978\n",
      "Matching for 979\n",
      "Matching for 980\n",
      "Matching for 981\n",
      "Matching for 982\n",
      "Matching for 983\n",
      "Matching for 984\n",
      "Matching for 985\n",
      "Matching for 986\n",
      "Matching for 987\n",
      "Matching for 988\n",
      "Matching for 989\n",
      "Matching for 990\n",
      "Matching for 991\n",
      "Matching for 992\n",
      "Matching for 993\n",
      "Matching for 994\n",
      "Matching for 995\n",
      "Matching for 996\n",
      "Matching for 997\n",
      "Matching for 998\n",
      "Matching for 999\n",
      "Matching for 1000\n",
      "Matching for 1001\n",
      "Matching for 1002\n",
      "Matching for 1003\n",
      "Matching for 1004\n",
      "Matching for 1005\n",
      "Matching for 1006\n",
      "Matching for 1007\n",
      "Matching for 1008\n",
      "Matching for 1009\n",
      "Matching for 1010\n",
      "Matching for 1011\n",
      "Matching for 1012\n",
      "Matching for 1013\n",
      "Matching for 1014\n",
      "Matching for 1015\n",
      "Matching for 1016\n",
      "Matching for 1017\n",
      "Matching for 1018\n",
      "Matching for 1019\n",
      "Matching for 1020\n",
      "Matching for 1021\n",
      "Matching for 1022\n",
      "Matching for 1023\n",
      "Matching for 1024\n",
      "Matching for 1025\n",
      "Matching for 1026\n",
      "Matching for 1027\n",
      "Matching for 1028\n",
      "Matching for 1029\n",
      "Matching for 1030\n",
      "Matching for 1031\n",
      "Matching for 1032\n",
      "Matching for 1033\n",
      "Matching for 1034\n",
      "Matching for 1035\n",
      "Matching for 1036\n",
      "Matching for 1037\n",
      "Matching for 1038\n",
      "Matching for 1039\n",
      "Matching for 1040\n",
      "Matching for 1041\n",
      "Matching for 1042\n",
      "Matching for 1043\n",
      "Matching for 1044\n",
      "Matching for 1045\n",
      "Matching for 1046\n",
      "Matching for 1047\n",
      "Matching for 1051\n",
      "Matching for 1052\n",
      "Matching for 1053\n",
      "Matching for 1054\n",
      "Matching for 1055\n",
      "Matching for 1056\n",
      "Matching for 1057\n",
      "Matching for 1058\n",
      "Matching for 1059\n",
      "Matching for 1060\n",
      "Matching for 1061\n",
      "Matching for 1062\n",
      "Matching for 1063\n",
      "Matching for 1064\n",
      "Matching for 1065\n",
      "Matching for 1066\n",
      "Matching for 1067\n",
      "Matching for 1069\n",
      "Matching for 1070\n",
      "Matching for 1071\n",
      "Matching for 1072\n",
      "Matching for 1073\n",
      "Matching for 1074\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (1123, 65)\n",
      "Matching for 1075\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (816, 65)\n",
      "Matching for 1076\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (1042, 65)\n",
      "Matching for 1077\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (1131, 65)\n",
      "Matching for 1078\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (1055, 65)\n",
      "Matching for 1079\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (1230, 65)\n",
      "Matching for 1080\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (1176, 65)\n",
      "Matching for 1081\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (889, 65)\n",
      "Matching for 1082\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (1262, 65)\n",
      "Matching for 1083\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (811, 65)\n",
      "Matching for 1084\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (1323, 65)\n",
      "Matching for 1085\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (953, 65)\n",
      "Matching for 1086\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (1382, 65)\n",
      "Matching for 1087\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (790, 65)\n",
      "Matching for 1088\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (1391, 65)\n",
      "Matching for 1089\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (969, 65)\n",
      "Matching for 1091\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (941, 65)\n",
      "Matching for 1092\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (504, 65)\n",
      "Matching for 1093\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (990, 65)\n",
      "Matching for 1094\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (1378, 65)\n",
      "Matching for 1095\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (1256, 65)\n",
      "Matching for 1096\n",
      "Matching for 1098\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (1055, 65)\n",
      "Matching for 1099\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (942, 65)\n",
      "Matching for 1100\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (995, 65)\n",
      "Matching for 1101\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (961, 65)\n",
      "Matching for 1102\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (1138, 65)\n",
      "Matching for 1104\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (1513, 65)\n",
      "Matching for 1105\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (1312, 65)\n",
      "Matching for 1106\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (1315, 65)\n",
      "Matching for 1107\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (1353, 65)\n",
      "Matching for 1108\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (970, 65)\n",
      "Matching for 1109\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (1252, 65)\n",
      "Matching for 1110\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (815, 65)\n",
      "Matching for 1111\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (1341, 65)\n",
      "Matching for 1112\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (955, 65)\n",
      "Matching for 1113\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (1084, 65)\n",
      "Matching for 1114\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (880, 65)\n",
      "Matching for 1115\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (1005, 65)\n",
      "Matching for 1116\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (1014, 65)\n",
      "Matching for 1117\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (1280, 65)\n",
      "Matching for 1118\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (1106, 65)\n",
      "Matching for 1119\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (943, 65)\n",
      "Matching for 1120\n",
      "Matching for 1121\n",
      "Matching for 1122\n",
      "Matching for 1123\n",
      "Matching for 1124\n",
      "Matching for 1125\n",
      "Matching for 1126\n",
      "Matching for 1127\n",
      "Matching for 1128\n",
      "Matching for 1129\n",
      "Matching for 1130\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (1310, 65)\n",
      "Matching for 1131\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (1405, 65)\n",
      "Matching for 1132\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (960, 65)\n",
      "Matching for 1133\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (1355, 65)\n",
      "Matching for 1134\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (841, 65)\n",
      "Matching for 1135\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (1426, 65)\n",
      "Matching for 1136\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (1008, 65)\n",
      "Matching for 1137\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (971, 65)\n",
      "Matching for 1138\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (1177, 65)\n",
      "Matching for 1139\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (1058, 65)\n",
      "Matching for 1140\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (1213, 65)\n",
      "Matching for 1141\n",
      "Error aligning weather data: Merge keys contain null values on right side\n",
      "Matched DataFrame shape: (1133, 65)\n",
      "(586171, 65)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'TrackTemp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/ie500-data-mining-group7-LKR-OXJO-py3.12/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'TrackTemp'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 108\u001b[0m\n\u001b[1;32m     99\u001b[0m    save_model_with_preprocessor(\n\u001b[1;32m    100\u001b[0m        model,\n\u001b[1;32m    101\u001b[0m        preprocessor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    104\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/lstm_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    105\u001b[0m    )\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 108\u001b[0m    \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 17\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m     15\u001b[0m    \u001b[38;5;66;03m# Load and preprocess data\u001b[39;00m\n\u001b[1;32m     16\u001b[0m    \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading and preprocessing data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m    df \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_preprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m    \u001b[38;5;66;03m# Split data by race to prevent data leakage\u001b[39;00m\n\u001b[1;32m     20\u001b[0m    \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSplitting data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/IE650-RAMP/ie500-data-mining-group7/lap_simulation/data_preparation.py:678\u001b[0m, in \u001b[0;36mload_and_preprocess_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m    675\u001b[0m race_features \u001b[38;5;241m=\u001b[39m RaceFeatures()\n\u001b[1;32m    677\u001b[0m \u001b[38;5;66;03m# Preprocess data\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;66;03m# Validate that all required columns are present\u001b[39;00m\n\u001b[1;32m    681\u001b[0m required_columns \u001b[38;5;241m=\u001b[39m race_features\u001b[38;5;241m.\u001b[39mstatic_features \u001b[38;5;241m+\u001b[39m race_features\u001b[38;5;241m.\u001b[39mdynamic_features\n",
      "File \u001b[0;32m~/Documents/GitHub/IE650-RAMP/ie500-data-mining-group7/lap_simulation/data_preparation.py:316\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28mprint\u001b[39m(laps\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    315\u001b[0m \u001b[38;5;66;03m# Fill missing weather data with default values\u001b[39;00m\n\u001b[0;32m--> 316\u001b[0m laps[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrack_temp\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mlaps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTrackTemp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m25.0\u001b[39m)\n\u001b[1;32m    317\u001b[0m laps[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mair_temp\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m laps[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAirTemp\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m20.0\u001b[39m)\n\u001b[1;32m    318\u001b[0m laps[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhumidity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m laps[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHumidity\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m50.0\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/ie500-data-mining-group7-LKR-OXJO-py3.12/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/ie500-data-mining-group7-LKR-OXJO-py3.12/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'TrackTemp'"
     ]
    }
   ],
   "source": [
    "# Import standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Import custom modules\n",
    "from data_preparation import load_and_preprocess_data, prepare_sequence_data, split_data_by_race, save_data_splits\n",
    "from features import RaceFeatures\n",
    "from lstm import F1PredictionModel, F1Dataset, F1DataPreprocessor, train_model, save_model_with_preprocessor\n",
    "from evaluation import evaluate_model, plot_predictions\n",
    "\n",
    "def main():\n",
    "   # Load and preprocess data\n",
    "   print(\"Loading and preprocessing data...\")\n",
    "   df = load_and_preprocess_data()\n",
    "\n",
    "   # Split data by race to prevent data leakage\n",
    "   print(\"Splitting data...\")\n",
    "   train_df, test_df = split_data_by_race(df, test_size=0.2, random_state=42)\n",
    "   save_data_splits(train_df, test_df)\n",
    "\n",
    "   # Initialize preprocessor and features\n",
    "   preprocessor = F1DataPreprocessor()\n",
    "   race_features = RaceFeatures()\n",
    "\n",
    "   # Prepare sequence data\n",
    "   print(\"Preparing sequence data...\")\n",
    "   sequences_train, static_train, targets_train = prepare_sequence_data(train_df, race_features, window_size=3)\n",
    "   sequences_test, static_test, targets_test = prepare_sequence_data(test_df, race_features, window_size=3)\n",
    "\n",
    "   # Fit scalers on training data and transform all datasets\n",
    "   print(\"Scaling data...\")\n",
    "   preprocessor.fit_scalers(sequences_train, static_train, targets_train)\n",
    "   \n",
    "   sequences_train_scaled, static_train_scaled, targets_train_scaled = preprocessor.transform_data(\n",
    "       sequences_train, static_train, targets_train)\n",
    "   sequences_test_scaled, static_test_scaled, targets_test_scaled = preprocessor.transform_data(\n",
    "       sequences_test, static_test, targets_test)\n",
    "\n",
    "   # Create datasets\n",
    "   train_dataset = F1Dataset(sequences_train_scaled, static_train_scaled, targets_train_scaled)\n",
    "   test_dataset = F1Dataset(sequences_test_scaled, static_test_scaled, targets_test_scaled)\n",
    "\n",
    "   # Initialize the model with default parameters\n",
    "   model = F1PredictionModel(\n",
    "       sequence_dim=sequences_train_scaled.shape[2],\n",
    "       static_dim=static_train_scaled.shape[1],\n",
    "       hidden_dim=64,\n",
    "       num_layers=10,\n",
    "       dropout_prob=0.5\n",
    "   )\n",
    "\n",
    "   # Create data loaders\n",
    "   train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "   test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "   # Train model\n",
    "   print(\"Training model...\")\n",
    "   history = train_model(\n",
    "       model,\n",
    "       train_loader,\n",
    "       test_loader,  # Using test_loader as validation for now\n",
    "       epochs=10,\n",
    "       learning_rate=0.001\n",
    "   )\n",
    "\n",
    "   # Evaluate on test set\n",
    "   print(\"Evaluating model...\")\n",
    "   model.eval()\n",
    "   predictions = []\n",
    "   true_values = []\n",
    "\n",
    "   with torch.no_grad():\n",
    "       for batch in test_loader:\n",
    "           sequences = batch['sequence']\n",
    "           static = batch['static']\n",
    "           targets = batch['target']\n",
    "\n",
    "           outputs = model(sequences, static)\n",
    "           predictions.extend(outputs.numpy())\n",
    "           true_values.extend(targets.numpy())\n",
    "\n",
    "   # Inverse transform predictions and true values\n",
    "   predictions = preprocessor.lap_time_scaler.inverse_transform(\n",
    "       np.array(predictions).reshape(-1, 1)).flatten()\n",
    "   true_values = preprocessor.lap_time_scaler.inverse_transform(\n",
    "       np.array(true_values).reshape(-1, 1)).flatten()\n",
    "\n",
    "   # Calculate and display evaluation metrics\n",
    "   metrics = evaluate_model(true_values, predictions)\n",
    "   print(\"Test set metrics:\", metrics)\n",
    "\n",
    "   # Plot results\n",
    "   plot_predictions(true_values, predictions, model_name='LSTM Model')\n",
    "\n",
    "   # Save the model\n",
    "   save_model_with_preprocessor(\n",
    "       model,\n",
    "       preprocessor,\n",
    "       sequences_train_scaled.shape[2],\n",
    "       static_train_scaled.shape[1],\n",
    "       'models/lstm_model.pth'\n",
    "   )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ie500-data-mining-group7-LKR-OXJO-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
