optimizer, loss_function, learning_rate, loss,
adam, mse, 0.000390, 89534.3093,
adamw, mse, 0.005119, 39697.1995,
adam, mse, 0.000039, 89560.1775,
adam, mse, 0.000607, 89442.7728,
sgd, l1, 0.000025, 89560.1499,
adam, l1, 0.002966, 51439.5356,
sgd, l1, 0.000144, 89559.9540,
adam, mse, 0.002059, 76630.4288,
adam, l1, 0.000248, 89555.0359,